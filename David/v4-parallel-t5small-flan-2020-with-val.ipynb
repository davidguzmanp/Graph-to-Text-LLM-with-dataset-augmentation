{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"2a8badda5171f6c1da75e6dcec216359e8635e393e06f848b1b87b76c1bdea5e"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"27dac6771009442986c337835ac2fab0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81ab3401681e449faca4585337346d4a","IPY_MODEL_ac24b2b5a91b48e6a8746e3e0a6bdd56","IPY_MODEL_099b3ea61045469caa5684f5d4b5fa38"],"layout":"IPY_MODEL_d41d0e0245a142589c8f5767ce8e0d3b"}},"81ab3401681e449faca4585337346d4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e466a23c1954b84bd29cee2299101b5","placeholder":"​","style":"IPY_MODEL_094afeea467543ae879be701e4a73d63","value":"100%"}},"ac24b2b5a91b48e6a8746e3e0a6bdd56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa9427c68daf40d3af8410141bfe94b3","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6dfc55f38ffe49e59ccb600b0de75088","value":3}},"099b3ea61045469caa5684f5d4b5fa38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec91a1ad9e7b4bafbc79f9ddfaa0296e","placeholder":"​","style":"IPY_MODEL_4cec0b2d487b4c13ad153e6924cc8e4a","value":" 3/3 [00:00&lt;00:00, 65.75it/s]"}},"d41d0e0245a142589c8f5767ce8e0d3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e466a23c1954b84bd29cee2299101b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"094afeea467543ae879be701e4a73d63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa9427c68daf40d3af8410141bfe94b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dfc55f38ffe49e59ccb600b0de75088":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec91a1ad9e7b4bafbc79f9ddfaa0296e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cec0b2d487b4c13ad153e6924cc8e4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1af09f1f71524f44b3f79ed0427c8559":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4027186c2a1646c7a47db3e69d3ef93b","IPY_MODEL_c224ebc06fcf44dc80e8285b6578680e","IPY_MODEL_f3f96e77a1134c5c93ba218b8261ec0f"],"layout":"IPY_MODEL_45509cc5af034006bade5bff3fe9ea3b"}},"4027186c2a1646c7a47db3e69d3ef93b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7719bedd5d2544a38a46f058d0ef1a7e","placeholder":"​","style":"IPY_MODEL_305d7d10c879476ea87f924e2f802958","value":"100%"}},"c224ebc06fcf44dc80e8285b6578680e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4731ce03cfa84014bce0054c8611b4f9","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6af2a7876d954b93aca5a16930c9f079","value":3}},"f3f96e77a1134c5c93ba218b8261ec0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_528070b64e7d4bb0a891f1dbe89ae5bc","placeholder":"​","style":"IPY_MODEL_a99d41291bf84041a091180eb477e519","value":" 3/3 [00:00&lt;00:00, 106.45it/s]"}},"45509cc5af034006bade5bff3fe9ea3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7719bedd5d2544a38a46f058d0ef1a7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"305d7d10c879476ea87f924e2f802958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4731ce03cfa84014bce0054c8611b4f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af2a7876d954b93aca5a16930c9f079":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"528070b64e7d4bb0a891f1dbe89ae5bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99d41291bf84041a091180eb477e519":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d15948f114040928a325e1665e0b1bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9aa2a3f7d6ec414cb6bc735391cc7462","IPY_MODEL_a72bd5b05ddc4e20bd777a1e51bff87f","IPY_MODEL_45e968b74fdc440382f08bfe83797d7f"],"layout":"IPY_MODEL_27829187a83e45859d0adf6deb1a5f12"}},"9aa2a3f7d6ec414cb6bc735391cc7462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01cfd32ca9ea4e54a1bff6119613d64a","placeholder":"​","style":"IPY_MODEL_abcb191fcc264867b122d58caf9e3652","value":"Downloading (…)ve/main/spiece.model: 100%"}},"a72bd5b05ddc4e20bd777a1e51bff87f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1375be65005469a9c05fb385f1597db","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_194bc9079f024606b19ed153cd2d2226","value":791656}},"45e968b74fdc440382f08bfe83797d7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccf95078f5474a8a9917dc95c2d296df","placeholder":"​","style":"IPY_MODEL_8c955109118d4ffcb3b5b9db8520eb2a","value":" 792k/792k [00:00&lt;00:00, 3.16MB/s]"}},"27829187a83e45859d0adf6deb1a5f12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01cfd32ca9ea4e54a1bff6119613d64a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abcb191fcc264867b122d58caf9e3652":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1375be65005469a9c05fb385f1597db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"194bc9079f024606b19ed153cd2d2226":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccf95078f5474a8a9917dc95c2d296df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c955109118d4ffcb3b5b9db8520eb2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"836b768308904b9e98965838df6d56cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c26f17223f9049fabbeeef900dc0f084","IPY_MODEL_096b9fdf24f44aedaa16e9f31bff5e74","IPY_MODEL_3f2e2e165fcf4575bfd2127e0f392e0d"],"layout":"IPY_MODEL_511bf71170c94239b561c6ed9c7a2014"}},"c26f17223f9049fabbeeef900dc0f084":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e0a091ca3f743b599684ec709c0724d","placeholder":"​","style":"IPY_MODEL_7f042786107f41a5be4dffec5461e220","value":"Downloading (…)lve/main/config.json: 100%"}},"096b9fdf24f44aedaa16e9f31bff5e74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98782b2ca67b42eabe9128090a4f3eec","max":1206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b61db7dc7854a6da1f96c46dfbdf72c","value":1206}},"3f2e2e165fcf4575bfd2127e0f392e0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a85ddf4d0fdf44ba815ca3f03b476407","placeholder":"​","style":"IPY_MODEL_46f3784588fe467cbddcf6e15bfcaa82","value":" 1.21k/1.21k [00:00&lt;00:00, 21.9kB/s]"}},"511bf71170c94239b561c6ed9c7a2014":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e0a091ca3f743b599684ec709c0724d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f042786107f41a5be4dffec5461e220":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98782b2ca67b42eabe9128090a4f3eec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b61db7dc7854a6da1f96c46dfbdf72c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a85ddf4d0fdf44ba815ca3f03b476407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f3784588fe467cbddcf6e15bfcaa82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76ea121789c34ab0ae3db2a11ce092dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0755e20e9e894e0782a6dc013944a602","IPY_MODEL_16d5d7274b774723913d9a9df040db90","IPY_MODEL_ca6af7cc25b745999b2e819972a5794c"],"layout":"IPY_MODEL_46a8ce2527bb48088f5a414f6df0ee73"}},"0755e20e9e894e0782a6dc013944a602":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed369610f713419fae0a9c26abee2b91","placeholder":"​","style":"IPY_MODEL_fe46615805e146788d96ca94f066fd87","value":"Downloading pytorch_model.bin: 100%"}},"16d5d7274b774723913d9a9df040db90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15c2f29bfa54944989bf35497436615","max":242065649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c7e7ef1e3a34c228e0972f094716cef","value":242065649}},"ca6af7cc25b745999b2e819972a5794c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2766052cd6cd43288677e89f524222aa","placeholder":"​","style":"IPY_MODEL_c1326237db9f4a39bb312b80678be410","value":" 242M/242M [00:01&lt;00:00, 240MB/s]"}},"46a8ce2527bb48088f5a414f6df0ee73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed369610f713419fae0a9c26abee2b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe46615805e146788d96ca94f066fd87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f15c2f29bfa54944989bf35497436615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c7e7ef1e3a34c228e0972f094716cef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2766052cd6cd43288677e89f524222aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1326237db9f4a39bb312b80678be410":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2bd17acda9f4a4cb40387e7a16a4aad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34b7d58e7c434652ab4a9f4cecef0791","IPY_MODEL_c406fb3d9ff8428da7b08d1dbf76e81a","IPY_MODEL_ceff9ff6affd4f168cff5c526d56fcd7"],"layout":"IPY_MODEL_13c9318a176f42ecac5d6162d510395f"}},"34b7d58e7c434652ab4a9f4cecef0791":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99ea585e29ff4e2a966d1c69be32cb97","placeholder":"​","style":"IPY_MODEL_1f85b576a95d4b6a8ee70e78ecaa34a7","value":"Downloading (…)neration_config.json: 100%"}},"c406fb3d9ff8428da7b08d1dbf76e81a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c80227b65297408db3c88583a2291f7b","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d55e7db195b44955b09e0f04598a3598","value":147}},"ceff9ff6affd4f168cff5c526d56fcd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85e687ff32694c0aa1bedacf5b4bbf21","placeholder":"​","style":"IPY_MODEL_0982aa5f0748431e86626537055d9978","value":" 147/147 [00:00&lt;00:00, 2.48kB/s]"}},"13c9318a176f42ecac5d6162d510395f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99ea585e29ff4e2a966d1c69be32cb97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f85b576a95d4b6a8ee70e78ecaa34a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c80227b65297408db3c88583a2291f7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d55e7db195b44955b09e0f04598a3598":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85e687ff32694c0aa1bedacf5b4bbf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0982aa5f0748431e86626537055d9978":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\n!pip install datasets\n\n!pip install transformers \n!pip install sentencepiece\n\n!pip install sacrebleu\n'''","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahHaXoNB9iBc","outputId":"7a29568e-467f-4334-b715-11bd6c8b649d","execution":{"iopub.status.busy":"2023-05-24T20:39:06.853402Z","iopub.execute_input":"2023-05-24T20:39:06.853745Z","iopub.status.idle":"2023-05-24T20:39:06.869756Z","shell.execute_reply.started":"2023-05-24T20:39:06.853716Z","shell.execute_reply":"2023-05-24T20:39:06.868644Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'\\n!pip install datasets\\n\\n!pip install transformers \\n!pip install sentencepiece\\n\\n!pip install sacrebleu\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom torch.nn.parallel import DataParallel\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\nmodel = DataParallel(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255,"referenced_widgets":["0d15948f114040928a325e1665e0b1bc","9aa2a3f7d6ec414cb6bc735391cc7462","a72bd5b05ddc4e20bd777a1e51bff87f","45e968b74fdc440382f08bfe83797d7f","27829187a83e45859d0adf6deb1a5f12","01cfd32ca9ea4e54a1bff6119613d64a","abcb191fcc264867b122d58caf9e3652","a1375be65005469a9c05fb385f1597db","194bc9079f024606b19ed153cd2d2226","ccf95078f5474a8a9917dc95c2d296df","8c955109118d4ffcb3b5b9db8520eb2a","836b768308904b9e98965838df6d56cc","c26f17223f9049fabbeeef900dc0f084","096b9fdf24f44aedaa16e9f31bff5e74","3f2e2e165fcf4575bfd2127e0f392e0d","511bf71170c94239b561c6ed9c7a2014","3e0a091ca3f743b599684ec709c0724d","7f042786107f41a5be4dffec5461e220","98782b2ca67b42eabe9128090a4f3eec","6b61db7dc7854a6da1f96c46dfbdf72c","a85ddf4d0fdf44ba815ca3f03b476407","46f3784588fe467cbddcf6e15bfcaa82","76ea121789c34ab0ae3db2a11ce092dc","0755e20e9e894e0782a6dc013944a602","16d5d7274b774723913d9a9df040db90","ca6af7cc25b745999b2e819972a5794c","46a8ce2527bb48088f5a414f6df0ee73","ed369610f713419fae0a9c26abee2b91","fe46615805e146788d96ca94f066fd87","f15c2f29bfa54944989bf35497436615","8c7e7ef1e3a34c228e0972f094716cef","2766052cd6cd43288677e89f524222aa","c1326237db9f4a39bb312b80678be410","c2bd17acda9f4a4cb40387e7a16a4aad","34b7d58e7c434652ab4a9f4cecef0791","c406fb3d9ff8428da7b08d1dbf76e81a","ceff9ff6affd4f168cff5c526d56fcd7","13c9318a176f42ecac5d6162d510395f","99ea585e29ff4e2a966d1c69be32cb97","1f85b576a95d4b6a8ee70e78ecaa34a7","c80227b65297408db3c88583a2291f7b","d55e7db195b44955b09e0f04598a3598","85e687ff32694c0aa1bedacf5b4bbf21","0982aa5f0748431e86626537055d9978"]},"id":"7Ms8N01X9MlZ","outputId":"331ae2b5-3110-47bb-e7a1-01240b6cab7c","execution":{"iopub.status.busy":"2023-07-08T21:03:59.908602Z","iopub.execute_input":"2023-07-08T21:03:59.909017Z","iopub.status.idle":"2023-07-08T21:04:02.768702Z","shell.execute_reply.started":"2023-07-08T21:03:59.908978Z","shell.execute_reply":"2023-07-08T21:04:02.767676Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"new_tokens = ['<H>', '<R>', '<T>']\nnew_tokens_vocab = {}\nnew_tokens_vocab['additional_special_tokens'] = []\nfor idx, t in enumerate(new_tokens):\n    new_tokens_vocab['additional_special_tokens'].append(t)\nnum_added_toks = tokenizer.add_special_tokens(new_tokens_vocab)\n\ntokenizer.add_tokens(\"[MASK]\")\ntokenizer.mask_token = \"[MASK]\"\ntokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T21:04:02.770918Z","iopub.execute_input":"2023-07-08T21:04:02.771537Z","iopub.status.idle":"2023-07-08T21:04:02.779890Z","shell.execute_reply.started":"2023-07-08T21:04:02.771501Z","shell.execute_reply":"2023-07-08T21:04:02.778783Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class WebNLGDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        self.prefix = \"translate from Graph to Text: \"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        # preprocess the input graph\n        try:\n            triples = item['modified_triple_sets']['mtriple_set']\n            input_text = self.prefix\n            for outer_list in triples: \n                for triple in outer_list:\n                    triple_txt = triple.split(\"|\")\n                    input_text += \" <H> \" + triple_txt[0] + \" <R> \" + triple_txt[1] + \" <T> \" + triple_txt[2]\n        except (KeyError, IndexError):\n            print(\"1\")\n            print(item['modified_triple_sets']['mtriple_set'])\n            print(item['modified_triple_sets']['mtriple_set'][0])\n            print(triples)\n            input_text = self.prefix\n        # preprocess the target text\n        try:\n            target_text = item['lex']['text'][0]\n        except (KeyError, IndexError):\n            print(\"2\")\n            print(item)\n            #print(item['modified_triple_sets']['mtriple_set'])\n            target_text = \"\"\n        #print(item)\n        #print(input_text)\n        # encode the inputs and targets using the tokenizer\n        input_ids = tokenizer.encode(input_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        target_ids = tokenizer.encode(target_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        return input_ids.squeeze(0), target_ids.squeeze(0)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T21:04:02.781348Z","iopub.execute_input":"2023-07-08T21:04:02.782351Z","iopub.status.idle":"2023-07-08T21:04:02.796300Z","shell.execute_reply.started":"2023-07-08T21:04:02.782314Z","shell.execute_reply":"2023-07-08T21:04:02.795456Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"MAX_INPUT_LENGTH = 128\nMAX_TARGET_LENGTH = 128\ntokenizer.model_max_length = MAX_INPUT_LENGTH\nmodel.module.config.max_length = MAX_TARGET_LENGTH\n\n# set up the device (GPU or CPU)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1jjIPRO9Mla","outputId":"c138f2cb-2966-4872-ac87-616a2d4119d1","_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-07-08T21:04:02.799468Z","iopub.execute_input":"2023-07-08T21:04:02.799949Z","iopub.status.idle":"2023-07-08T21:04:02.906024Z","shell.execute_reply.started":"2023-07-08T21:04:02.799913Z","shell.execute_reply":"2023-07-08T21:04:02.904905Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): T5ForConditionalGeneration(\n    (shared): Embedding(32128, 512)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 512)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=384, bias=False)\n                (k): Linear(in_features=512, out_features=384, bias=False)\n                (v): Linear(in_features=512, out_features=384, bias=False)\n                (o): Linear(in_features=384, out_features=512, bias=False)\n                (relative_attention_bias): Embedding(32, 6)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n                (wo): Linear(in_features=1024, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-7): 7 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=384, bias=False)\n                (k): Linear(in_features=512, out_features=384, bias=False)\n                (v): Linear(in_features=512, out_features=384, bias=False)\n                (o): Linear(in_features=384, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n                (wo): Linear(in_features=1024, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (decoder): T5Stack(\n      (embed_tokens): Embedding(32128, 512)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=384, bias=False)\n                (k): Linear(in_features=512, out_features=384, bias=False)\n                (v): Linear(in_features=512, out_features=384, bias=False)\n                (o): Linear(in_features=384, out_features=512, bias=False)\n                (relative_attention_bias): Embedding(32, 6)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=384, bias=False)\n                (k): Linear(in_features=512, out_features=384, bias=False)\n                (v): Linear(in_features=512, out_features=384, bias=False)\n                (o): Linear(in_features=384, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n                (wo): Linear(in_features=1024, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-7): 7 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=384, bias=False)\n                (k): Linear(in_features=512, out_features=384, bias=False)\n                (v): Linear(in_features=512, out_features=384, bias=False)\n                (o): Linear(in_features=384, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=384, bias=False)\n                (k): Linear(in_features=512, out_features=384, bias=False)\n                (v): Linear(in_features=512, out_features=384, bias=False)\n                (o): Linear(in_features=384, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n                (wo): Linear(in_features=1024, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# load the WebNLG dataset\ndataset = load_dataset('web_nlg', 'release_v3.0_en')['train']\ndataset_val = load_dataset('web_nlg', 'release_v3.0_en')['dev']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["1af09f1f71524f44b3f79ed0427c8559","4027186c2a1646c7a47db3e69d3ef93b","c224ebc06fcf44dc80e8285b6578680e","f3f96e77a1134c5c93ba218b8261ec0f","45509cc5af034006bade5bff3fe9ea3b","7719bedd5d2544a38a46f058d0ef1a7e","305d7d10c879476ea87f924e2f802958","4731ce03cfa84014bce0054c8611b4f9","6af2a7876d954b93aca5a16930c9f079","528070b64e7d4bb0a891f1dbe89ae5bc","a99d41291bf84041a091180eb477e519"]},"id":"qEf48SzQ9Mla","outputId":"4c918f52-9562-4b13-f519-0f20efe57b2d","execution":{"iopub.status.busy":"2023-07-08T21:04:02.907644Z","iopub.execute_input":"2023-07-08T21:04:02.908095Z","iopub.status.idle":"2023-07-08T21:04:03.838070Z","shell.execute_reply.started":"2023-07-08T21:04:02.908062Z","shell.execute_reply":"2023-07-08T21:04:03.837120Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d080f7c2b9d4c34aa62be491bb057ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3e6ae2190664a35809549886b1d4fea"}},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch\nimport numpy as np\n\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), 'checkpoint.pt')\n        self.val_loss_min = val_loss\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T21:04:03.840513Z","iopub.execute_input":"2023-07-08T21:04:03.841198Z","iopub.status.idle":"2023-07-08T21:04:03.854387Z","shell.execute_reply.started":"2023-07-08T21:04:03.841162Z","shell.execute_reply":"2023-07-08T21:04:03.853320Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Adaptive pretraining","metadata":{}},{"cell_type":"markdown","source":"For STA, we fine-tuned the PLMs on a small amount of labeled data from the target task using a maximum likelihood estimation (MLE) objective. This involves training the model to maximize the likelihood of generating the correct output given the input graph and labeled data. This process helps to further adapt the PLM to the specific requirements of the target task and improve its performance on that task.","metadata":{}},{"cell_type":"code","source":"import random\n\npretrain_batch_size = 60\n\npretrain_texts = []\nfor sample in dataset:\n    try:\n        text = sample['lex']['text'][0]\n        pretrain_texts.append(text)\n    except (KeyError, IndexError):\n        continue\n\ntokenized_inputs = tokenizer(pretrain_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\ninput_ids = tokenized_inputs['input_ids']\nattention_mask = tokenized_inputs['attention_mask']\n\npretrain_data = torch.utils.data.TensorDataset(input_ids, attention_mask)\n\npretrain_loader = torch.utils.data.DataLoader(pretrain_data, batch_size=pretrain_batch_size, shuffle=True)\n\npretrain_optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\npretrain_criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n\npretrain_epochs = 20  # Set the number of pre-training epochs\nmasking_prob = 0.15  # Probability of masking a token\n\n\n# Prepare validation data\nval_texts = []\nfor sample in dataset_val:\n    try:\n        text = sample['lex']['text'][0]\n        val_texts.append(text)\n    except (KeyError, IndexError):\n        continue\n\ntokenized_inputs_val = tokenizer(val_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\ninput_ids_val = tokenized_inputs_val['input_ids']\nattention_mask_val = tokenized_inputs_val['attention_mask']\n\nval_data = TensorDataset(input_ids_val, attention_mask_val)\n\nval_loader = DataLoader(val_data, batch_size=pretrain_batch_size, shuffle=True)\n\nearly_stopping = EarlyStopping(patience=2, verbose=True)\n\nif tokenizer.mask_token is None:\n    # Manually set a mask token if not already defined\n    tokenizer.add_tokens(\"[MASK]\")\n    tokenizer.mask_token = \"[MASK]\"\n    tokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n\nfor epoch in range(pretrain_epochs):\n    running_loss = 0.0\n    for inputs, attention_mask in pretrain_loader:\n        inputs = inputs.to(device)\n        attention_mask = attention_mask.to(device)\n        batch_size, seq_length = inputs.shape\n        \n        # Create a mask for randomly selected tokens\n        mask = torch.rand(inputs.shape) < masking_prob\n        \n        # Randomly replace selected tokens with [MASK] token\n        masked_inputs = inputs.clone()\n        masked_inputs[mask] = tokenizer.mask_token_id\n        \n        pretrain_optimizer.zero_grad()\n        outputs = model(input_ids=masked_inputs, attention_mask=attention_mask, decoder_input_ids=inputs)\n        \n        # Compute the loss only for the masked tokens\n        masked_logits = outputs.logits[mask]\n        masked_labels = inputs[mask]\n        loss = pretrain_criterion(masked_logits.view(-1, masked_logits.size(-1)), masked_labels.view(-1))\n        \n        loss.backward()\n        pretrain_optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    \n    epoch_loss = running_loss / len(pretrain_data)\n    print(f\"Pretrain Epoch {epoch+1}/{pretrain_epochs} - loss: {epoch_loss:.4f}\")\n    \n    # Validation\n    model.eval()\n    val_running_loss = 0.0\n    for val_inputs, val_attention_mask in val_loader:\n        val_inputs = val_inputs.to(device)\n        val_attention_mask = val_attention_mask.to(device)\n        batch_size, seq_length = val_inputs.shape\n\n        mask = torch.rand(val_inputs.shape) < masking_prob\n        masked_inputs = val_inputs.clone()\n        masked_inputs[mask] = tokenizer.mask_token_id\n\n        with torch.no_grad():\n            outputs = model(input_ids=masked_inputs, attention_mask=val_attention_mask, decoder_input_ids=val_inputs)\n            masked_logits = outputs.logits[mask]\n            masked_labels = val_inputs[mask]\n            val_loss = pretrain_criterion(masked_logits.view(-1, masked_logits.size(-1)), masked_labels.view(-1))\n\n        val_running_loss += val_loss.item() * val_inputs.size(0)\n\n    epoch_val_loss = val_running_loss / len(val_data)\n    print(f\"Val Epoch {epoch+1}/{pretrain_epochs} - loss: {epoch_val_loss:.4f}\")\n\n    early_stopping(epoch_val_loss, model)\n\n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T21:04:04.905481Z","iopub.execute_input":"2023-07-08T21:04:04.905856Z","iopub.status.idle":"2023-07-08T21:48:24.441624Z","shell.execute_reply.started":"2023-07-08T21:04:04.905824Z","shell.execute_reply":"2023-07-08T21:48:24.440553Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Pretrain Epoch 1/20 - loss: 2.1126\nVal Epoch 1/20 - loss: 0.3252\nValidation loss decreased (inf --> 0.325190).  Saving model ...\nPretrain Epoch 2/20 - loss: 0.1685\nVal Epoch 2/20 - loss: 0.0884\nValidation loss decreased (0.325190 --> 0.088390).  Saving model ...\nPretrain Epoch 3/20 - loss: 0.0598\nVal Epoch 3/20 - loss: 0.0425\nValidation loss decreased (0.088390 --> 0.042550).  Saving model ...\nPretrain Epoch 4/20 - loss: 0.0378\nVal Epoch 4/20 - loss: 0.0394\nValidation loss decreased (0.042550 --> 0.039399).  Saving model ...\nPretrain Epoch 5/20 - loss: 0.0241\nVal Epoch 5/20 - loss: 0.0207\nValidation loss decreased (0.039399 --> 0.020696).  Saving model ...\nPretrain Epoch 6/20 - loss: 0.0174\nVal Epoch 6/20 - loss: 0.0175\nValidation loss decreased (0.020696 --> 0.017505).  Saving model ...\nPretrain Epoch 7/20 - loss: 0.0139\nVal Epoch 7/20 - loss: 0.0126\nValidation loss decreased (0.017505 --> 0.012612).  Saving model ...\nPretrain Epoch 8/20 - loss: 0.0111\nVal Epoch 8/20 - loss: 0.0082\nValidation loss decreased (0.012612 --> 0.008195).  Saving model ...\nPretrain Epoch 9/20 - loss: 0.0096\nVal Epoch 9/20 - loss: 0.0084\nEarlyStopping counter: 1 out of 2\nPretrain Epoch 10/20 - loss: 0.0059\nVal Epoch 10/20 - loss: 0.0064\nValidation loss decreased (0.008195 --> 0.006446).  Saving model ...\nPretrain Epoch 11/20 - loss: 0.0093\nVal Epoch 11/20 - loss: 0.0067\nEarlyStopping counter: 1 out of 2\nPretrain Epoch 12/20 - loss: 0.0066\nVal Epoch 12/20 - loss: 0.0057\nValidation loss decreased (0.006446 --> 0.005660).  Saving model ...\nPretrain Epoch 13/20 - loss: 0.0058\nVal Epoch 13/20 - loss: 0.0079\nEarlyStopping counter: 1 out of 2\nPretrain Epoch 14/20 - loss: 0.0045\nVal Epoch 14/20 - loss: 0.0056\nValidation loss decreased (0.005660 --> 0.005635).  Saving model ...\nPretrain Epoch 15/20 - loss: 0.0033\nVal Epoch 15/20 - loss: 0.0036\nValidation loss decreased (0.005635 --> 0.003588).  Saving model ...\nPretrain Epoch 16/20 - loss: 0.0024\nVal Epoch 16/20 - loss: 0.0053\nEarlyStopping counter: 1 out of 2\nPretrain Epoch 17/20 - loss: 0.0019\nVal Epoch 17/20 - loss: 0.0039\nEarlyStopping counter: 2 out of 2\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/working/checkpoint.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-07-08T21:49:44.217017Z","iopub.execute_input":"2023-07-08T21:49:44.217387Z","iopub.status.idle":"2023-07-08T21:49:44.458938Z","shell.execute_reply.started":"2023-07-08T21:49:44.217358Z","shell.execute_reply":"2023-07-08T21:49:44.458000Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"For LMA, we first fine-tuned the PLMs on a small amount of task-specific data using a masked language modeling objective. This involves randomly masking some tokens in the input sequence and training the model to predict the masked tokens based on the context provided by the unmasked tokens. This process helps to adapt the PLM to the specific characteristics of the target task and improve its performance on that task.","metadata":{}},{"cell_type":"markdown","source":"# Finetuning","metadata":{}},{"cell_type":"code","source":"# set up the data loader\ntrain_data = WebNLGDataset(dataset)\nbatch_size = 32 #16\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n\nval_data = load_dataset('web_nlg', 'release_v3.0_en')['dev']\nval_data = WebNLGDataset(val_data)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)","metadata":{"id":"pOfRTwjZ9Mla","execution":{"iopub.status.busy":"2023-07-08T21:49:48.553954Z","iopub.execute_input":"2023-07-08T21:49:48.554359Z","iopub.status.idle":"2023-07-08T21:49:49.125357Z","shell.execute_reply.started":"2023-07-08T21:49:48.554325Z","shell.execute_reply":"2023-07-08T21:49:49.124475Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6785e1d01d854853a5f7c5e1ce42ee4a"}},"metadata":{}}]},{"cell_type":"code","source":"# set up the optimizer and the loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4) #3e-5\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\nearly_stopping = EarlyStopping(patience=2, verbose=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T21:49:49.310910Z","iopub.execute_input":"2023-07-08T21:49:49.311589Z","iopub.status.idle":"2023-07-08T21:49:49.322269Z","shell.execute_reply.started":"2023-07-08T21:49:49.311549Z","shell.execute_reply":"2023-07-08T21:49:49.321192Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"num_epochs = 20\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, targets in train_loader:\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs, labels=targets)\n        loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), targets.view(-1))\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    epoch_loss = running_loss / len(train_data)\n    print(f\"Train loss: {epoch_loss:.4f}\")\n    \n    model.eval()\n    running_val_loss = 0.0\n    with torch.no_grad():\n        for val_inputs, val_targets in val_loader:\n            val_inputs = val_inputs.to(device)\n            val_targets = val_targets.to(device)\n            val_outputs = model(val_inputs, labels=val_targets)\n            val_loss = criterion(val_outputs.logits.view(-1, val_outputs.logits.size(-1)), val_targets.view(-1))\n            running_val_loss += val_loss.item() * val_inputs.size(0)\n    epoch_val_loss = running_val_loss / len(val_data)\n    print(f\"Val loss: {epoch_val_loss:.4f}\")\n    \n    early_stopping(epoch_val_loss, model)\n    \n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYG15tgj9Mla","outputId":"0e9adabd-0a23-4320-db12-8890b1a83361","execution":{"iopub.status.busy":"2023-07-08T21:49:53.159558Z","iopub.execute_input":"2023-07-08T21:49:53.159921Z","iopub.status.idle":"2023-07-08T22:47:17.440545Z","shell.execute_reply.started":"2023-07-08T21:49:53.159891Z","shell.execute_reply":"2023-07-08T22:47:17.439461Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Train loss: 1.1287\nVal loss: 0.7849\nValidation loss decreased (inf --> 0.784888).  Saving model ...\nTrain loss: 0.9147\nVal loss: 0.7324\nValidation loss decreased (0.784888 --> 0.732428).  Saving model ...\nTrain loss: 0.8472\nVal loss: 0.7179\nValidation loss decreased (0.732428 --> 0.717920).  Saving model ...\nTrain loss: 0.8017\nVal loss: 0.6881\nValidation loss decreased (0.717920 --> 0.688066).  Saving model ...\nTrain loss: 0.7659\nVal loss: 0.6740\nValidation loss decreased (0.688066 --> 0.673992).  Saving model ...\nTrain loss: 0.7373\nVal loss: 0.6628\nValidation loss decreased (0.673992 --> 0.662761).  Saving model ...\nTrain loss: 0.7107\nVal loss: 0.6637\nEarlyStopping counter: 1 out of 2\nTrain loss: 0.6907\nVal loss: 0.6525\nValidation loss decreased (0.662761 --> 0.652536).  Saving model ...\nTrain loss: 0.6719\nVal loss: 0.6430\nValidation loss decreased (0.652536 --> 0.643005).  Saving model ...\nTrain loss: 0.6532\nVal loss: 0.6424\nValidation loss decreased (0.643005 --> 0.642430).  Saving model ...\nTrain loss: 0.6383\nVal loss: 0.6384\nValidation loss decreased (0.642430 --> 0.638359).  Saving model ...\nTrain loss: 0.6246\nVal loss: 0.6372\nValidation loss decreased (0.638359 --> 0.637239).  Saving model ...\nTrain loss: 0.6097\nVal loss: 0.6311\nValidation loss decreased (0.637239 --> 0.631122).  Saving model ...\nTrain loss: 0.5976\nVal loss: 0.6290\nValidation loss decreased (0.631122 --> 0.628993).  Saving model ...\nTrain loss: 0.5839\nVal loss: 0.6310\nEarlyStopping counter: 1 out of 2\nTrain loss: 0.5723\nVal loss: 0.6340\nEarlyStopping counter: 2 out of 2\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/working/checkpoint.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-07-08T22:49:01.732226Z","iopub.execute_input":"2023-07-08T22:49:01.732745Z","iopub.status.idle":"2023-07-08T22:49:01.973297Z","shell.execute_reply.started":"2023-07-08T22:49:01.732704Z","shell.execute_reply":"2023-07-08T22:49:01.972311Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the entire model\ntorch.save(model, 'model_T5_flan_small_2020_v4')\nprint(\"Model saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T22:49:05.624380Z","iopub.execute_input":"2023-07-08T22:49:05.624769Z","iopub.status.idle":"2023-07-08T22:49:06.178519Z","shell.execute_reply.started":"2023-07-08T22:49:05.624739Z","shell.execute_reply":"2023-07-08T22:49:06.177485Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the model\n#model = torch.load('/kaggle/input/models/model_T5_flan_small_multi')\n\n# Print a confirmation message\nprint(\"Model loaded successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T14:36:05.231909Z","iopub.execute_input":"2023-07-05T14:36:05.232475Z","iopub.status.idle":"2023-07-05T14:36:07.655113Z","shell.execute_reply.started":"2023-07-05T14:36:05.232431Z","shell.execute_reply":"2023-07-05T14:36:07.654022Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model loaded successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## are we accounting for the multiple texts targets in the bleu? it doesn't look like it","metadata":{}},{"cell_type":"code","source":"!pip install sacrebleu\nbatch_size=32","metadata":{"execution":{"iopub.status.busy":"2023-07-08T22:49:42.461233Z","iopub.execute_input":"2023-07-08T22:49:42.462183Z","iopub.status.idle":"2023-07-08T22:49:54.538838Z","shell.execute_reply.started":"2023-07-08T22:49:42.462146Z","shell.execute_reply":"2023-07-08T22:49:54.537582Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.3.1)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2.7.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.5.5)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_bleu\nfrom random import sample\nfrom tqdm import tqdm\n\n\n# load the WebNLG validation dataset\nvalidation_dataset = load_dataset('web_nlg', 'release_v3.0_en')['test']\nvalidation_dataset = [sample for sample in validation_dataset if sample['lex']['text']] # filter out samples with empty targets \n# Select a subset of the validation dataset\n#subset_size = 10  # Choose the desired subset size\n#validation_subset = sample(list(validation_dataset), subset_size)\nvalidation_data = WebNLGDataset(validation_dataset)\n\n# set up the validation data loader\nvalidation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n\n# switch model to evaluation mode\nmodel.eval()\n\n# generate predictions for the validation dataset\npredictions = []\nreferences = []\nwith torch.no_grad():\n    for inputs, targets in tqdm(validation_loader, desc='Validation Progress', leave=False):\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        outputs = model.module.generate(inputs, max_length=MAX_TARGET_LENGTH, num_beams=4)\n        # convert token IDs to strings\n        predicted_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        target_texts = tokenizer.batch_decode(targets, skip_special_tokens=True)\n        # append predicted and target texts for BLEU evaluation\n        predictions.extend(predicted_texts)\n        references.extend(target_texts)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T22:49:54.542563Z","iopub.execute_input":"2023-07-08T22:49:54.542918Z","iopub.status.idle":"2023-07-08T22:55:26.295036Z","shell.execute_reply.started":"2023-07-08T22:49:54.542886Z","shell.execute_reply":"2023-07-08T22:55:26.293965Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"948c07f4b52c4f4f897c61b0db4627ef"}},"metadata":{}},{"name":"stderr","text":"                                                                      \r","output_type":"stream"}]},{"cell_type":"code","source":"# Writing predictions to a .txt file\nwith open(\"predictions\", \"w\") as f:\n    for prediction in predictions:\n        f.write(prediction + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T22:55:26.296854Z","iopub.execute_input":"2023-07-08T22:55:26.297553Z","iopub.status.idle":"2023-07-08T22:55:26.307690Z","shell.execute_reply.started":"2023-07-08T22:55:26.297516Z","shell.execute_reply":"2023-07-08T22:55:26.306756Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# calculate BLEU scores\n#bleu = corpus_bleu(predictions, [references])\n\nmultiple_references = []\nfor i in range(len(validation_dataset)):\n    multiple_references.append(validation_dataset[i]['lex']['text'])\n    \nbleu = corpus_bleu(predictions, references)\nbleu_multiple = corpus_bleu(predictions, multiple_references)\n\nprint(f\"BLEU score: {bleu.score}\")\nprint(f\"BLEU score with multiple references: {bleu_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T22:55:26.310194Z","iopub.execute_input":"2023-07-08T22:55:26.311584Z","iopub.status.idle":"2023-07-08T22:55:27.799090Z","shell.execute_reply.started":"2023-07-08T22:55:26.311558Z","shell.execute_reply":"2023-07-08T22:55:27.797929Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"BLEU score: 0.1354638113124636\nBLEU score with multiple references: 94.149097734812\n","output_type":"stream"}]},{"cell_type":"code","source":"# Getting the maximum length of the sublists in multiple_references\nmax_length = max(len(sublist) for sublist in multiple_references)\n\n# Writing multiple_references to separate .txt files\nfor i in range(max_length):\n    with open(f\"references{i}\", \"w\") as f:\n        for ref_list in multiple_references:\n            # Writing the ith element if it exists, otherwise an empty line\n            if i < len(ref_list):\n                f.write(ref_list[i] + \"\\n\")\n            else:\n                f.write(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:41:02.553207Z","iopub.execute_input":"2023-07-08T20:41:02.554006Z","iopub.status.idle":"2023-07-08T20:41:02.573735Z","shell.execute_reply.started":"2023-07-08T20:41:02.553967Z","shell.execute_reply":"2023-07-08T20:41:02.572854Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# calculate BLEU scores\n#bleu = corpus_bleu(predictions, [references])\n\nmultiple_references = []\nfor i in range(len(validation_dataset)):\n    multiple_references.append(validation_dataset[i]['lex']['text'])\n    \n# First, determine the maximum length of sublists\nmax_len = max(len(refs) for refs in multiple_references)\n\n# Then pad all sublists to that length\npadded_references = [refs * (max_len // len(refs)) + refs[:max_len % len(refs)] for refs in multiple_references]\n    \nbleu = corpus_bleu(predictions, references)\nbleu_multiple = corpus_bleu(predictions, padded_references)\n\nprint(f\"BLEU score: {bleu.score}\")\nprint(f\"BLEU score with padded references: {bleu_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:39:08.784027Z","iopub.execute_input":"2023-07-05T00:39:08.784420Z","iopub.status.idle":"2023-07-05T00:39:12.491724Z","shell.execute_reply.started":"2023-07-05T00:39:08.784371Z","shell.execute_reply":"2023-07-05T00:39:12.489939Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"BLEU score: 0.16214501382472107\nBLEU score with padded references: 80.7204465338761\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric('sacrebleu')\n\n# First, determine the maximum length of sublists\nmax_len = max(len(refs) for refs in multiple_references)\n\n# Then pad all sublists to that length\npadded_references = [refs * (max_len // len(refs)) + refs[:max_len % len(refs)] for refs in multiple_references]\n\n# Now 'padded_references' is a list of lists, where each sublist has the same length.\n# We can now compute the SacreBLEU score.\n\n# Note the change in the compute line\nscore = metric.compute(predictions=predictions, references = padded_references)\n\nprint(f\"SacreBLEU score: {score['score']}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:39:29.889557Z","iopub.execute_input":"2023-07-05T00:39:29.889918Z","iopub.status.idle":"2023-07-05T00:39:34.151307Z","shell.execute_reply.started":"2023-07-05T00:39:29.889887Z","shell.execute_reply":"2023-07-05T00:39:34.149323Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3977d215683d4a51941b587a2cad1d1b"}},"metadata":{}},{"name":"stdout","text":"SacreBLEU score: 31.99615265661011\n","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_chrf\n# Calculate CHR F++ scores\nchrf = corpus_chrf(predictions, [references])\nchrf_multiple = corpus_chrf(predictions, multiple_references)\nprint(f\"CHR F++ score: {chrf.score}\")\nprint(f\"CHR F++ score with multiple references: {chrf_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:39:46.532954Z","iopub.execute_input":"2023-07-05T00:39:46.533322Z","iopub.status.idle":"2023-07-05T00:39:50.531546Z","shell.execute_reply.started":"2023-07-05T00:39:46.533289Z","shell.execute_reply":"2023-07-05T00:39:50.530539Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"CHR F++ score: 54.00287217727219\nCHR F++ score with multiple references: 77.50627157244912\n","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_chrf\n# Calculate CHR F++ scores\nchrf = corpus_chrf(predictions, [references])\nchrf_multiple = corpus_chrf(predictions, padded_references)\nprint(f\"CHR F++ score: {chrf.score}\")\nprint(f\"CHR F++ score with multiple references: {chrf_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:40:05.832831Z","iopub.execute_input":"2023-07-05T00:40:05.833194Z","iopub.status.idle":"2023-07-05T00:40:16.362275Z","shell.execute_reply.started":"2023-07-05T00:40:05.833163Z","shell.execute_reply":"2023-07-05T00:40:16.361205Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"CHR F++ score: 54.00287217727219\nCHR F++ score with multiple references: 70.48380146771281\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bert_score","metadata":{"execution":{"iopub.status.busy":"2023-07-08T20:48:24.676609Z","iopub.execute_input":"2023-07-08T20:48:24.677603Z","iopub.status.idle":"2023-07-08T20:48:37.431189Z","shell.execute_reply.started":"2023-07-08T20:48:24.677564Z","shell.execute_reply":"2023-07-08T20:48:37.429969Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.0.0)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.5.3)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.30.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.28.2)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.64.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.15.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.5.5)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.3.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2023.5.7)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert_score) (2023.6.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"### from datasets import load_metric\nimport numpy as np\n\n\nmetric = load_metric('bertscore')\n\nassert len(predictions) == len(references), \"The number of predictions and references should be the same.\"\n\n# Compute the score\nscore = metric.compute(predictions=predictions, references=references, lang='en')\n\nprint(f\"BERTScore: {np.mean(score['precision'])}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T22:55:27.800534Z","iopub.execute_input":"2023-07-08T22:55:27.800964Z","iopub.status.idle":"2023-07-08T22:56:19.535094Z","shell.execute_reply.started":"2023-07-08T22:55:27.800930Z","shell.execute_reply":"2023-07-08T22:56:19.533300Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"BERTScore: 0.9123497803803925\n","output_type":"stream"}]},{"cell_type":"code","source":"i=5\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:04:20.449276Z","iopub.execute_input":"2023-07-08T23:04:20.449703Z","iopub.status.idle":"2023-07-08T23:04:20.457088Z","shell.execute_reply.started":"2023-07-08T23:04:20.449672Z","shell.execute_reply":"2023-07-08T23:04:20.456098Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"[['Bootleg_Series_Volume_1:_The_Quine_Tapes | precededBy | Squeeze_(The_Velvet_Underground_album)', 'Squeeze_(The_Velvet_Underground_album) | followedBy | 1969:_The_Velvet_Underground_Live']]\n----\nThe book \"BoodlegSeries Volume 1: The Quiet Underground\" was preceded by \"Squeeze\", which was followed by \"1969: The Velvet Underground Live\" and \"Squeeze\".\n----\n['The album 1969: The Velvet Underground Live is preceded by the Velvet Underground album Squeeze, which was followed by The Quine Tapes.', 'The Velvet Underground album Bootleg Series Volume 1: The Quine Tapes was preceded by the album Squeeze, which was followed by the live album 1969: The Velvet Underground Live.', 'The Bootleg Series Volume I: The Quine Tapes is preceded by the Velvet Underground album Squeeze which was itself followed by the album 1969: The Velvet Underground Live.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=10\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:04:21.799926Z","iopub.execute_input":"2023-07-08T23:04:21.800300Z","iopub.status.idle":"2023-07-08T23:04:21.808347Z","shell.execute_reply.started":"2023-07-08T23:04:21.800269Z","shell.execute_reply":"2023-07-08T23:04:21.807316Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"[['Piotr_Hallmann | birthDate | 1987-08-25']]\n----\nPiotr Hallmann was born on the 25th of August 1987 and was born on the 25th of August 1987.\n----\n['Piotr Hallmann was born on August 25, 1987.', \"Piotr Hallmann's birthday is August 25th 1987.\", 'Piotr Hallmann was born on the 25th of August 1987.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=50\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:04:23.383025Z","iopub.execute_input":"2023-07-08T23:04:23.384148Z","iopub.status.idle":"2023-07-08T23:04:23.393529Z","shell.execute_reply.started":"2023-07-08T23:04:23.384105Z","shell.execute_reply":"2023-07-08T23:04:23.392252Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"[['Alan_Shepard | birthDate | \"1923-11-18\"', 'Alan_Shepard | deathPlace | California', 'Alan_Shepard | birthPlace | New_Hampshire', 'Alan_Shepard | mission | Apollo_14']]\n----\nAlan Shepard was born in New Hampshire on November 18th, 1923. He was a crew member of Apollo 14 and died in California. He was born in New Hampshire on November 18th, 1923.\n----\n['Alan Shepard was a crew member of Apollo 14 who was born November 18th, 1923, in New Hampshire and died in California.', 'Alan Shepard was born in New Hampshire on November 18, 1923. He was a crew member of Apollo 14, and died later on in California.', 'Alan Shepard was born on Nov 18, 1923 in New Hampshire, was a member of the Apollo 14 crew and died in California.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=0\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:04:26.341837Z","iopub.execute_input":"2023-07-08T23:04:26.342207Z","iopub.status.idle":"2023-07-08T23:04:26.348456Z","shell.execute_reply.started":"2023-07-08T23:04:26.342177Z","shell.execute_reply":"2023-07-08T23:04:26.347358Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"[['Estádio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca', 'Agremiação_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_Série_C', 'Campeonato_Brasileiro_Série_C | country | Brazil', 'Agremiação_Sportiva_Arapiraquense | nickname | \"\\'\\'Alvinegro\"', 'Agremiação_Sportiva_Arapiraquense | ground | Estádio_Municipal_Coaracy_da_Mata_Fonseca']]\n----\nEstádio Municipal Coaracy da Mata Fonseca is located in Arapiraca, Brazil. The club play in the Campeonato Brasileiro Série C league which is based in Brazil.\n----\n['Estádio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremiação Sportiva Arapiraquense in Arapiraca. Agremiação Sportiva Arapiraquense, nicknamed \"Alvinegro\", lay in the Campeonato Brasileiro Série C league from Brazil.', 'Estádio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremiação Sportiva Arapiraquense in Arapiraca. Alvinegro, the nickname of Agremiação Sportiva Arapiraquense, play in the Campeonato Brasileiro Série C league from Brazil.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=70\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:04:33.469878Z","iopub.execute_input":"2023-07-08T23:04:33.470293Z","iopub.status.idle":"2023-07-08T23:04:33.477364Z","shell.execute_reply.started":"2023-07-08T23:04:33.470259Z","shell.execute_reply":"2023-07-08T23:04:33.476070Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"[['Pontiac_Rageous | assembly | Michigan', 'Pontiac_Rageous | assembly | Detroit', 'Pontiac_Rageous | productionEndYear | 1997']]\n----\nPontiac Ridgeous was assembled in Michigan in the year 1997 and finished its production in the year 1997. It is located in Detroit and was involved in the production of the Pontiac Rigous.\n----\n['The Pontiac Rageous assembled in Michigan with assembly line in Detroit was last produced in 1997.', 'Ending its production in 1997, the Pontiac Rageous was assembled in Detroit, Michigan.', 'Ending in 1997, the Pontiac Rageous was assembled in Detroit, Michigan.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=130\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:04:43.770383Z","iopub.execute_input":"2023-07-08T23:04:43.770775Z","iopub.status.idle":"2023-07-08T23:04:43.776927Z","shell.execute_reply.started":"2023-07-08T23:04:43.770744Z","shell.execute_reply":"2023-07-08T23:04:43.775939Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"[['McVeagh_of_the_South_Seas | director | Harry_Carey_(actor_born_1878)', 'McVeagh_of_the_South_Seas | writer | Harry_Carey_(actor_born_1878)', 'McVeagh_of_the_South_Seas | producer | The_Progressive_Motion_Picture_Company']]\n----\nThe producer of McVeagh of the South Seas is The Progressive Movement Pictures Company. McVeagh of the South Seas was created by Harry Reid, who was born in 1888. McVeagh of the South Seas was created by The Progressive Movement Pictures Company.\n----\n['\"McVeagh of the South Seas\" was written and directed by Harry Carey born in 1878 and produced by Progressive Motion Picture Company.', 'Harry Carey, an actor born in 1878, was the director and writer for the film McVeagh of the South Seas which was produced by the Progressive Motion Picture Company.', 'Harry Carey, an actor and director, was born in 1878. He was the writer of the movie McVeagh of the South Seas, which was produced by the Progressive Motion Picture Company. As well as writing the film script, Carey also acted a role in the movie, and directed it.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=1861\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:05:13.101749Z","iopub.execute_input":"2023-07-08T23:05:13.102200Z","iopub.status.idle":"2023-07-08T23:05:13.114545Z","shell.execute_reply.started":"2023-07-08T23:05:13.102160Z","shell.execute_reply":"2023-07-08T23:05:13.113492Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"[['Akeem_Ayers | currentteam | \"Los Angeles Rams\"', 'Akeem_Ayers | debutTeam | Tennessee_Titans']]\n----\nAkeem Ayers made his debut for the Tennessee Titans and played for the Los Angeles Rams. He has also played for the Los Angeles Rams and the Los Angeles Rams.\n----\n['Akeem Ayers made his debut for the Tennessee Titans and currently plays for the Los Angeles Rams.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=1860\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:05:21.718774Z","iopub.execute_input":"2023-07-08T23:05:21.719149Z","iopub.status.idle":"2023-07-08T23:05:21.725239Z","shell.execute_reply.started":"2023-07-08T23:05:21.719118Z","shell.execute_reply":"2023-07-08T23:05:21.724231Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"[['Turn_Me_On_(album) | runtime | 35.1', 'Turn_Me_On_(album) | artist | The_Honeymoon_Killers_(American_band)', 'Turn_Me_On_(album) | genre | Punk_blues', 'Turn_Me_On_(album) | producer | The_Honeymoon_Killers_(American_band)', 'Turn_Me_On_(album) | genre | Noise_rock', 'Turn_Me_On_(album) | precededBy | Let_It_Breed']]\n----\nThe rapper, The Honeymoon Millers, is a performer of the Punk Blues. It was produced by The Honeymoon Millers and has a run time of 35.1 minutes.\n----\n['Turn Me On by the Honeymoon Killers is a punk blues album in the noise rock genre. The run time is 35.1 minutes and was preceded by the Let it Breed album.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=-10\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:05:37.675844Z","iopub.execute_input":"2023-07-08T23:05:37.676204Z","iopub.status.idle":"2023-07-08T23:05:37.682796Z","shell.execute_reply.started":"2023-07-08T23:05:37.676174Z","shell.execute_reply":"2023-07-08T23:05:37.681804Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"[['McVeagh_of_the_South_Seas | imdbId | 0004319', 'McVeagh_of_the_South_Seas | director | Cyril_Bruce', 'McVeagh_of_the_South_Seas | director | Harry_Carey_(actor_born_1878)', 'McVeagh_of_the_South_Seas | starring | Harry_Carey_(actor_born_1878)', 'McVeagh_of_the_South_Seas | writer | Harry_Carey_(actor_born_1878)', 'McVeagh_of_the_South_Seas | producer | The_Progressive_Motion_Picture_Company']]\n----\nCyril Bruce and Harry Carey stars in McVeagh of the South Seas. McVeagh of the South Seas was created by Cyril Bruce and was starred by Harry Carey. McVeagh of the South Seas was created by Cyril Bruce and was starred by Cyril Bruce.\n----\n['Actor Harry Carey, born in 1878, and Cyril Bruce directed McVeagh of the South Seas which was registered in IMDb with the ID 0004319. Harry Carey also wrote and acted in the movie which was produced by the Progressive Motion Picture Company.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=-9\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:05:39.314145Z","iopub.execute_input":"2023-07-08T23:05:39.314606Z","iopub.status.idle":"2023-07-08T23:05:39.321830Z","shell.execute_reply.started":"2023-07-08T23:05:39.314573Z","shell.execute_reply":"2023-07-08T23:05:39.320525Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"[['Mermaid_(Train_song) | recordLabel | Columbia_Records', 'Mermaid_(Train_song) | recordLabel | Sony_Music_Entertainment', \"Mermaid_(Train_song) | precededBy | This'll_Be_My_Year\", 'Mermaid_(Train_song) | runtime | 3.16', 'Mermaid_(Train_song) | genre | Reggae']]\n----\nMermaid is a musical sequel to This'll Be My Year and was recorded by Columbia Records. It has a run time of 3.16 and was preceded by This'll Be My Year.\n----\n['The Train song Mermaid is a 3.16 minute song in the reggae genre which is on Columbia Records. It had been released under the Sony Music Entertainment label and was preceded by \"This\\'ll Be my Year.\"']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=-5\nprint(validation_dataset[i]['modified_triple_sets']['mtriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:05:40.956037Z","iopub.execute_input":"2023-07-08T23:05:40.956777Z","iopub.status.idle":"2023-07-08T23:05:40.962461Z","shell.execute_reply.started":"2023-07-08T23:05:40.956739Z","shell.execute_reply":"2023-07-08T23:05:40.961478Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"[['Trane | type | Subsidiary', 'Trane | foundingDate | 1913-01-01', 'Trane | location | Ireland', 'Trane | foundationPlace | La_Crosse,_Wisconsin', 'Trane | numberOfEmployees | 29000', 'Trane | product | HVAC', 'Trane | industry | Building_materials']]\n----\nTrane was founded in La Crosse, Wisconsin on January 1, 1913. Trane is a subsidiary company in the building materials industry. Trane was founded on January 1, 1913 in La Crosse, Wisconsin. Trane is a subsidiary company in the building materials industry. Trane is a subsidiary company in the building materials industry.\n----\n['Trane is a subsidiary company that was founded in La Crosse, Wisconsin on 1913-01-01 but later moved to Ireland. Their 29,000 employees produce building materials, prominent among which are HVAC products.']\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import T5Tokenizer\nfrom datasets import load_dataset\n\n# Define the tokenizer\n#tokenizer = T5Tokenizer.from_pretrained('t5-small')\n\n# Load the WebNLG dataset\ndataset = load_dataset('web_nlg', 'release_v3.0_en')['test']\ndataset = [sample for sample in dataset if sample['lex']['text']]\n\n# Create an instance of WebNLGDataset\nwebnlg_dataset = WebNLGDataset(dataset)\n\n# Define the index of the example you want to test\nexample_index = 70\n\n# Get the input and target texts for the example at the specified index\ninput_text, target_text = webnlg_dataset[example_index]\n\n# Decode the input and target texts using the tokenizer\ndecoded_input_text = tokenizer.decode(input_text, skip_special_tokens=True)\ndecoded_target_text = tokenizer.decode(target_text, skip_special_tokens=True)\n\n# Print the preprocessed input and target texts\nprint(\"Input Text:\", decoded_input_text)\nprint(\"Target Text:\", decoded_target_text)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:36:30.294773Z","iopub.execute_input":"2023-05-19T18:36:30.295189Z","iopub.status.idle":"2023-05-19T18:36:31.861708Z","shell.execute_reply.started":"2023-05-19T18:36:30.295152Z","shell.execute_reply":"2023-05-19T18:36:31.860533Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b598640a8aaf4538bace35a707a4555e"}},"metadata":{}},{"name":"stdout","text":"{'category': 'MeanOfTransportation', 'size': 1, 'eid': 'Id71', 'original_triple_sets': {'otriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema'], ['Alfa_Romeo_164 | related | Lancia_Thema']]}, 'modified_triple_sets': {'mtriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Alfa Romeo 164 and Lancia Thema are related types of transportation.', 'The related transport to the Alfa Romeo 164 is the Lancia Thema.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\ntranslate from Graph to Text:  <H> Alfa_Romeo_164  <R>  relatedMeanOfTransportation  <T>  Lancia_Thema <H> Alfa_Romeo_164  <R>  related  <T>  Lancia_Thema\nInput Text: translate from Graph to Text: Alfa_Romeo_164 relatedMeanOfTransportation Lancia_Thema Alfa_Romeo_164 related Lancia_Thema\nTarget Text: Alfa Romeo 164 and Lancia Thema are related types of transportation.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## seeing how many empty targets there are in the testing set","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('web_nlg', 'release_v3.0_en')['test']\ncount_empty_text = 0\nfor sample in dataset:\n    if not sample['lex']['text']:\n        count_empty_text += 1\n\nprint(f\"Number of samples with empty 'lex' 'text' field: {count_empty_text}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:48:18.862931Z","iopub.execute_input":"2023-05-18T18:48:18.863745Z","iopub.status.idle":"2023-05-18T18:48:20.403634Z","shell.execute_reply.started":"2023-05-18T18:48:18.863701Z","shell.execute_reply":"2023-05-18T18:48:20.402308Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2dc9ec2d9f4cc5a3473a3a50d95272"}},"metadata":{}},{"name":"stdout","text":"Number of samples with empty 'lex' 'text' field: 1862\n","output_type":"stream"}]},{"cell_type":"code","source":"total_samples = len(dataset)\nprint(f\"Total number of samples in the test dataset: {total_samples}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:48:20.405561Z","iopub.execute_input":"2023-05-18T18:48:20.405994Z","iopub.status.idle":"2023-05-18T18:48:20.412699Z","shell.execute_reply.started":"2023-05-18T18:48:20.405940Z","shell.execute_reply":"2023-05-18T18:48:20.411048Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Total number of samples in the test dataset: 4615\n","output_type":"stream"}]}]}