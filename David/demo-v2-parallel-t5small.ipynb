{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"2a8badda5171f6c1da75e6dcec216359e8635e393e06f848b1b87b76c1bdea5e"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"27dac6771009442986c337835ac2fab0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81ab3401681e449faca4585337346d4a","IPY_MODEL_ac24b2b5a91b48e6a8746e3e0a6bdd56","IPY_MODEL_099b3ea61045469caa5684f5d4b5fa38"],"layout":"IPY_MODEL_d41d0e0245a142589c8f5767ce8e0d3b"}},"81ab3401681e449faca4585337346d4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e466a23c1954b84bd29cee2299101b5","placeholder":"​","style":"IPY_MODEL_094afeea467543ae879be701e4a73d63","value":"100%"}},"ac24b2b5a91b48e6a8746e3e0a6bdd56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa9427c68daf40d3af8410141bfe94b3","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6dfc55f38ffe49e59ccb600b0de75088","value":3}},"099b3ea61045469caa5684f5d4b5fa38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec91a1ad9e7b4bafbc79f9ddfaa0296e","placeholder":"​","style":"IPY_MODEL_4cec0b2d487b4c13ad153e6924cc8e4a","value":" 3/3 [00:00&lt;00:00, 65.75it/s]"}},"d41d0e0245a142589c8f5767ce8e0d3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e466a23c1954b84bd29cee2299101b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"094afeea467543ae879be701e4a73d63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa9427c68daf40d3af8410141bfe94b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dfc55f38ffe49e59ccb600b0de75088":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec91a1ad9e7b4bafbc79f9ddfaa0296e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cec0b2d487b4c13ad153e6924cc8e4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1af09f1f71524f44b3f79ed0427c8559":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4027186c2a1646c7a47db3e69d3ef93b","IPY_MODEL_c224ebc06fcf44dc80e8285b6578680e","IPY_MODEL_f3f96e77a1134c5c93ba218b8261ec0f"],"layout":"IPY_MODEL_45509cc5af034006bade5bff3fe9ea3b"}},"4027186c2a1646c7a47db3e69d3ef93b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7719bedd5d2544a38a46f058d0ef1a7e","placeholder":"​","style":"IPY_MODEL_305d7d10c879476ea87f924e2f802958","value":"100%"}},"c224ebc06fcf44dc80e8285b6578680e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4731ce03cfa84014bce0054c8611b4f9","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6af2a7876d954b93aca5a16930c9f079","value":3}},"f3f96e77a1134c5c93ba218b8261ec0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_528070b64e7d4bb0a891f1dbe89ae5bc","placeholder":"​","style":"IPY_MODEL_a99d41291bf84041a091180eb477e519","value":" 3/3 [00:00&lt;00:00, 106.45it/s]"}},"45509cc5af034006bade5bff3fe9ea3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7719bedd5d2544a38a46f058d0ef1a7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"305d7d10c879476ea87f924e2f802958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4731ce03cfa84014bce0054c8611b4f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af2a7876d954b93aca5a16930c9f079":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"528070b64e7d4bb0a891f1dbe89ae5bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99d41291bf84041a091180eb477e519":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d15948f114040928a325e1665e0b1bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9aa2a3f7d6ec414cb6bc735391cc7462","IPY_MODEL_a72bd5b05ddc4e20bd777a1e51bff87f","IPY_MODEL_45e968b74fdc440382f08bfe83797d7f"],"layout":"IPY_MODEL_27829187a83e45859d0adf6deb1a5f12"}},"9aa2a3f7d6ec414cb6bc735391cc7462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01cfd32ca9ea4e54a1bff6119613d64a","placeholder":"​","style":"IPY_MODEL_abcb191fcc264867b122d58caf9e3652","value":"Downloading (…)ve/main/spiece.model: 100%"}},"a72bd5b05ddc4e20bd777a1e51bff87f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1375be65005469a9c05fb385f1597db","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_194bc9079f024606b19ed153cd2d2226","value":791656}},"45e968b74fdc440382f08bfe83797d7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccf95078f5474a8a9917dc95c2d296df","placeholder":"​","style":"IPY_MODEL_8c955109118d4ffcb3b5b9db8520eb2a","value":" 792k/792k [00:00&lt;00:00, 3.16MB/s]"}},"27829187a83e45859d0adf6deb1a5f12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01cfd32ca9ea4e54a1bff6119613d64a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abcb191fcc264867b122d58caf9e3652":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1375be65005469a9c05fb385f1597db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"194bc9079f024606b19ed153cd2d2226":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccf95078f5474a8a9917dc95c2d296df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c955109118d4ffcb3b5b9db8520eb2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"836b768308904b9e98965838df6d56cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c26f17223f9049fabbeeef900dc0f084","IPY_MODEL_096b9fdf24f44aedaa16e9f31bff5e74","IPY_MODEL_3f2e2e165fcf4575bfd2127e0f392e0d"],"layout":"IPY_MODEL_511bf71170c94239b561c6ed9c7a2014"}},"c26f17223f9049fabbeeef900dc0f084":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e0a091ca3f743b599684ec709c0724d","placeholder":"​","style":"IPY_MODEL_7f042786107f41a5be4dffec5461e220","value":"Downloading (…)lve/main/config.json: 100%"}},"096b9fdf24f44aedaa16e9f31bff5e74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98782b2ca67b42eabe9128090a4f3eec","max":1206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b61db7dc7854a6da1f96c46dfbdf72c","value":1206}},"3f2e2e165fcf4575bfd2127e0f392e0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a85ddf4d0fdf44ba815ca3f03b476407","placeholder":"​","style":"IPY_MODEL_46f3784588fe467cbddcf6e15bfcaa82","value":" 1.21k/1.21k [00:00&lt;00:00, 21.9kB/s]"}},"511bf71170c94239b561c6ed9c7a2014":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e0a091ca3f743b599684ec709c0724d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f042786107f41a5be4dffec5461e220":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98782b2ca67b42eabe9128090a4f3eec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b61db7dc7854a6da1f96c46dfbdf72c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a85ddf4d0fdf44ba815ca3f03b476407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f3784588fe467cbddcf6e15bfcaa82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76ea121789c34ab0ae3db2a11ce092dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0755e20e9e894e0782a6dc013944a602","IPY_MODEL_16d5d7274b774723913d9a9df040db90","IPY_MODEL_ca6af7cc25b745999b2e819972a5794c"],"layout":"IPY_MODEL_46a8ce2527bb48088f5a414f6df0ee73"}},"0755e20e9e894e0782a6dc013944a602":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed369610f713419fae0a9c26abee2b91","placeholder":"​","style":"IPY_MODEL_fe46615805e146788d96ca94f066fd87","value":"Downloading pytorch_model.bin: 100%"}},"16d5d7274b774723913d9a9df040db90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15c2f29bfa54944989bf35497436615","max":242065649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c7e7ef1e3a34c228e0972f094716cef","value":242065649}},"ca6af7cc25b745999b2e819972a5794c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2766052cd6cd43288677e89f524222aa","placeholder":"​","style":"IPY_MODEL_c1326237db9f4a39bb312b80678be410","value":" 242M/242M [00:01&lt;00:00, 240MB/s]"}},"46a8ce2527bb48088f5a414f6df0ee73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed369610f713419fae0a9c26abee2b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe46615805e146788d96ca94f066fd87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f15c2f29bfa54944989bf35497436615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c7e7ef1e3a34c228e0972f094716cef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2766052cd6cd43288677e89f524222aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1326237db9f4a39bb312b80678be410":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2bd17acda9f4a4cb40387e7a16a4aad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34b7d58e7c434652ab4a9f4cecef0791","IPY_MODEL_c406fb3d9ff8428da7b08d1dbf76e81a","IPY_MODEL_ceff9ff6affd4f168cff5c526d56fcd7"],"layout":"IPY_MODEL_13c9318a176f42ecac5d6162d510395f"}},"34b7d58e7c434652ab4a9f4cecef0791":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99ea585e29ff4e2a966d1c69be32cb97","placeholder":"​","style":"IPY_MODEL_1f85b576a95d4b6a8ee70e78ecaa34a7","value":"Downloading (…)neration_config.json: 100%"}},"c406fb3d9ff8428da7b08d1dbf76e81a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c80227b65297408db3c88583a2291f7b","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d55e7db195b44955b09e0f04598a3598","value":147}},"ceff9ff6affd4f168cff5c526d56fcd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85e687ff32694c0aa1bedacf5b4bbf21","placeholder":"​","style":"IPY_MODEL_0982aa5f0748431e86626537055d9978","value":" 147/147 [00:00&lt;00:00, 2.48kB/s]"}},"13c9318a176f42ecac5d6162d510395f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99ea585e29ff4e2a966d1c69be32cb97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f85b576a95d4b6a8ee70e78ecaa34a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c80227b65297408db3c88583a2291f7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d55e7db195b44955b09e0f04598a3598":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85e687ff32694c0aa1bedacf5b4bbf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0982aa5f0748431e86626537055d9978":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install datasets\n\n!pip install transformers \n!pip install sentencepiece\n\n!pip install sacrebleu\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahHaXoNB9iBc","outputId":"7a29568e-467f-4334-b715-11bd6c8b649d","execution":{"iopub.status.busy":"2023-05-22T12:47:36.829876Z","iopub.execute_input":"2023-05-22T12:47:36.830862Z","iopub.status.idle":"2023-05-22T12:48:25.091760Z","shell.execute_reply.started":"2023-05-22T12:47:36.830826Z","shell.execute_reply":"2023-05-22T12:48:25.090555Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.13.4)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (10.0.1)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.4.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.98)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting sacrebleu\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nCollecting portalocker\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.3.23)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.7.0 sacrebleu-2.3.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom torch.nn.parallel import DataParallel\n\n# define the tokenizer and model\ntokenizer = T5Tokenizer.from_pretrained('t5-small')\nmodel = T5ForConditionalGeneration.from_pretrained('t5-small')\nmodel = DataParallel(model)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255,"referenced_widgets":["0d15948f114040928a325e1665e0b1bc","9aa2a3f7d6ec414cb6bc735391cc7462","a72bd5b05ddc4e20bd777a1e51bff87f","45e968b74fdc440382f08bfe83797d7f","27829187a83e45859d0adf6deb1a5f12","01cfd32ca9ea4e54a1bff6119613d64a","abcb191fcc264867b122d58caf9e3652","a1375be65005469a9c05fb385f1597db","194bc9079f024606b19ed153cd2d2226","ccf95078f5474a8a9917dc95c2d296df","8c955109118d4ffcb3b5b9db8520eb2a","836b768308904b9e98965838df6d56cc","c26f17223f9049fabbeeef900dc0f084","096b9fdf24f44aedaa16e9f31bff5e74","3f2e2e165fcf4575bfd2127e0f392e0d","511bf71170c94239b561c6ed9c7a2014","3e0a091ca3f743b599684ec709c0724d","7f042786107f41a5be4dffec5461e220","98782b2ca67b42eabe9128090a4f3eec","6b61db7dc7854a6da1f96c46dfbdf72c","a85ddf4d0fdf44ba815ca3f03b476407","46f3784588fe467cbddcf6e15bfcaa82","76ea121789c34ab0ae3db2a11ce092dc","0755e20e9e894e0782a6dc013944a602","16d5d7274b774723913d9a9df040db90","ca6af7cc25b745999b2e819972a5794c","46a8ce2527bb48088f5a414f6df0ee73","ed369610f713419fae0a9c26abee2b91","fe46615805e146788d96ca94f066fd87","f15c2f29bfa54944989bf35497436615","8c7e7ef1e3a34c228e0972f094716cef","2766052cd6cd43288677e89f524222aa","c1326237db9f4a39bb312b80678be410","c2bd17acda9f4a4cb40387e7a16a4aad","34b7d58e7c434652ab4a9f4cecef0791","c406fb3d9ff8428da7b08d1dbf76e81a","ceff9ff6affd4f168cff5c526d56fcd7","13c9318a176f42ecac5d6162d510395f","99ea585e29ff4e2a966d1c69be32cb97","1f85b576a95d4b6a8ee70e78ecaa34a7","c80227b65297408db3c88583a2291f7b","d55e7db195b44955b09e0f04598a3598","85e687ff32694c0aa1bedacf5b4bbf21","0982aa5f0748431e86626537055d9978"]},"id":"7Ms8N01X9MlZ","outputId":"331ae2b5-3110-47bb-e7a1-01240b6cab7c","execution":{"iopub.status.busy":"2023-05-22T12:49:39.521150Z","iopub.execute_input":"2023-05-22T12:49:39.521580Z","iopub.status.idle":"2023-05-22T12:49:52.735391Z","shell.execute_reply.started":"2023-05-22T12:49:39.521545Z","shell.execute_reply":"2023-05-22T12:49:52.733999Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# define the tokenizer and model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacebook/bart-base\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/bart-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m DataParallel(model)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1795\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1789\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1790\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1792\u001b[0m     )\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1800\u001b[0m     )\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n","\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/bart-base'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/bart-base' is the correct path to a directory containing all relevant files for a T5Tokenizer tokenizer."],"ename":"OSError","evalue":"Can't load tokenizer for 'facebook/bart-base'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/bart-base' is the correct path to a directory containing all relevant files for a T5Tokenizer tokenizer.","output_type":"error"}]},{"cell_type":"code","source":"new_tokens = ['<H>', '<R>', '<T>']\nnew_tokens_vocab = {}\nnew_tokens_vocab['additional_special_tokens'] = []\nfor idx, t in enumerate(new_tokens):\n    new_tokens_vocab['additional_special_tokens'].append(t)\nnum_added_toks = tokenizer.add_special_tokens(new_tokens_vocab)\n\ntokenizer.add_tokens(\"[MASK]\")\ntokenizer.mask_token = \"[MASK]\"\ntokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:48:06.604021Z","iopub.execute_input":"2023-05-21T23:48:06.604769Z","iopub.status.idle":"2023-05-21T23:48:06.612644Z","shell.execute_reply.started":"2023-05-21T23:48:06.604731Z","shell.execute_reply":"2023-05-21T23:48:06.611604Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class WebNLGDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        self.prefix = \"translate from Graph to Text: \"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        # preprocess the input graph\n        try:\n            triples = item['original_triple_sets']['otriple_set']\n            input_text = self.prefix\n            for outer_list in triples: \n                for triple in outer_list:\n                    triple_txt = triple.split(\"|\")\n                    input_text += \" <H> \" + triple_txt[0] + \" <R> \" + triple_txt[1] + \" <T> \" + triple_txt[2]\n        except (KeyError, IndexError):\n            print(\"1\")\n            print(item['original_triple_sets']['otriple_set'])\n            print(item['original_triple_sets']['otriple_set'][0])\n            print(triples)\n            input_text = self.prefix\n        # preprocess the target text\n        try:\n            target_text = item['lex']['text'][0]\n        except (KeyError, IndexError):\n            print(\"2\")\n            print(item)\n            #print(item['original_triple_sets']['otriple_set'])\n            target_text = \"\"\n        #print(item)\n        #print(input_text)\n        # encode the inputs and targets using the tokenizer\n        input_ids = tokenizer.encode(input_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        target_ids = tokenizer.encode(target_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        return input_ids.squeeze(0), target_ids.squeeze(0)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:48:06.630740Z","iopub.execute_input":"2023-05-21T23:48:06.631495Z","iopub.status.idle":"2023-05-21T23:48:06.643177Z","shell.execute_reply.started":"2023-05-21T23:48:06.631455Z","shell.execute_reply":"2023-05-21T23:48:06.642091Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"MAX_INPUT_LENGTH = 128\nMAX_TARGET_LENGTH = 128\ntokenizer.model_max_length = MAX_INPUT_LENGTH\nmodel.module.config.max_length = MAX_TARGET_LENGTH\n\n# set up the device (GPU or CPU)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1jjIPRO9Mla","outputId":"c138f2cb-2966-4872-ac87-616a2d4119d1","_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-05-21T23:48:06.644788Z","iopub.execute_input":"2023-05-21T23:48:06.645311Z","iopub.status.idle":"2023-05-21T23:48:06.735641Z","shell.execute_reply.started":"2023-05-21T23:48:06.645278Z","shell.execute_reply":"2023-05-21T23:48:06.733611Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): T5ForConditionalGeneration(\n    (shared): Embedding(32128, 512)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 512)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=512, bias=False)\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): Linear(in_features=512, out_features=512, bias=False)\n                (o): Linear(in_features=512, out_features=512, bias=False)\n                (relative_attention_bias): Embedding(32, 8)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-5): 5 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=512, bias=False)\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): Linear(in_features=512, out_features=512, bias=False)\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (decoder): T5Stack(\n      (embed_tokens): Embedding(32128, 512)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=512, bias=False)\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): Linear(in_features=512, out_features=512, bias=False)\n                (o): Linear(in_features=512, out_features=512, bias=False)\n                (relative_attention_bias): Embedding(32, 8)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=512, bias=False)\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): Linear(in_features=512, out_features=512, bias=False)\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-5): 5 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=512, bias=False)\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): Linear(in_features=512, out_features=512, bias=False)\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=512, out_features=512, bias=False)\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): Linear(in_features=512, out_features=512, bias=False)\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# load the WebNLG dataset\ndataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['train']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["1af09f1f71524f44b3f79ed0427c8559","4027186c2a1646c7a47db3e69d3ef93b","c224ebc06fcf44dc80e8285b6578680e","f3f96e77a1134c5c93ba218b8261ec0f","45509cc5af034006bade5bff3fe9ea3b","7719bedd5d2544a38a46f058d0ef1a7e","305d7d10c879476ea87f924e2f802958","4731ce03cfa84014bce0054c8611b4f9","6af2a7876d954b93aca5a16930c9f079","528070b64e7d4bb0a891f1dbe89ae5bc","a99d41291bf84041a091180eb477e519"]},"id":"qEf48SzQ9Mla","outputId":"4c918f52-9562-4b13-f519-0f20efe57b2d","execution":{"iopub.status.busy":"2023-05-21T23:48:06.736969Z","iopub.execute_input":"2023-05-21T23:48:06.737921Z","iopub.status.idle":"2023-05-21T23:48:07.448124Z","shell.execute_reply.started":"2023-05-21T23:48:06.737885Z","shell.execute_reply":"2023-05-21T23:48:07.447225Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c784909247d427b9df58ca8b161f571"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Adaptive pretraining","metadata":{}},{"cell_type":"markdown","source":"For STA, we fine-tuned the PLMs on a small amount of labeled data from the target task using a maximum likelihood estimation (MLE) objective. This involves training the model to maximize the likelihood of generating the correct output given the input graph and labeled data. This process helps to further adapt the PLM to the specific requirements of the target task and improve its performance on that task.","metadata":{}},{"cell_type":"code","source":"import random\n\npretrain_texts = []\nfor sample in dataset:\n    try:\n        text = sample['lex']['text'][0]\n        pretrain_texts.append(text)\n    except (KeyError, IndexError):\n        continue\n\ntokenized_inputs = tokenizer(pretrain_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\ninput_ids = tokenized_inputs['input_ids']\nattention_mask = tokenized_inputs['attention_mask']\n\npretrain_data = torch.utils.data.TensorDataset(input_ids, attention_mask)\n\npretrain_loader = torch.utils.data.DataLoader(pretrain_data, batch_size=int(60), shuffle=True)\n\npretrain_optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\npretrain_criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n\npretrain_epochs = 2  # Set the number of pre-training epochs\nmasking_prob = 0.15  # Probability of masking a token\n\nif tokenizer.mask_token is None:\n    # Manually set a mask token if not already defined\n    tokenizer.add_tokens(\"[MASK]\")\n    tokenizer.mask_token = \"[MASK]\"\n    tokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n\nfor epoch in range(pretrain_epochs):\n    running_loss = 0.0\n    for inputs, attention_mask in pretrain_loader:\n        inputs = inputs.to(device)\n        attention_mask = attention_mask.to(device)\n        batch_size, seq_length = inputs.shape\n        \n        # Create a mask for randomly selected tokens\n        mask = torch.rand(inputs.shape) < masking_prob\n        \n        # Randomly replace selected tokens with [MASK] token\n        masked_inputs = inputs.clone()\n        masked_inputs[mask] = tokenizer.mask_token_id\n        \n        pretrain_optimizer.zero_grad()\n        outputs = model(input_ids=masked_inputs, attention_mask=attention_mask, decoder_input_ids=inputs)\n        \n        # Compute the loss only for the masked tokens\n        masked_logits = outputs.logits[mask]\n        masked_labels = inputs[mask]\n        loss = pretrain_criterion(masked_logits.view(-1, masked_logits.size(-1)), masked_labels.view(-1))\n        \n        loss.backward()\n        pretrain_optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    \n    epoch_loss = running_loss / len(pretrain_data)\n    print(f\"Pretrain Epoch {epoch+1}/{pretrain_epochs} - loss: {epoch_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:48:07.460657Z","iopub.execute_input":"2023-05-21T23:48:07.461388Z","iopub.status.idle":"2023-05-21T23:50:25.762889Z","shell.execute_reply.started":"2023-05-21T23:48:07.461320Z","shell.execute_reply":"2023-05-21T23:50:25.761836Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Pretrain Epoch 1/2 - loss: 2.0749\nPretrain Epoch 2/2 - loss: 0.2933\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For LMA, we first fine-tuned the PLMs on a small amount of task-specific data using a masked language modeling objective. This involves randomly masking some tokens in the input sequence and training the model to predict the masked tokens based on the context provided by the unmasked tokens. This process helps to adapt the PLM to the specific characteristics of the target task and improve its performance on that task.","metadata":{}},{"cell_type":"markdown","source":"# Finetuning","metadata":{}},{"cell_type":"code","source":"# set up the data loader\ntrain_data = WebNLGDataset(dataset)\nbatch_size = 32 #16\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)","metadata":{"id":"pOfRTwjZ9Mla","execution":{"iopub.status.busy":"2023-05-21T23:50:25.765196Z","iopub.execute_input":"2023-05-21T23:50:25.765949Z","iopub.status.idle":"2023-05-21T23:50:25.772224Z","shell.execute_reply.started":"2023-05-21T23:50:25.765913Z","shell.execute_reply":"2023-05-21T23:50:25.770856Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# set up the optimizer and the loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4) #3e-5\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:50:25.776946Z","iopub.execute_input":"2023-05-21T23:50:25.777215Z","iopub.status.idle":"2023-05-21T23:50:25.785780Z","shell.execute_reply.started":"2023-05-21T23:50:25.777191Z","shell.execute_reply":"2023-05-21T23:50:25.784975Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# fine-tune the model\nnum_epochs = 2\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for inputs, targets in train_loader:\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs, labels=targets)\n        loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), targets.view(-1))\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    epoch_loss = running_loss / len(train_data)\n    print(f\"Epoch {epoch+1}/{num_epochs} - loss: {epoch_loss:.4f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYG15tgj9Mla","outputId":"0e9adabd-0a23-4320-db12-8890b1a83361","execution":{"iopub.status.busy":"2023-05-21T23:50:25.787135Z","iopub.execute_input":"2023-05-21T23:50:25.787543Z","iopub.status.idle":"2023-05-21T23:53:34.750449Z","shell.execute_reply.started":"2023-05-21T23:50:25.787509Z","shell.execute_reply":"2023-05-21T23:53:34.747930Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2 - loss: 1.7436\nEpoch 2/2 - loss: 1.1279\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the entire model\ntorch.save(model, 'model_with_CCE_masked_pretraining_multipe_triples_43_parallel')\nprint(\"Model saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:58:26.137130Z","iopub.execute_input":"2023-05-21T23:58:26.137515Z","iopub.status.idle":"2023-05-21T23:58:26.510148Z","shell.execute_reply.started":"2023-05-21T23:58:26.137484Z","shell.execute_reply":"2023-05-21T23:58:26.509141Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the model\n#model = torch.load('/kaggle/input/models/model_with_CCE_masked_pretraining_multipe_triples_71')\n\n# Print a confirmation message\nprint(\"Model loaded successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:53:35.297210Z","iopub.execute_input":"2023-05-21T23:53:35.297827Z","iopub.status.idle":"2023-05-21T23:53:35.303598Z","shell.execute_reply.started":"2023-05-21T23:53:35.297790Z","shell.execute_reply":"2023-05-21T23:53:35.302609Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Model loaded successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## are we accounting for the multiple texts targets in the bleu? it doesn't look like it","metadata":{}},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:53:35.305044Z","iopub.execute_input":"2023-05-21T23:53:35.305592Z","iopub.status.idle":"2023-05-21T23:53:46.487228Z","shell.execute_reply.started":"2023-05-21T23:53:35.305542Z","shell.execute_reply":"2023-05-21T23:53:46.485911Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.3.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2.7.0)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.3.23)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=32","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:53:46.490366Z","iopub.execute_input":"2023-05-21T23:53:46.490814Z","iopub.status.idle":"2023-05-21T23:53:46.499735Z","shell.execute_reply.started":"2023-05-21T23:53:46.490769Z","shell.execute_reply":"2023-05-21T23:53:46.498523Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from sacrebleu import corpus_bleu\nfrom random import sample\nfrom tqdm import tqdm\n\n\n# load the WebNLG validation dataset\nvalidation_dataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['test']\nvalidation_dataset = [sample for sample in validation_dataset if sample['lex']['text']] # filter out samples with empty targets \n# Select a subset of the validation dataset\n#subset_size = 10  # Choose the desired subset size\n#validation_subset = sample(list(validation_dataset), subset_size)\nvalidation_data = WebNLGDataset(validation_dataset)\n\n# set up the validation data loader\nvalidation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n\n# switch model to evaluation mode\nmodel.eval()\n\n# generate predictions for the validation dataset\npredictions = []\nreferences = []\nwith torch.no_grad():\n    for inputs, targets in tqdm(validation_loader, desc='Validation Progress', leave=False):\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        outputs = model.module.generate(inputs, max_length=MAX_TARGET_LENGTH, num_beams=4)\n        # convert token IDs to strings\n        predicted_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        target_texts = tokenizer.batch_decode(targets, skip_special_tokens=True)\n        # append predicted and target texts for BLEU evaluation\n        predictions.extend(predicted_texts)\n        references.extend(target_texts)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:53:46.501875Z","iopub.execute_input":"2023-05-21T23:53:46.502358Z","iopub.status.idle":"2023-05-21T23:57:29.944862Z","shell.execute_reply.started":"2023-05-21T23:53:46.502322Z","shell.execute_reply":"2023-05-21T23:57:29.943884Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e18a5881ebd048a5ad3f0a6244d94f2d"}},"metadata":{}},{"name":"stderr","text":"Validation Progress:   0%|          | 0/87 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n  warnings.warn(\n                                                                    \r","output_type":"stream"}]},{"cell_type":"code","source":"# calculate BLEU scores\n#bleu = corpus_bleu(predictions, [references])\n\nmultiple_references = []\nfor i in range(len(validation_dataset)):\n    multiple_references.append(validation_dataset[i]['lex']['text'])\n    \nbleu = corpus_bleu(predictions, references)\nbleu_multiple = corpus_bleu(predictions, multiple_references)\n\nprint(f\"BLEU score: {bleu.score}\")\nprint(f\"BLEU score with multiple references: {bleu_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:57:29.946476Z","iopub.execute_input":"2023-05-21T23:57:29.947807Z","iopub.status.idle":"2023-05-21T23:57:30.752211Z","shell.execute_reply.started":"2023-05-21T23:57:29.947768Z","shell.execute_reply":"2023-05-21T23:57:30.751116Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"BLEU score: 0.4971592134485973\nBLEU score with multiple references: 43.47208719449915\n","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_chrf \nbleu_multiple = corpus_bleu(predictions, multiple_references)\nprint(f\"BLEU score with multiple references: {bleu_multiple.score}\")\nchrf = corpus_chrf(predictions, multiple_references)\nprint(chrf.score)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:57:30.753816Z","iopub.execute_input":"2023-05-21T23:57:30.754201Z","iopub.status.idle":"2023-05-21T23:57:31.915249Z","shell.execute_reply.started":"2023-05-21T23:57:30.754166Z","shell.execute_reply":"2023-05-21T23:57:31.914233Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"BLEU score with multiple references: 43.47208719449915\n64.80979690907658\n","output_type":"stream"}]},{"cell_type":"code","source":"import sacrebleu\n\n# Prepare reference and hypothesis sentences\nreference = [\n  ['The Guiana Space Centre has its headquarters at Kourou in French Guiana.', \"The Guiana Space Centre's headquarters are located in Kourou, French Guiana.\", 'The headquarters of the Guiana Space Centre is in Kourou, French Guiana.']]\nhypotheses = [\n  'The Guiana Space Centre has its headquarters in Kourou, in the French Republic of Guyana. The Guiana Space Centre has its headquarter in Kourou, in the French Republic of Guyana.'\n]\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(hypotheses, reference)\nprint(bleu.score)\n\n# Calculate CHR-F score\nchrf = sacrebleu.corpus_chrf(hypotheses, reference)\nprint(chrf.score)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T23:35:50.006453Z","iopub.execute_input":"2023-05-19T23:35:50.007429Z","iopub.status.idle":"2023-05-19T23:35:50.016319Z","shell.execute_reply.started":"2023-05-19T23:35:50.007385Z","shell.execute_reply":"2023-05-19T23:35:50.015330Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"18.96550847075289\n62.20788243603901\n","output_type":"stream"}]},{"cell_type":"code","source":"import sacrebleu\n\n# Prepare reference and hypothesis sentences\nreference = [\n    ['The cat is on the mat.', 'There is a cat on the mat.'],\n    ['I love eating pizza.', 'Pizza is my favorite food.'],\n    ['This is the hypothesis sentence']\n]\nhypotheses = [\n    'The cat is sitting on the mat.',\n    'I enjoy eating pizza.',\n    'This is the hypothesis sentence.'\n]\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(hypotheses, reference)\nprint(bleu.score)\n\n# Calculate CHR-F score\nchrf = sacrebleu.corpus_chrf(hypotheses, reference)\nprint(chrf.score)\n\nimport sacrebleu\n\n# Prepare reference and hypothesis sentences\nreference = [\n     ['This is the hypothesis sentence'],\n    ['The cat is on the mat.', 'There is a cat on the mat.'],\n     ['I love eating pizza.', 'Pizza is my favorite food.']\n]\nhypotheses = [\n    'The cat is sitting on the mat.',\n    'I enjoy eating pizza.',\n    'This is the hypothesis sentence.'\n]\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(hypotheses, reference)\nprint(bleu.score)\n\n# Calculate CHR-F score\nchrf = sacrebleu.corpus_chrf(hypotheses, reference)\nprint(chrf.score)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T23:26:02.784362Z","iopub.execute_input":"2023-05-19T23:26:02.784759Z","iopub.status.idle":"2023-05-19T23:26:02.796337Z","shell.execute_reply.started":"2023-05-19T23:26:02.784726Z","shell.execute_reply":"2023-05-19T23:26:02.795035Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"50.000000000000014\n74.02630292838671\n50.000000000000014\n74.02630292838671\n","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_chrf\n# Calculate CHR F++ scores\nchrf = corpus_chrf(predictions, [references])\nchrf_multiple = corpus_chrf(predictions, multiple_references)\nprint(f\"CHR F++ score: {chrf.score}\")\nprint(f\"CHR F++ score with multiple references: {chrf_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-19T23:26:35.797650Z","iopub.execute_input":"2023-05-19T23:26:35.798039Z","iopub.status.idle":"2023-05-19T23:26:38.101883Z","shell.execute_reply.started":"2023-05-19T23:26:35.798007Z","shell.execute_reply":"2023-05-19T23:26:38.100828Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"CHR F++ score: 57.01406827265573\nCHR F++ score with multiple references: 87.37417180259725\n","output_type":"stream"}]},{"cell_type":"code","source":"i=5\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:45:06.925592Z","iopub.execute_input":"2023-05-21T23:45:06.926167Z","iopub.status.idle":"2023-05-21T23:45:06.932482Z","shell.execute_reply.started":"2023-05-21T23:45:06.926133Z","shell.execute_reply":"2023-05-21T23:45:06.931569Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id6', 'original_triple_sets': {'otriple_set': [['Abdul_Taib_Mahmud | successor | Sulaiman_Abdul_Rahman_Taib']]}, 'modified_triple_sets': {'mtriple_set': [['Abdul_Taib_Mahmud | successor | Sulaiman_Abdul_Rahman_Taib']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': [\"Abdul Taib Mahmud's successor was Sulaiman Abdul Rahman Taib.\", 'Abdul Taib Mahmud was succeded by Sulaiman Abdul Rahman Taib.', 'The sucessor to Abdul Taib Mahmud was Sulaiman Abdul Rahman Taib.'], 'lang': ['', '', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Abdul_Taib_Mahmud | successor | Sulaiman_Abdul_Rahman_Taib']]\nSulaiman Abdul Rahman Taib is the successor of Abdul Taib Mohammed.\n[\"Abdul Taib Mahmud's successor was Sulaiman Abdul Rahman Taib.\", 'Abdul Taib Mahmud was succeded by Sulaiman Abdul Rahman Taib.', 'The sucessor to Abdul Taib Mahmud was Sulaiman Abdul Rahman Taib.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=10\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:45:11.854061Z","iopub.execute_input":"2023-05-21T23:45:11.854440Z","iopub.status.idle":"2023-05-21T23:45:11.861611Z","shell.execute_reply.started":"2023-05-21T23:45:11.854408Z","shell.execute_reply":"2023-05-21T23:45:11.860591Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id11', 'original_triple_sets': {'otriple_set': [['Abner_W._Sibal | deathPlace | Alexandria,_Virginia']]}, 'modified_triple_sets': {'mtriple_set': [['Abner_W._Sibal | deathPlace | Alexandria,_Virginia']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Abner W Sibal died in Alexandria, Virginia.', 'Abner W. Sibal died in Alexandria, Virginia.', 'Abner W Sibal died in Alexandria, Virginia.'], 'lang': ['', '', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Abner_W._Sibal | deathPlace | Alexandria,_Virginia']]\nAbner W. Sibal died in Alexandria, Virginia.\n['Abner W Sibal died in Alexandria, Virginia.', 'Abner W. Sibal died in Alexandria, Virginia.', 'Abner W Sibal died in Alexandria, Virginia.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=50\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:45:14.767970Z","iopub.execute_input":"2023-05-21T23:45:14.768362Z","iopub.status.idle":"2023-05-21T23:45:14.774084Z","shell.execute_reply.started":"2023-05-21T23:45:14.768328Z","shell.execute_reply":"2023-05-21T23:45:14.773113Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id51', 'original_triple_sets': {'otriple_set': [['United_States_Army | battles | Spanish–American_War'], ['United_States_Army | battle | Spanish–American_War']]}, 'modified_triple_sets': {'mtriple_set': [['United_States_Army | battles | Spanish–American_War']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good'], 'lid': ['Id1'], 'text': ['The United States Army was involved in battles in the Spanish-American War.'], 'lang': ['']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['United_States_Army | battles | Spanish–American_War'], ['United_States_Army | battle | Spanish–American_War']]\nThe Spanish–American War is a battle of the United States Armee.\n['The United States Army was involved in battles in the Spanish-American War.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=0\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:52:34.630263Z","iopub.execute_input":"2023-05-19T22:52:34.630672Z","iopub.status.idle":"2023-05-19T22:52:34.639090Z","shell.execute_reply.started":"2023-05-19T22:52:34.630640Z","shell.execute_reply":"2023-05-19T22:52:34.637997Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id1', 'original_triple_sets': {'otriple_set': [['Aaron_S._Daggett | award | Purple_Heart']]}, 'modified_triple_sets': {'mtriple_set': [['Aaron_S._Daggett | award | Purple_Heart']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Aaron S Daggett was awarded the Purple Heart.', 'Aaron S. Daggett was awarded the Purple Heart.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Aaron_S._Daggett | award | Purple_Heart']]\nAaron S. Daggett won the Purple Heart award.\n['Aaron S Daggett was awarded the Purple Heart.', 'Aaron S. Daggett was awarded the Purple Heart.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### known error, sometimes the prompt leaks into the output ","metadata":{}},{"cell_type":"code","source":"i=70\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:52:44.533063Z","iopub.execute_input":"2023-05-19T22:52:44.533429Z","iopub.status.idle":"2023-05-19T22:52:44.541012Z","shell.execute_reply.started":"2023-05-19T22:52:44.533393Z","shell.execute_reply":"2023-05-19T22:52:44.540105Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"{'category': 'MeanOfTransportation', 'size': 1, 'eid': 'Id71', 'original_triple_sets': {'otriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema'], ['Alfa_Romeo_164 | related | Lancia_Thema']]}, 'modified_triple_sets': {'mtriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Alfa Romeo 164 and Lancia Thema are related types of transportation.', 'The related transport to the Alfa Romeo 164 is the Lancia Thema.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema'], ['Alfa_Romeo_164 | related | Lancia_Thema']]\nAlfa Romeo 164 is related to Lancia Thema.\n['Alfa Romeo 164 and Lancia Thema are related types of transportation.', 'The related transport to the Alfa Romeo 164 is the Lancia Thema.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=130\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-19T21:05:22.135681Z","iopub.execute_input":"2023-05-19T21:05:22.136441Z","iopub.status.idle":"2023-05-19T21:05:22.142961Z","shell.execute_reply.started":"2023-05-19T21:05:22.136399Z","shell.execute_reply":"2023-05-19T21:05:22.141558Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'category': 'Athlete', 'size': 1, 'eid': 'Id131', 'original_triple_sets': {'otriple_set': [['Aleksandr_Prudnikov | team | FC_Amkar_Perm'], ['Aleksandr_Prudnikov | clubs | FC_Amkar_Perm']]}, 'modified_triple_sets': {'mtriple_set': [['Aleksandr_Prudnikov | club | FC_Amkar_Perm']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Aleksandr Prudnikov plays for FC Amkar Perm.', 'Aleksandr Prudnikov plays for the FC Amkar Perm football club.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Aleksandr_Prudnikov | team | FC_Amkar_Perm'], ['Aleksandr_Prudnikov | clubs | FC_Amkar_Perm']]\nAleksandr Prudnikov's club is FC Amkar Perm.\n['Aleksandr Prudnikov plays for FC Amkar Perm.', 'Aleksandr Prudnikov plays for the FC Amkar Perm football club.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=1861\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-19T21:05:33.650468Z","iopub.execute_input":"2023-05-19T21:05:33.650876Z","iopub.status.idle":"2023-05-19T21:05:33.657619Z","shell.execute_reply.started":"2023-05-19T21:05:33.650837Z","shell.execute_reply":"2023-05-19T21:05:33.656372Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'category': 'Astronaut', 'size': 7, 'eid': 'Id971', 'original_triple_sets': {'otriple_set': [['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | selection | 1963', 'William_Anders | timeInSpace | \"8820.0\"^^<http://dbpedia.org/datatype/minute>', 'William_Anders | birthDate | \"1933-10-17\"^^xsd:date', 'William_Anders | occupation | Fighter_pilot', 'William_Anders | birthPlace | British_Hong_Kong', 'William_Anders | mission | Apollo_8']]}, 'modified_triple_sets': {'mtriple_set': [['William_Anders | dateOfRetirement | \"1969-09-01\"', 'William_Anders | was selected by NASA | 1963', 'William_Anders | timeInSpace | \"8820.0\"(minutes)', 'William_Anders | birthDate | \"1933-10-17\"', 'William_Anders | occupation | Fighter_pilot', 'William_Anders | birthPlace | British_Hong_Kong', 'William_Anders | was a crew member of | Apollo_8']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Test pilot William Anders was born in British Hong Kong on October 17th, 1933. After joining NASA in 1963, he served as a crew member of Apollo 8. When he retired on September 1st, 1969 his total space time was 8820.0 minutes.', 'William Anders was born in British Hong Kong on October 17th, 1933. He served as a fighter pilot. He joined NASA in 1963 and was a crew member on Apollo 8. He retired on the 1st September 1969, having spent 8820 minutes in space.', 'Selected in 1963 by NASA as a test pilot, William Anders was born in Hong Kong on October 17 1933, retired in 1969, and served as a crew member of Apollo 8 spending 8820 minutes in space.'], 'lang': ['', '', '']}, 'test_category': 'testdata_with_lex', 'dbpedia_links': [], 'links': []}\n[['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | selection | 1963', 'William_Anders | timeInSpace | \"8820.0\"^^<http://dbpedia.org/datatype/minute>', 'William_Anders | birthDate | \"1933-10-17\"^^xsd:date', 'William_Anders | occupation | Fighter_pilot', 'William_Anders | birthPlace | British_Hong_Kong', 'William_Anders | mission | Apollo_8']]\nWilliam Anders was born on July 17th, 1933, in British Hong Kong. He was a fighter pilot and was selected by the dbpedia.org database. William was selected by the dbpedia.org database.\n['Test pilot William Anders was born in British Hong Kong on October 17th, 1933. After joining NASA in 1963, he served as a crew member of Apollo 8. When he retired on September 1st, 1969 his total space time was 8820.0 minutes.', 'William Anders was born in British Hong Kong on October 17th, 1933. He served as a fighter pilot. He joined NASA in 1963 and was a crew member on Apollo 8. He retired on the 1st September 1969, having spent 8820 minutes in space.', 'Selected in 1963 by NASA as a test pilot, William Anders was born in Hong Kong on October 17 1933, retired in 1969, and served as a crew member of Apollo 8 spending 8820 minutes in space.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=1860\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-19T22:52:57.195899Z","iopub.execute_input":"2023-05-19T22:52:57.196281Z","iopub.status.idle":"2023-05-19T22:52:57.202465Z","shell.execute_reply.started":"2023-05-19T22:52:57.196251Z","shell.execute_reply":"2023-05-19T22:52:57.201544Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"{'category': 'Astronaut', 'size': 7, 'eid': 'Id970', 'original_triple_sets': {'otriple_set': [['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | mission | Apollo_8', 'William_Anders | nationality | United_States', 'William_Anders | birthPlace | British_Hong_Kong', 'Apollo_8 | crew2Up | Buzz_Aldrin', 'Apollo_8 | crewMembers | Frank_Borman', 'Apollo_8 | operator | NASA']]}, 'modified_triple_sets': {'mtriple_set': [['William_Anders | dateOfRetirement | \"1969-09-01\"', 'William_Anders | was a crew member of | Apollo_8', 'William_Anders | nationality | United_States', 'William_Anders | birthPlace | British_Hong_Kong', 'Apollo_8 | backup pilot | Buzz_Aldrin', 'Apollo_8 | crewMembers | Frank_Borman', 'Apollo_8 | operator | NASA']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': [\"William Anders was born in British Hong Kong and is a U.S Citizen. William was a member of the Apollo 8 crew (along with Frank Borman) which was operated by NASA's backup pilot Buzz Aldrin. William retired on September 1st in 1969.\", 'William Anders was born in British Hong Kong but is an American. He was a member of Apollo 8 which is operated by NASA. His backup pilot was Buzz Aldrin. Anders retired in 1960-09-01.', \"William Anders was from the US and he was born in British Hong Kong. Alongside Frank Borman, he crewed the NASA operated Apollo 8 before he retired on1969-09-01. Apollo 8's backup pilot was Buzz Aldrin.\"], 'lang': ['', '', '']}, 'test_category': 'testdata_with_lex', 'dbpedia_links': [], 'links': []}\n[['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | mission | Apollo_8', 'William_Anders | nationality | United_States', 'William_Anders | birthPlace | British_Hong_Kong', 'Apollo_8 | crew2Up | Buzz_Aldrin', 'Apollo_8 | crewMembers | Frank_Borman', 'Apollo_8 | operator | NASA']]\nWilliam Anders was born in British Hong Kong and was a crew member of Apollo 8 which was operated by NASA on the 9th of September 1969. He was a member of the crew of Buzz Aldrin and Frank Burman. He was a member of the Apollo 8 which was operated by NASA.\n[\"William Anders was born in British Hong Kong and is a U.S Citizen. William was a member of the Apollo 8 crew (along with Frank Borman) which was operated by NASA's backup pilot Buzz Aldrin. William retired on September 1st in 1969.\", 'William Anders was born in British Hong Kong but is an American. He was a member of Apollo 8 which is operated by NASA. His backup pilot was Buzz Aldrin. Anders retired in 1960-09-01.', \"William Anders was from the US and he was born in British Hong Kong. Alongside Frank Borman, he crewed the NASA operated Apollo 8 before he retired on1969-09-01. Apollo 8's backup pilot was Buzz Aldrin.\"]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## there is a problem with empty target samples in the test set, we still need to check multiple triples!","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer\nfrom datasets import load_dataset\n\n# Define the tokenizer\n#tokenizer = T5Tokenizer.from_pretrained('t5-small')\n\n# Load the WebNLG dataset\ndataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['test']\ndataset = [sample for sample in dataset if sample['lex']['text']]\n\n# Create an instance of WebNLGDataset\nwebnlg_dataset = WebNLGDataset(dataset)\n\n# Define the index of the example you want to test\nexample_index = 70\n\n# Get the input and target texts for the example at the specified index\ninput_text, target_text = webnlg_dataset[example_index]\n\n# Decode the input and target texts using the tokenizer\ndecoded_input_text = tokenizer.decode(input_text, skip_special_tokens=True)\ndecoded_target_text = tokenizer.decode(target_text, skip_special_tokens=True)\n\n# Print the preprocessed input and target texts\nprint(\"Input Text:\", decoded_input_text)\nprint(\"Target Text:\", decoded_target_text)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:36:30.294773Z","iopub.execute_input":"2023-05-19T18:36:30.295189Z","iopub.status.idle":"2023-05-19T18:36:31.861708Z","shell.execute_reply.started":"2023-05-19T18:36:30.295152Z","shell.execute_reply":"2023-05-19T18:36:31.860533Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b598640a8aaf4538bace35a707a4555e"}},"metadata":{}},{"name":"stdout","text":"{'category': 'MeanOfTransportation', 'size': 1, 'eid': 'Id71', 'original_triple_sets': {'otriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema'], ['Alfa_Romeo_164 | related | Lancia_Thema']]}, 'modified_triple_sets': {'mtriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Alfa Romeo 164 and Lancia Thema are related types of transportation.', 'The related transport to the Alfa Romeo 164 is the Lancia Thema.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\ntranslate from Graph to Text:  <H> Alfa_Romeo_164  <R>  relatedMeanOfTransportation  <T>  Lancia_Thema <H> Alfa_Romeo_164  <R>  related  <T>  Lancia_Thema\nInput Text: translate from Graph to Text: Alfa_Romeo_164 relatedMeanOfTransportation Lancia_Thema Alfa_Romeo_164 related Lancia_Thema\nTarget Text: Alfa Romeo 164 and Lancia Thema are related types of transportation.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## seeing how many empty targets there are in the testing set","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['test']\ncount_empty_text = 0\nfor sample in dataset:\n    if not sample['lex']['text']:\n        count_empty_text += 1\n\nprint(f\"Number of samples with empty 'lex' 'text' field: {count_empty_text}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:48:18.862931Z","iopub.execute_input":"2023-05-18T18:48:18.863745Z","iopub.status.idle":"2023-05-18T18:48:20.403634Z","shell.execute_reply.started":"2023-05-18T18:48:18.863701Z","shell.execute_reply":"2023-05-18T18:48:20.402308Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2dc9ec2d9f4cc5a3473a3a50d95272"}},"metadata":{}},{"name":"stdout","text":"Number of samples with empty 'lex' 'text' field: 1862\n","output_type":"stream"}]},{"cell_type":"code","source":"total_samples = len(dataset)\nprint(f\"Total number of samples in the test dataset: {total_samples}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:48:20.405561Z","iopub.execute_input":"2023-05-18T18:48:20.405994Z","iopub.status.idle":"2023-05-18T18:48:20.412699Z","shell.execute_reply.started":"2023-05-18T18:48:20.405940Z","shell.execute_reply":"2023-05-18T18:48:20.411048Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Total number of samples in the test dataset: 4615\n","output_type":"stream"}]}]}