{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"2a8badda5171f6c1da75e6dcec216359e8635e393e06f848b1b87b76c1bdea5e"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"1af09f1f71524f44b3f79ed0427c8559":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4027186c2a1646c7a47db3e69d3ef93b","IPY_MODEL_c224ebc06fcf44dc80e8285b6578680e","IPY_MODEL_f3f96e77a1134c5c93ba218b8261ec0f"],"layout":"IPY_MODEL_45509cc5af034006bade5bff3fe9ea3b"}},"4027186c2a1646c7a47db3e69d3ef93b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7719bedd5d2544a38a46f058d0ef1a7e","placeholder":"​","style":"IPY_MODEL_305d7d10c879476ea87f924e2f802958","value":"100%"}},"c224ebc06fcf44dc80e8285b6578680e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4731ce03cfa84014bce0054c8611b4f9","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6af2a7876d954b93aca5a16930c9f079","value":3}},"f3f96e77a1134c5c93ba218b8261ec0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_528070b64e7d4bb0a891f1dbe89ae5bc","placeholder":"​","style":"IPY_MODEL_a99d41291bf84041a091180eb477e519","value":" 3/3 [00:00&lt;00:00, 106.45it/s]"}},"45509cc5af034006bade5bff3fe9ea3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7719bedd5d2544a38a46f058d0ef1a7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"305d7d10c879476ea87f924e2f802958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4731ce03cfa84014bce0054c8611b4f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af2a7876d954b93aca5a16930c9f079":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"528070b64e7d4bb0a891f1dbe89ae5bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99d41291bf84041a091180eb477e519":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad3be34b6eb94452a3230903e6b30f1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ecfc2ce3b494aaa9637a3972d69b372","IPY_MODEL_d826b516ed494815b339c3f5a81b92e5","IPY_MODEL_561440b297714889bc5e1ccae8a553f4"],"layout":"IPY_MODEL_0f69091ff4ec47959c9f7d4a2135febf"}},"5ecfc2ce3b494aaa9637a3972d69b372":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bcef4bf5ee84c96a8e416e4cb73b14c","placeholder":"​","style":"IPY_MODEL_e0a5f1f63b85442ba734bbf90bfda6bd","value":"100%"}},"d826b516ed494815b339c3f5a81b92e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8ebcb18b8dd4259812dbaf39677a6e8","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4542fecca894086ab325a598b3d46b0","value":3}},"561440b297714889bc5e1ccae8a553f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1739d352f2748fd85a75ec63cf3f2f6","placeholder":"​","style":"IPY_MODEL_92e0ab09fad1427e8869c7cf6e75caac","value":" 3/3 [00:00&lt;00:00, 106.73it/s]"}},"0f69091ff4ec47959c9f7d4a2135febf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bcef4bf5ee84c96a8e416e4cb73b14c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0a5f1f63b85442ba734bbf90bfda6bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8ebcb18b8dd4259812dbaf39677a6e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4542fecca894086ab325a598b3d46b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1739d352f2748fd85a75ec63cf3f2f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92e0ab09fad1427e8869c7cf6e75caac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"id":"ahHaXoNB9iBc","execution":{"iopub.status.busy":"2023-07-08T23:57:42.304107Z","iopub.execute_input":"2023-07-08T23:57:42.304367Z","iopub.status.idle":"2023-07-08T23:57:56.981421Z","shell.execute_reply.started":"2023-07-08T23:57:42.304342Z","shell.execute_reply":"2023-07-08T23:57:56.980224Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.5.5)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.7.0 sacrebleu-2.3.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom torch.nn.parallel import DataParallel\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport pandas as pd\nimport datasets\n\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\nmodel = DataParallel(model)","metadata":{"id":"7Ms8N01X9MlZ","execution":{"iopub.status.busy":"2023-07-08T23:57:56.985756Z","iopub.execute_input":"2023-07-08T23:57:56.986100Z","iopub.status.idle":"2023-07-08T23:58:20.308612Z","shell.execute_reply.started":"2023-07-08T23:57:56.986071Z","shell.execute_reply":"2023-07-08T23:58:20.307229Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcba21c108a54ae992f1e3e7b2c556d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3970553111884b7590ffcec9b3f51b79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5b9f2c1fb5474188c4b660975a251c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1cc57f9d0b9415789b61960f7a440cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7952cab8b00d4c7a83e0634f947f58ff"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd848b8834b4f2bae898cb7bb264edf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b702136f33bb4cbc801fab4b47d09fa9"}},"metadata":{}}]},{"cell_type":"code","source":"new_tokens = ['<H>', '<R>', '<T>', '[SEP]']\nnew_tokens_vocab = {}\nnew_tokens_vocab['additional_special_tokens'] = []\nfor idx, t in enumerate(new_tokens):\n    new_tokens_vocab['additional_special_tokens'].append(t)\nnum_added_toks = tokenizer.add_special_tokens(new_tokens_vocab)\n\ntokenizer.add_tokens(\"[MASK]\")\ntokenizer.mask_token = \"[MASK]\"\ntokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")","metadata":{"id":"mujqgky_O0Lt","execution":{"iopub.status.busy":"2023-07-08T23:58:20.310072Z","iopub.execute_input":"2023-07-08T23:58:20.310449Z","iopub.status.idle":"2023-07-08T23:58:20.319911Z","shell.execute_reply.started":"2023-07-08T23:58:20.310411Z","shell.execute_reply":"2023-07-08T23:58:20.316779Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class WebNLGDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        self.prefix = \"translate from Graph to Text: \"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        # preprocess the input graph\n        try:\n            triples = item['modified_triple_sets']['mtriple_set']\n            input_text = self.prefix\n            for outer_list in triples:\n                for triple in outer_list:\n                    triple_txt = triple.split(\"|\")\n                    input_text += \" <H> \" + triple_txt[0] + \" <R> \" + triple_txt[1] + \" <T> \" + triple_txt[2]\n        except (KeyError, IndexError):\n            print(\"1\")\n            print(item['original_triple_sets']['otriple_set'])\n            print(item['original_triple_sets']['otriple_set'][0])\n            print(triples)\n            input_text = self.prefix\n        # preprocess the target text\n        try:\n            target_text = item['text'][0]\n        except (KeyError, IndexError):\n            print(\"2\")\n            print(item)\n            #print(item['original_triple_sets']['otriple_set'])\n            target_text = \"\"\n        #print(item)\n        #print(input_text)\n        # encode the inputs and targets using the tokenizer\n        input_ids = tokenizer.encode(input_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        target_ids = tokenizer.encode(target_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        #print(input_text)\n        #print(target_text)\n        return input_ids.squeeze(0), target_ids.squeeze(0)\n","metadata":{"id":"nXK6oOgXO0Lt","execution":{"iopub.status.busy":"2023-07-08T23:58:20.322943Z","iopub.execute_input":"2023-07-08T23:58:20.323493Z","iopub.status.idle":"2023-07-08T23:58:20.464701Z","shell.execute_reply.started":"2023-07-08T23:58:20.323461Z","shell.execute_reply":"2023-07-08T23:58:20.463603Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"MAX_INPUT_LENGTH = 128\nMAX_TARGET_LENGTH = 128\ntokenizer.model_max_length = MAX_INPUT_LENGTH\nmodel.module.config.max_length = MAX_TARGET_LENGTH\n\n# set up the device (GPU or CPU)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"id":"g1jjIPRO9Mla","_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-07-08T23:58:20.466516Z","iopub.execute_input":"2023-07-08T23:58:20.466912Z","iopub.status.idle":"2023-07-08T23:58:26.899736Z","shell.execute_reply.started":"2023-07-08T23:58:20.466876Z","shell.execute_reply":"2023-07-08T23:58:26.898685Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): T5ForConditionalGeneration(\n    (shared): Embedding(32128, 768)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 768)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n                (relative_attention_bias): Embedding(32, 12)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-11): 11 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (decoder): T5Stack(\n      (embed_tokens): Embedding(32128, 768)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n                (relative_attention_bias): Embedding(32, 12)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-11): 11 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseGatedActDense(\n                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): NewGELUActivation()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/models/final_dataset.pkl', 'rb') as f:\n  final_dataset = pickle.load(f)","metadata":{"id":"rGmMBlDWQDNN","execution":{"iopub.status.busy":"2023-07-08T23:58:26.901215Z","iopub.execute_input":"2023-07-08T23:58:26.901813Z","iopub.status.idle":"2023-07-08T23:58:26.940009Z","shell.execute_reply.started":"2023-07-08T23:58:26.901779Z","shell.execute_reply":"2023-07-08T23:58:26.939139Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import random\n\nrandom.Random(4).shuffle(final_dataset)","metadata":{"id":"Xij8H9Z6Qc_7","execution":{"iopub.status.busy":"2023-07-08T23:58:26.943305Z","iopub.execute_input":"2023-07-08T23:58:26.943623Z","iopub.status.idle":"2023-07-08T23:58:29.573215Z","shell.execute_reply.started":"2023-07-08T23:58:26.943598Z","shell.execute_reply":"2023-07-08T23:58:29.572103Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset = final_dataset[:700]\ndataset_val = final_dataset[700:900]\ndataset_test = final_dataset[900:]","metadata":{"id":"9vyHhtbMQdDu","execution":{"iopub.status.busy":"2023-07-08T23:58:29.576513Z","iopub.execute_input":"2023-07-08T23:58:29.577287Z","iopub.status.idle":"2023-07-08T23:58:29.585335Z","shell.execute_reply.started":"2023-07-08T23:58:29.577240Z","shell.execute_reply":"2023-07-08T23:58:29.584349Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"new_dataset = []\n\nfor i in range(len(dataset)):\n  sample = dataset[i]\n  target_list = sample['lex']['text']\n  reason = sample['reasoning']\n  mod_text_list = []\n  for a in target_list:\n    b = reason + \" [SEP]\" + a\n    mod_text_list.append(b)\n  sample['text'] = mod_text_list\n  new_dataset.append(sample)","metadata":{"id":"MD__zcyORvm5","execution":{"iopub.status.busy":"2023-07-08T23:58:29.588584Z","iopub.execute_input":"2023-07-08T23:58:29.589421Z","iopub.status.idle":"2023-07-08T23:58:29.600164Z","shell.execute_reply.started":"2023-07-08T23:58:29.589390Z","shell.execute_reply":"2023-07-08T23:58:29.599188Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"new_dataset_val = []\n\nfor i in range(len(dataset_val)):\n  sample = dataset[i]\n  target_list = sample['lex']['text']\n  reason = sample['reasoning']\n  mod_text_list = []\n  for a in target_list:\n    b = reason + \" [SEP]\" + a\n    mod_text_list.append(b)\n  sample['text'] = mod_text_list\n  new_dataset_val.append(sample)","metadata":{"id":"G7lHUDNTRvpQ","execution":{"iopub.status.busy":"2023-07-08T23:58:29.604210Z","iopub.execute_input":"2023-07-08T23:58:29.604584Z","iopub.status.idle":"2023-07-08T23:58:29.613579Z","shell.execute_reply.started":"2023-07-08T23:58:29.604560Z","shell.execute_reply":"2023-07-08T23:58:29.612654Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"new_dataset_test = []\n\nfor i in range(len(dataset_test)):\n  sample = dataset[i]\n  target_list = sample['lex']['text']\n  reason = sample['reasoning']\n  mod_text_list = []\n  for a in target_list:\n    b = reason + \" [SEP]\" + a\n    mod_text_list.append(b)\n  sample['text'] = mod_text_list\n  new_dataset_test.append(sample)","metadata":{"id":"uUCHuBM6VbM1","execution":{"iopub.status.busy":"2023-07-08T23:58:29.615124Z","iopub.execute_input":"2023-07-08T23:58:29.615529Z","iopub.status.idle":"2023-07-08T23:58:29.627571Z","shell.execute_reply.started":"2023-07-08T23:58:29.615478Z","shell.execute_reply":"2023-07-08T23:58:29.626482Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.Dataset.from_pandas(pd.DataFrame(data=new_dataset))","metadata":{"id":"rX_XjSOxRKaj","execution":{"iopub.status.busy":"2023-07-08T23:58:29.629369Z","iopub.execute_input":"2023-07-08T23:58:29.629714Z","iopub.status.idle":"2023-07-08T23:58:29.675497Z","shell.execute_reply.started":"2023-07-08T23:58:29.629683Z","shell.execute_reply":"2023-07-08T23:58:29.674412Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"val_dataset = datasets.Dataset.from_pandas(pd.DataFrame(data=new_dataset_val))\ntest_dataset = datasets.Dataset.from_pandas(pd.DataFrame(data=new_dataset_test))","metadata":{"id":"eboECLtLRKfo","execution":{"iopub.status.busy":"2023-07-08T23:58:29.678887Z","iopub.execute_input":"2023-07-08T23:58:29.679156Z","iopub.status.idle":"2023-07-08T23:58:29.703483Z","shell.execute_reply.started":"2023-07-08T23:58:29.679133Z","shell.execute_reply":"2023-07-08T23:58:29.702657Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dataset_train = WebNLGDataset(train_dataset)\ndataset_val = WebNLGDataset(val_dataset)\ndataset_test = WebNLGDataset(test_dataset)","metadata":{"id":"212F8MYBa-YJ","execution":{"iopub.status.busy":"2023-07-08T23:58:29.704579Z","iopub.execute_input":"2023-07-08T23:58:29.705534Z","iopub.status.idle":"2023-07-08T23:58:29.710141Z","shell.execute_reply.started":"2023-07-08T23:58:29.705503Z","shell.execute_reply":"2023-07-08T23:58:29.709160Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# load the WebNLG dataset\n#dataset = load_dataset('web_nlg', 'release_v3.0_en')['train']\n#dataset_val = load_dataset('web_nlg', 'release_v3.0_en')['dev']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["1af09f1f71524f44b3f79ed0427c8559","4027186c2a1646c7a47db3e69d3ef93b","c224ebc06fcf44dc80e8285b6578680e","f3f96e77a1134c5c93ba218b8261ec0f","45509cc5af034006bade5bff3fe9ea3b","7719bedd5d2544a38a46f058d0ef1a7e","305d7d10c879476ea87f924e2f802958","4731ce03cfa84014bce0054c8611b4f9","6af2a7876d954b93aca5a16930c9f079","528070b64e7d4bb0a891f1dbe89ae5bc","a99d41291bf84041a091180eb477e519","386a6ef8f07447f79d1e919da4012f33","af60a623a68a4391a2d9fe20c9814dce"]},"id":"qEf48SzQ9Mla","outputId":"4c918f52-9562-4b13-f519-0f20efe57b2d","execution":{"iopub.status.busy":"2023-07-08T23:58:29.711330Z","iopub.execute_input":"2023-07-08T23:58:29.712271Z","iopub.status.idle":"2023-07-08T23:58:29.720074Z","shell.execute_reply.started":"2023-07-08T23:58:29.712238Z","shell.execute_reply":"2023-07-08T23:58:29.719059Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch\nimport numpy as np\n\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decrease.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), 'checkpoint.pt')\n        self.val_loss_min = val_loss\n","metadata":{"id":"fowbYhoMO0Lw","execution":{"iopub.status.busy":"2023-07-08T23:58:29.722714Z","iopub.execute_input":"2023-07-08T23:58:29.723025Z","iopub.status.idle":"2023-07-08T23:58:29.735919Z","shell.execute_reply.started":"2023-07-08T23:58:29.722995Z","shell.execute_reply":"2023-07-08T23:58:29.734982Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Adaptive pretraining","metadata":{"id":"3KkcUmcLO0Lw"}},{"cell_type":"markdown","source":"For STA, we fine-tuned the PLMs on a small amount of labeled data from the target task using a maximum likelihood estimation (MLE) objective. This involves training the model to maximize the likelihood of generating the correct output given the input graph and labeled data. This process helps to further adapt the PLM to the specific requirements of the target task and improve its performance on that task.","metadata":{"id":"EaMPSnzSO0Ly"}},{"cell_type":"code","source":"import random\n\npretrain_texts = []\nfor sample in dataset:\n    try:\n        text = sample['text'][0]\n        pretrain_texts.append(text)\n    except (KeyError, IndexError):\n        continue\n\ntokenized_inputs = tokenizer(pretrain_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\ninput_ids = tokenized_inputs['input_ids']\nattention_mask = tokenized_inputs['attention_mask']\n\npretrain_data = torch.utils.data.TensorDataset(input_ids, attention_mask)\n\npretrain_loader = torch.utils.data.DataLoader(pretrain_data, batch_size=int(60), shuffle=True)\n\npretrain_optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\npretrain_criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n\npretrain_epochs = 10  # Set the number of pre-training epochs\nmasking_prob = 0.15  # Probability of masking a token\n\n\n# Prepare validation data\nval_texts = []\nfor sample in dataset_val:\n    try:\n        text = sample['text'][0]\n        val_texts.append(text)\n    except (KeyError, IndexError):\n        continue\n\ntokenized_inputs_val = tokenizer(val_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\ninput_ids_val = tokenized_inputs_val['input_ids']\nattention_mask_val = tokenized_inputs_val['attention_mask']\n\nval_data = TensorDataset(input_ids_val, attention_mask_val)\n\nval_loader = DataLoader(val_data, batch_size=int(60), shuffle=True)\n\nearly_stopping = EarlyStopping(patience=3, verbose=True)\n\nif tokenizer.mask_token is None:\n    # Manually set a mask token if not already defined\n    tokenizer.add_tokens(\"[MASK]\")\n    tokenizer.mask_token = \"[MASK]\"\n    tokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n\nfor epoch in range(pretrain_epochs):\n    running_loss = 0.0\n    for inputs, attention_mask in pretrain_loader:\n        inputs = inputs.to(device)\n        attention_mask = attention_mask.to(device)\n        batch_size, seq_length = inputs.shape\n\n        # Create a mask for randomly selected tokens\n        mask = torch.rand(inputs.shape) < masking_prob\n\n        # Randomly replace selected tokens with [MASK] token\n        masked_inputs = inputs.clone()\n        masked_inputs[mask] = tokenizer.mask_token_id\n\n        pretrain_optimizer.zero_grad()\n        outputs = model(input_ids=masked_inputs, attention_mask=attention_mask, decoder_input_ids=inputs)\n\n        # Compute the loss only for the masked tokens\n        masked_logits = outputs.logits[mask]\n        masked_labels = inputs[mask]\n        loss = pretrain_criterion(masked_logits.view(-1, masked_logits.size(-1)), masked_labels.view(-1))\n\n        loss.backward()\n        pretrain_optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n\n    epoch_loss = running_loss / len(pretrain_data)\n    print(f\"Pretrain Epoch {epoch+1}/{pretrain_epochs} - loss: {epoch_loss:.4f}\")\n\n    # Validation\n    model.eval()\n    val_running_loss = 0.0\n    for val_inputs, val_attention_mask in val_loader:\n        val_inputs = val_inputs.to(device)\n        val_attention_mask = val_attention_mask.to(device)\n        batch_size, seq_length = val_inputs.shape\n\n        mask = torch.rand(val_inputs.shape) < masking_prob\n        masked_inputs = val_inputs.clone()\n        masked_inputs[mask] = tokenizer.mask_token_id\n\n        with torch.no_grad():\n            outputs = model(input_ids=masked_inputs, attention_mask=val_attention_mask, decoder_input_ids=val_inputs)\n            masked_logits = outputs.logits[mask]\n            masked_labels = val_inputs[mask]\n            val_loss = pretrain_criterion(masked_logits.view(-1, masked_logits.size(-1)), masked_labels.view(-1))\n\n        val_running_loss += val_loss.item() * val_inputs.size(0)\n\n    epoch_val_loss = val_running_loss / len(val_data)\n    print(f\"Val Epoch {epoch+1}/{pretrain_epochs} - loss: {epoch_val_loss:.4f}\")\n\n    early_stopping(epoch_val_loss, model)\n\n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T16:43:36.977651Z","iopub.execute_input":"2023-07-05T16:43:36.978033Z","iopub.status.idle":"2023-07-05T17:09:15.775897Z","shell.execute_reply.started":"2023-07-05T16:43:36.978005Z","shell.execute_reply":"2023-07-05T17:09:15.774909Z"},"id":"vT3E0HVCO0Ly","outputId":"6ee39643-a1db-4068-dc82-3e5607004455","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Pretrain Epoch 1/10 - loss: 2.0488\nVal Epoch 1/10 - loss: 0.3027\nValidation loss decreased (inf --> 0.302650).  Saving model ...\nPretrain Epoch 2/10 - loss: 0.1625\nVal Epoch 2/10 - loss: 0.0930\nValidation loss decreased (0.302650 --> 0.092999).  Saving model ...\nPretrain Epoch 3/10 - loss: 0.0651\nVal Epoch 3/10 - loss: 0.0468\nValidation loss decreased (0.092999 --> 0.046806).  Saving model ...\nPretrain Epoch 4/10 - loss: 0.0339\nVal Epoch 4/10 - loss: 0.0367\nValidation loss decreased (0.046806 --> 0.036662).  Saving model ...\nPretrain Epoch 5/10 - loss: 0.0233\nVal Epoch 5/10 - loss: 0.0264\nValidation loss decreased (0.036662 --> 0.026411).  Saving model ...\nPretrain Epoch 6/10 - loss: 0.0202\nVal Epoch 6/10 - loss: 0.0199\nValidation loss decreased (0.026411 --> 0.019874).  Saving model ...\nPretrain Epoch 7/10 - loss: 0.0143\nVal Epoch 7/10 - loss: 0.0136\nValidation loss decreased (0.019874 --> 0.013611).  Saving model ...\nPretrain Epoch 8/10 - loss: 0.0101\nVal Epoch 8/10 - loss: 0.0130\nValidation loss decreased (0.013611 --> 0.013019).  Saving model ...\nPretrain Epoch 9/10 - loss: 0.0078\nVal Epoch 9/10 - loss: 0.0071\nValidation loss decreased (0.013019 --> 0.007115).  Saving model ...\nPretrain Epoch 10/10 - loss: 0.0087\nVal Epoch 10/10 - loss: 0.0115\nEarlyStopping counter: 1 out of 3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For LMA, we first fine-tuned the PLMs on a small amount of task-specific data using a masked language modeling objective. This involves randomly masking some tokens in the input sequence and training the model to predict the masked tokens based on the context provided by the unmasked tokens. This process helps to adapt the PLM to the specific characteristics of the target task and improve its performance on that task.","metadata":{"id":"oS19HRKDO0L0"}},{"cell_type":"markdown","source":"# Finetuning","metadata":{"id":"8RA2Ab27O0L0"}},{"cell_type":"code","source":"# set up the data loader\n#train_data = WebNLGDataset(dataset)\nbatch_size = 32 #32\ntrain_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)","metadata":{"id":"pOfRTwjZ9Mla","execution":{"iopub.status.busy":"2023-07-08T23:58:43.537250Z","iopub.execute_input":"2023-07-08T23:58:43.537614Z","iopub.status.idle":"2023-07-08T23:58:43.543473Z","shell.execute_reply.started":"2023-07-08T23:58:43.537583Z","shell.execute_reply":"2023-07-08T23:58:43.542185Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# set up the optimizer and the loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4) #3e-5\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T23:58:44.142980Z","iopub.execute_input":"2023-07-08T23:58:44.143344Z","iopub.status.idle":"2023-07-08T23:58:44.153677Z","shell.execute_reply.started":"2023-07-08T23:58:44.143313Z","shell.execute_reply":"2023-07-08T23:58:44.152550Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"num_epochs = 2\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for inputs, targets in train_loader:\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs, labels=targets)\n        loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), targets.view(-1))\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    epoch_loss = running_loss / len(dataset_train)\n    print(f\"Epoch {epoch+1}/{num_epochs} - loss: {epoch_loss:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSzuf23KgCu_","outputId":"a3281f18-44a8-499b-e55a-a058a53b7e19","execution":{"iopub.status.busy":"2023-07-08T23:58:47.455467Z","iopub.execute_input":"2023-07-08T23:58:47.455844Z","iopub.status.idle":"2023-07-09T00:00:00.388252Z","shell.execute_reply.started":"2023-07-08T23:58:47.455799Z","shell.execute_reply":"2023-07-09T00:00:00.387154Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2 - loss: 0.9237\nEpoch 2/2 - loss: 0.5273\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/working/checkpoint.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-07-05T17:38:55.252723Z","iopub.execute_input":"2023-07-05T17:38:55.253653Z","iopub.status.idle":"2023-07-05T17:38:55.468523Z","shell.execute_reply.started":"2023-07-05T17:38:55.253621Z","shell.execute_reply":"2023-07-05T17:38:55.467604Z"},"id":"6534gR0EO0L1","outputId":"bbdcebd1-4d33-4c72-a5ce-32e418e96d41","trusted":true},"execution_count":null,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the entire model\ntorch.save(model, 'model_T5_flan_small_2020_v2')\nprint(\"Model saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T17:52:23.630427Z","iopub.execute_input":"2023-07-05T17:52:23.630812Z","iopub.status.idle":"2023-07-05T17:52:24.092727Z","shell.execute_reply.started":"2023-07-05T17:52:23.630782Z","shell.execute_reply":"2023-07-05T17:52:24.091694Z"},"id":"2Zl-NvP9O0L1","outputId":"56c2eab3-6ac6-4f07-9cb6-9cba91e8f62b","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the model\n#model = torch.load('/kaggle/input/models/model_T5_flan_small_multi')\n\n# Print a confirmation message\nprint(\"Model loaded successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T14:36:05.231909Z","iopub.execute_input":"2023-07-05T14:36:05.232475Z","iopub.status.idle":"2023-07-05T14:36:07.655113Z","shell.execute_reply.started":"2023-07-05T14:36:05.232431Z","shell.execute_reply":"2023-07-05T14:36:07.654022Z"},"id":"M_ptcPIKO0L1","outputId":"6adfbfc9-decb-42ba-a4aa-6c42bb8f81be","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model loaded successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"JYrzGmp7PZDX"}},{"cell_type":"markdown","source":"## are we accounting for the multiple texts targets in the bleu? it doesn't look like it","metadata":{"id":"RfWwLt_XO0L2"}},{"cell_type":"code","source":"batch_size=32","metadata":{"id":"-H73FAjaO0L2","execution":{"iopub.status.busy":"2023-07-09T00:00:27.633784Z","iopub.execute_input":"2023-07-09T00:00:27.635632Z","iopub.status.idle":"2023-07-09T00:00:27.640900Z","shell.execute_reply.started":"2023-07-09T00:00:27.635584Z","shell.execute_reply":"2023-07-09T00:00:27.639727Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sacrebleu import corpus_bleu\nfrom random import sample\nfrom tqdm import tqdm\n\n\n# load the WebNLG validation dataset\nvalidation_dataset = load_dataset('web_nlg', 'release_v3.0_en')['test']\nvalidation_dataset = [sample for sample in validation_dataset if sample['lex']['text']] # filter out samples with empty targets\nvalidation_dataset = validation_dataset[:32]\n# Select a subset of the validation dataset\n#subset_size = 10  # Choose the desired subset size\n#validation_subset = sample(list(validation_dataset), subset_size)\nvalidation_data = WebNLGDataset(validation_dataset)\n\n# set up the validation data loader\nvalidation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n\n# switch model to evaluation mode\nmodel.eval()\n\n# generate predictions for the validation dataset\npredictions = []\nreferences = []\nwith torch.no_grad():\n    for inputs, targets in tqdm(validation_loader, desc='Validation Progress', leave=False):\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        outputs = model.module.generate(inputs, max_length=MAX_TARGET_LENGTH, num_beams=4)\n        # convert token IDs to strings\n        predicted_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        target_texts = tokenizer.batch_decode(targets, skip_special_tokens=True)\n        # append predicted and target texts for BLEU evaluation\n        predictions.extend(predicted_texts)\n        references.extend(target_texts)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["ad3be34b6eb94452a3230903e6b30f1a","5ecfc2ce3b494aaa9637a3972d69b372","d826b516ed494815b339c3f5a81b92e5","561440b297714889bc5e1ccae8a553f4","0f69091ff4ec47959c9f7d4a2135febf","5bcef4bf5ee84c96a8e416e4cb73b14c","e0a5f1f63b85442ba734bbf90bfda6bd","c8ebcb18b8dd4259812dbaf39677a6e8","e4542fecca894086ab325a598b3d46b0","e1739d352f2748fd85a75ec63cf3f2f6","92e0ab09fad1427e8869c7cf6e75caac"]},"id":"5Ylb9U5rO0L2","outputId":"52c5277b-2515-4b7b-bad8-bc5b1a38c306","execution":{"iopub.status.busy":"2023-07-09T00:00:28.016738Z","iopub.execute_input":"2023-07-09T00:00:28.017640Z","iopub.status.idle":"2023-07-09T00:00:52.582872Z","shell.execute_reply.started":"2023-07-09T00:00:28.017603Z","shell.execute_reply":"2023-07-09T00:00:52.580863Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e882ba2ab0d34ae3a251202fde9f37e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5479e7fe65f4e3281d41c9816b65b54"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset web_nlg/release_v3.0_en (download: 24.32 MiB, generated: 15.75 MiB, post-processed: Unknown size, total: 40.07 MiB) to /root/.cache/huggingface/datasets/web_nlg/release_v3.0_en/0.0.0/28ffb892f7f42450dd9558684aa43bcaf44b1b3bf0d77cb8d73534646af88dda...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ae4b000c0ef4126ab0b05a91eb0379d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/13211 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1667 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5713 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset web_nlg downloaded and prepared to /root/.cache/huggingface/datasets/web_nlg/release_v3.0_en/0.0.0/28ffb892f7f42450dd9558684aa43bcaf44b1b3bf0d77cb8d73534646af88dda. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ddc8e293a4541bf875e7e0c167cfd01"}},"metadata":{}},{"name":"stderr","text":"Validation Progress:   0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"2\n{'category': 'SportsTeam', 'size': 5, 'eid': 'Id1', 'original_triple_sets': {'otriple_set': [['Estádio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca', 'Agremiação_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_Série_C', 'Campeonato_Brasileiro_Série_C | country | Brazil', 'Agremiação_Sportiva_Arapiraquense | nickname | \"\\'\\'Alvinegro\"@en', 'Agremiação_Sportiva_Arapiraquense | ground | Estádio_Municipal_Coaracy_da_Mata_Fonseca']]}, 'modified_triple_sets': {'mtriple_set': [['Estádio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca', 'Agremiação_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_Série_C', 'Campeonato_Brasileiro_Série_C | country | Brazil', 'Agremiação_Sportiva_Arapiraquense | nickname | \"\\'\\'Alvinegro\"', 'Agremiação_Sportiva_Arapiraquense | ground | Estádio_Municipal_Coaracy_da_Mata_Fonseca']]}, 'shape': '(X (X) (X (X)) (X (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', ''], 'lid': ['Id1', 'Id2'], 'text': ['Estádio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremiação Sportiva Arapiraquense in Arapiraca. Agremiação Sportiva Arapiraquense, nicknamed \"Alvinegro\", lay in the Campeonato Brasileiro Série C league from Brazil.', 'Estádio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremiação Sportiva Arapiraquense in Arapiraca. Alvinegro, the nickname of Agremiação Sportiva Arapiraquense, play in the Campeonato Brasileiro Série C league from Brazil.'], 'lang': ['', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Astronaut', 'size': 2, 'eid': 'Id2', 'original_triple_sets': {'otriple_set': [['Nie_Haisheng | birthDate | 1964-10-13', 'Nie_Haisheng | occupation | Fighter_pilot']]}, 'modified_triple_sets': {'mtriple_set': [['Nie_Haisheng | birthDate | 1964-10-13', 'Nie_Haisheng | occupation | Fighter_pilot']]}, 'shape': '(X (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Nie Haisheng, born on October 13, 1964, worked as a fighter pilot.', 'Nie Haisheng is a former fighter pilot who was born on October 13, 1964.', 'Nie Haisheng born on 10/13/1964 is a fighter pilot.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Airport', 'size': 1, 'eid': 'Id3', 'original_triple_sets': {'otriple_set': [['MotorSport_Vision | locationCity | Fawkham']]}, 'modified_triple_sets': {'mtriple_set': [['MotorSport_Vision | city | Fawkham']]}, 'shape': '(X (X))', 'shape_type': 'NA', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['MotorSport Vision is located in the city of Fawkham.', 'MotorSport Vision is located in the city of Fawkham, UK.', 'MotorSport Vision is located in Fawkham.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Athlete', 'size': 3, 'eid': 'Id4', 'original_triple_sets': {'otriple_set': [['Aleksandr_Prudnikov | Person/height | \"185.0\"^^<http://dbpedia.org/datatype/centimetre>', 'FC_Spartak_Moscow | ground | Otkrytiye_Arena', 'Aleksandr_Prudnikov | team | FC_Spartak_Moscow'], ['Aleksandr_Prudnikov | Person/height | \"185.0\"^^<http://dbpedia.org/datatype/centimetre>', 'FC_Spartak_Moscow | ground | Otkrytiye_Arena', 'Aleksandr_Prudnikov | clubs | FC_Spartak_Moscow']]}, 'modified_triple_sets': {'mtriple_set': [['Aleksandr_Prudnikov | height | 185.0 (centimetres)', 'FC_Spartak_Moscow | ground | Otkrytiye_Arena', 'Aleksandr_Prudnikov | club | FC_Spartak_Moscow']]}, 'shape': '(X (X) (X (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['185 centimetre tall Aleksandr Prudnikov played for the Otkrytiye Arena based FC Spartak, Moscow.', 'The 185 cm tall Aleksandr Prudnikov plays for FC Spartak Moscow who call their home ground Otkrytiye Arena.', 'Aleksandr Prudnikov who is 185 cm tall, plays for FC Spartak Moscow whose ground is the Otkrytiye Arena.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'City', 'size': 5, 'eid': 'Id5', 'original_triple_sets': {'otriple_set': [['Ciudad_Ayala | populationMetro | 1777539', 'Ciudad_Ayala | leaderTitle | City Manager', 'Ciudad_Ayala | type | City', 'Ciudad_Ayala | populationDensity | 1604.0', 'Ciudad_Ayala | governmentType | Council-manager_government']]}, 'modified_triple_sets': {'mtriple_set': [['Ciudad_Ayala | populationMetro | 1777539', 'Ciudad_Ayala | leaderTitle | \"City Manager\"', 'Ciudad_Ayala | type | City', 'Ciudad_Ayala | populationDensity | 1604.0', 'Ciudad_Ayala | governmentType | Council-manager_government']]}, 'shape': '(X (X) (X) (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Ciudad Ayala is a city with population density and population of 1604 and 1777539 respectively, where the leader is called the City Manager. The government type in the city of Ciudad Ayala is council-manager.', 'The city of Ciudad Ayala, with a population of 1,777,539, is led by a City Manager on a council-manager government system. It has a population density of 1604.', 'Ciudad Ayala, a city with population density and population of 1604.0 and 1,777,539 respectively, uses a type of government called council-manager government. One of the leaders of Ciudad Ayala is the City Manager.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'MusicalWork', 'size': 2, 'eid': 'Id6', 'original_triple_sets': {'otriple_set': [['Bootleg_Series_Volume_1:_The_Quine_Tapes | previousWork | Squeeze_(The_Velvet_Underground_album)', 'Squeeze_(The_Velvet_Underground_album) | subsequentWork | 1969:_The_Velvet_Underground_Live']]}, 'modified_triple_sets': {'mtriple_set': [['Bootleg_Series_Volume_1:_The_Quine_Tapes | precededBy | Squeeze_(The_Velvet_Underground_album)', 'Squeeze_(The_Velvet_Underground_album) | followedBy | 1969:_The_Velvet_Underground_Live']]}, 'shape': '(X (X (X)))', 'shape_type': 'chain', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['The album 1969: The Velvet Underground Live is preceded by the Velvet Underground album Squeeze, which was followed by The Quine Tapes.', 'The Velvet Underground album Bootleg Series Volume 1: The Quine Tapes was preceded by the album Squeeze, which was followed by the live album 1969: The Velvet Underground Live.', 'The Bootleg Series Volume I: The Quine Tapes is preceded by the Velvet Underground album Squeeze which was itself followed by the album 1969: The Velvet Underground Live.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'City', 'size': 5, 'eid': 'Id7', 'original_triple_sets': {'otriple_set': [['Ciudad_Ayala | populationDensity | 1604.0', 'Ciudad_Ayala | leaderTitle | Governator', 'Ciudad_Ayala | country | Mexico', 'Ciudad_Ayala | elevation | 1147.0', 'Ciudad_Ayala | timeZone | Pacific_Daylight_Time']]}, 'modified_triple_sets': {'mtriple_set': [['Ciudad_Ayala | populationDensity | 1604.0', 'Ciudad_Ayala | leaderTitle | Governator', 'Ciudad_Ayala | country | Mexico', 'Ciudad_Ayala | elevationAboveTheSeaLevel | 1147.0', 'Ciudad_Ayala | timeZone | Pacific_Daylight_Time']]}, 'shape': '(X (X) (X) (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Ciudad Ayala in Mexico with population density of 1604.0 and elevated 1147.0 above sea level is in the PDT time zone. The leader here is called the governator.', 'Ciudad Ayala is a country in Mexico that is located 1147 above sea level and is in the Pacific Daylight time zone. The population density is 1604 and the leader of Ciudad Ayala is called the governator.', 'Ciudad Ayala is located in Mexico and has a population density of 1604. The city stands 1147 m above sea level. The Governator is the leader of Ciudad Ayala located in the Pacific Daylight time zone.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Scientist', 'size': 1, 'eid': 'Id8', 'original_triple_sets': {'otriple_set': [['Olga_Bondareva | deathDate | 1991-12-01'], ['Olga_Bondareva | deathDate | 1991-12-09']]}, 'modified_triple_sets': {'mtriple_set': [['Olga_Bondareva | deathDate | 1991-12-09']]}, 'shape': '(X (X))', 'shape_type': 'NA', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Olga Bondareva died on December 9, 1991.', 'Olga Bondareva died on the 9th of December, 1991.', \"The date of Olga Bondareva's death was the ninth of December 1991.\"], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Scientist', 'size': 3, 'eid': 'Id9', 'original_triple_sets': {'otriple_set': [['Saint_Petersburg | foundingDate | 1703-05-27', 'Olga_Bondareva | deathPlace | Saint_Petersburg', 'Saint_Petersburg | areaTotal | 1439.0']]}, 'modified_triple_sets': {'mtriple_set': [['Saint_Petersburg | foundingDate | 1703-05-27', 'Olga_Bondareva | deathPlace | Saint_Petersburg', 'Saint_Petersburg | areaTotal | 1439.0']]}, 'shape': '(X (X (X) (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Saint Petersburg was founded on May 27, 1703 and has a total area of 1439.0, Olga Bondareva passed away at Saint Petersburg.', 'Saint Petersburg, where Olga Bondareva died, was founded on the 27th of May, 1703 and has a total area of approximately 1439 km2.', 'Saint Petersburg, where Olga Bondareva died, was founded on May 27, 1703 and consists of a total area of 1439.0 sq/km.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'City', 'size': 1, 'eid': 'Id10', 'original_triple_sets': {'otriple_set': [['Ciudad_Ayala | populationDensity | 1604.0'], ['Ciudad_Ayala | populationDensity | 1603.87']]}, 'modified_triple_sets': {'mtriple_set': [['Ciudad_Ayala | populationDensity | 1604.0']]}, 'shape': '(X (X))', 'shape_type': 'NA', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['The population density of Ciudad Ayala is 1604.0.', 'Ciudad Ayala city has a population density of 1604.0.', 'The population density in Ciudad Ayala is 1604.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Athlete', 'size': 1, 'eid': 'Id11', 'original_triple_sets': {'otriple_set': [['Piotr_Hallmann | birthDate | 1987-01-01'], ['Piotr_Hallmann | birthDate | 1987-08-25']]}, 'modified_triple_sets': {'mtriple_set': [['Piotr_Hallmann | birthDate | 1987-08-25']]}, 'shape': '(X (X))', 'shape_type': 'NA', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Piotr Hallmann was born on August 25, 1987.', \"Piotr Hallmann's birthday is August 25th 1987.\", 'Piotr Hallmann was born on the 25th of August 1987.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Scientist', 'size': 1, 'eid': 'Id12', 'original_triple_sets': {'otriple_set': [['Darlington | areaCode | 01325']]}, 'modified_triple_sets': {'mtriple_set': [['Darlington | areaCode | 01325']]}, 'shape': '(X (X))', 'shape_type': 'NA', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['The Darlington town has an area code of 01325.', 'The telephone area code for Darlington is 01325.', 'The area code in Darlington is 01325.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Monument', 'size': 6, 'eid': 'Id13', 'original_triple_sets': {'otriple_set': [['Adams_County,_Pennsylvania | west | Franklin_County,_Pennsylvania', '11th_Mississippi_Infantry_Monument | established | 2000', '11th_Mississippi_Infantry_Monument | region | Adams_County,_Pennsylvania', '11th_Mississippi_Infantry_Monument | municipality | Gettysburg,_Pennsylvania', '11th_Mississippi_Infantry_Monument | category | Contributing_property', 'Adams_County,_Pennsylvania | north | Cumberland_County,_Pennsylvania']]}, 'modified_triple_sets': {'mtriple_set': [['Adams_County,_Pennsylvania | hasToItsWest | Franklin_County,_Pennsylvania', '11th_Mississippi_Infantry_Monument | established | 2000', '11th_Mississippi_Infantry_Monument | location | Adams_County,_Pennsylvania', '11th_Mississippi_Infantry_Monument | municipality | Gettysburg,_Pennsylvania', '11th_Mississippi_Infantry_Monument | category | Contributing_property', 'Adams_County,_Pennsylvania | hasToItsNorth | Cumberland_County,_Pennsylvania']]}, 'shape': '(X (X) (X) (X) (X (X) (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', ''], 'lid': ['Id1', 'Id2'], 'text': [\"Pennsylvania's Franklin County is found to the west of Adams County, Pennsylvania and Pennsylvania's Cumberland County is to the north. A monument to the 11th Mississippi Infantry was erected in Adams County in the year 2000 in the municipality of Gettysburg and this monument is categorised as a contributing property.\", 'The 11th Mississippi Infantry Monument, a Contributing property established in the year 2000 in Adams County, Pennsylvania falls in the municipality of Gettysburg, Pennsylvania. Adams County Pennsylvania is East of Franklin County, Pennsylvania and has Cumberland County, Pennsylvania to its north.'], 'lang': ['', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Artist', 'size': 1, 'eid': 'Id14', 'original_triple_sets': {'otriple_set': [['Israel | officialLanguage | Modern_Hebrew']]}, 'modified_triple_sets': {'mtriple_set': [['Israel | officialLanguage | Modern_Hebrew']]}, 'shape': '(X (X))', 'shape_type': 'NA', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['The official language of Israel is modern Hebrew.', 'Israel’s official language is Modern Hebrew.', 'Modern Hebrew is the official language of Israel.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Airport', 'size': 3, 'eid': 'Id15', 'original_triple_sets': {'otriple_set': [['Adolfo_Suárez_Madrid–Barajas_Airport | operator | ENAIRE', 'Adolfo_Suárez_Madrid–Barajas_Airport | location | Alcobendas', 'Adolfo_Suárez_Madrid–Barajas_Airport | elevation | \"609.6\"^^xsd:double']]}, 'modified_triple_sets': {'mtriple_set': [['Adolfo_Suárez_Madrid–Barajas_Airport | operatingOrganisation | ENAIRE', 'Adolfo_Suárez_Madrid–Barajas_Airport | location | Alcobendas', 'Adolfo_Suárez_Madrid–Barajas_Airport | elevationAboveTheSeaLevel | 610.0']]}, 'shape': '(X (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': [''], 'lid': ['Id1'], 'text': ['ENAIRE is the operating organisation for Adolfo Suarez Madrid-Barajas airport. This airport is situated 610 meters above sea level in Alcobendas.'], 'lang': ['']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Company', 'size': 2, 'eid': 'Id16', 'original_triple_sets': {'otriple_set': [['GMA_New_Media | foundingYear | 2000-01-01', 'GMA_New_Media | product | Mobile_Applications']]}, 'modified_triple_sets': {'mtriple_set': [['GMA_New_Media | foundingDate | 2000-01-01', 'GMA_New_Media | product | Mobile_Applications']]}, 'shape': '(X (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['GMA New Media, a company founded on 01-01-2000 are manufacturers of mobile applications.', 'GMA New Media, which was founded on January 1, 2000, is a company that offers products such as mobile applications.', 'GMA New Media makes mobile apps and was founded on 01/01/2000.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Company', 'size': 4, 'eid': 'Id17', 'original_triple_sets': {'otriple_set': [['Hypermarcas | location | São_Paulo', 'Brazil | areaTotal | 8514837.141576303', 'Hypermarcas | location | Brazil', 'Hypermarcas | industry | Pharmaceuticals']]}, 'modified_triple_sets': {'mtriple_set': [['Hypermarcas | location | São_Paulo', 'Brazil | areaTotal | 8514837.14  (square kilometres)', 'Hypermarcas | location | Brazil', 'Hypermarcas | industry | Pharmaceuticals']]}, 'shape': '(X (X) (X) (X (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Hypermarcas is a pharmaceutical company located in Sao Paulo, Brazil. Brazil is 8514837.14 square kilometers in size.', 'Hypermarcas, a pharmaceutical company, is located in Sao Paulo within the 8514837.14 square kilometres that make up the country of Brazil.', 'Hypermarcas, a company in the pharmaceuticals industry, is located in Sao Paulo, Brazil, a country with a total area of 8514837.14 square kilometres.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'MusicalWork', 'size': 3, 'eid': 'Id18', 'original_triple_sets': {'otriple_set': [['Bootleg_Series_Volume_1:_The_Quine_Tapes | genre | Rock_music', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | previousWork | Squeeze_(The_Velvet_Underground_album)', \"Squeeze_(The_Velvet_Underground_album) | previousWork | Andy_Warhol's_Velvet_Underground_Featuring_Nico\"]]}, 'modified_triple_sets': {'mtriple_set': [['Bootleg_Series_Volume_1:_The_Quine_Tapes | genre | Rock_music', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | precededBy | Squeeze_(The_Velvet_Underground_album)', \"Squeeze_(The_Velvet_Underground_album) | precededBy | Andy_Warhol's_Velvet_Underground_Featuring_Nico\"]]}, 'shape': '(X (X) (X (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': [\"The Quine Tapes are Rock music genre preceded by the album Squeeze, and Squeeze was preceded by the album Andy Warhol's Velvet Underground Featuring Nico.\", \"Bootleg Series Volume 1: The Quine Tapes's genre is rock, and is preceded by the Velvet Underground album Squeeze, which was preceded by the compilation album Andy Warhol's Velvet Underground Featuring Nico.\", \"The album Bootleg Series Volume 1: The Quine Tapes fits into the Rock music genre and was preceded by Squeeze by The Velvet Underground, which in turn was preceded by Andy Warhol's Velvet Underground Featuring Nico.\"], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'University', 'size': 4, 'eid': 'Id19', 'original_triple_sets': {'otriple_set': [['Acharya_Institute_of_Technology | campus | \"Urban, ,\\\\nIn Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore – 560090.\"@en', 'Acharya_Institute_of_Technology | director | \"Dr. G. P. Prabhukumar\"@en', 'Acharya_Institute_of_Technology | affiliation | Visvesvaraya_Technological_University', 'Acharya_Institute_of_Technology | country | \"India\"@en'], ['Acharya_Institute_of_Technology | campus | \"Urban, ,\\\\nIn Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore – 560090.\"@en', 'Acharya_Institute_of_Technology | director | \"Dr. G. P. Prabhukumar\"@en', 'Acharya_Institute_of_Technology | affiliations | Visvesvaraya_Technological_University', 'Acharya_Institute_of_Technology | country | \"India\"@en']]}, 'modified_triple_sets': {'mtriple_set': [['Acharya_Institute_of_Technology | campus | \"In Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore – 560090.\"', 'Acharya_Institute_of_Technology | director | \"Dr. G. P. Prabhukumar\"', 'Acharya_Institute_of_Technology | affiliation | Visvesvaraya_Technological_University', 'Acharya_Institute_of_Technology | country | \"India\"']]}, 'shape': '(X (X) (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Dr. G. P. Prabhukumar is the director of the Acharya Institute of Technology which is located at Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore - 560090 in India and is affiliated with Visvesvaraya Technological University.', 'The Acharya Institute of Technology campus is located in Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore – 560090, India. Its director is Dr.G.P. Prabhukumar and it is affiliated to Visvesvaraya Technological University.', 'The campus of the Acharya Institute of Technology is located at Soldevanahalli, Acharya Dr. Sarvapalli Radhakrishnan Road, Hessarghatta Main Road, Bangalore – 560090, India and it is affiliated with the Visvesvaraya Technological University. Its director is Dr.G.P.Prabhukumar.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Politician', 'size': 3, 'eid': 'Id20', 'original_triple_sets': {'otriple_set': [['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans'], ['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans'], ['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans'], ['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans'], ['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans'], ['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans'], ['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans']]}, 'modified_triple_sets': {'mtriple_set': [['Abraham_A._Ribicoff | deathPlace | United_States', 'Abraham_A._Ribicoff | birthPlace | United_States', 'United_States | ethnicGroup | African_Americans']]}, 'shape': '(X (X (X)) (X (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Abraham A. Ribicoff was born and died in the United States where African Americans are an ethnic group.', 'Abraham A.Ribicoff died in the United States. It was also his birthplace. African Americans are an ethnic group in the U.S.A.', 'Abraham A Ribicoff was born and died in the United States where African Americans are an ethnic group.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'MusicalWork', 'size': 7, 'eid': 'Id21', 'original_triple_sets': {'otriple_set': [['Bootleg_Series_Volume_1:_The_Quine_Tapes | artist | The_Velvet_Underground', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | producer | The_Velvet_Underground', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | runtime | 13803.0', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | recordedIn | United_States', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | recordedIn | St._Louis,_Missouri', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | genre | Rock_music', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | recordLabel | Polydor_Records']]}, 'modified_triple_sets': {'mtriple_set': [['Bootleg_Series_Volume_1:_The_Quine_Tapes | artist | The_Velvet_Underground', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | producer | The_Velvet_Underground', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | runtime | 230.05', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | recordedIn | United_States', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | recordedIn | St._Louis,_Missouri', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | genre | Rock_music', 'Bootleg_Series_Volume_1:_The_Quine_Tapes | recordLabel | Polydor_Records']]}, 'shape': '(X (X) (X) (X) (X) (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Music group the Velvet Underground produced and released rock music album Bootleg Series Volume 1: The Quine Tapes under the Polydor Records record label. The album was recorded in St. Louis, Missouri, USA and has a run time of 230:05.', 'Bootleg Series Volume 1: The Quine Tapes created and produced by The Velvet Underground with runtime of 230.05 minutes was recorded in was St. Louis Missouri, United States. The Rock genre album was recorded through Polydor Records.', 'The Bootleg Series Volume I: The Quine Tapes created and produced by The Velvet Underground with runtime of 230.05 minutes was recorded in St. Louis, Missouri, United States. The Rock music genre album was released by the record label Polydor Records.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'WrittenWork', 'size': 2, 'eid': 'Id22', 'original_triple_sets': {'otriple_set': [['The_Fellowship_of_the_Ring | publisher | George_Allen_&_Unwin', 'The_Fellowship_of_the_Ring | literaryGenre | Fantasy_(genre)']]}, 'modified_triple_sets': {'mtriple_set': [['The_Fellowship_of_the_Ring | publisher | George_Allen_&_Unwin', 'The_Fellowship_of_the_Ring | literaryGenre | Fantasy_(genre)']]}, 'shape': '(X (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['The fellowship of the Ring belongs to the fantasy genre.George Allen & Unwin published it.', 'The Fellowship of the Ring was published in the Fantasy genre by George Allen & Unwin.', 'The Fellowship of the Ring, from the fantasy genre, was published by George Allen & Unwin.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Astronaut', 'size': 3, 'eid': 'Id23', 'original_triple_sets': {'otriple_set': [['Alan_Shepard | deathPlace | California', 'Alan_Shepard | birthPlace | New_Hampshire', 'Alan_Shepard | awards | Distinguished_Service_Medal_(United_States_Navy)']]}, 'modified_triple_sets': {'mtriple_set': [['Alan_Shepard | deathPlace | California', 'Alan_Shepard | birthPlace | New_Hampshire', 'Alan_Shepard | award | Distinguished_Service_Medal_(United_States_Navy)']]}, 'shape': '(X (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Distinguished Service Medal (US Navy) recipient Alan Shepard was born in New Hampshire but died in California.', 'Awarded the Distinguished Service Medal by The United States Navy, Alan Shepard, was born in New Hampshire, and died in California.', 'Alan Shepard, born in New Hampshire while having died in California, was awarded the Distinguished Service Medal by the United States Navy.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'MusicalWork', 'size': 3, 'eid': 'Id24', 'original_triple_sets': {'otriple_set': [['Mermaid_(Train_song) | subsequentWork | Imagine_(John_Lennon_song)', 'Mermaid_(Train_song) | producer | Espionage_(production_team)', 'Mermaid_(Train_song) | album | California_37_(Train_album)']]}, 'modified_triple_sets': {'mtriple_set': [['Mermaid_(Train_song) | followedBy | Imagine_(John_Lennon_song)', 'Mermaid_(Train_song) | producer | Espionage_(production_team)', 'Mermaid_(Train_song) | album | California_37_(Train_album)']]}, 'shape': '(X (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', '', '', ''], 'lid': ['Id1', 'Id2', 'Id3', 'Id4', 'Id5'], 'text': ['Imagine is a song that Train followed Mermaid with, which was a song produced by the production team Espionage, and was on their album California 37.', 'Train followed its song Mermaid, from its California 37 album, which was was produced by the production team Espionage, with a song titled Imagine.', \"From the production team Espionage, Train's song Mermaid (on the California 37 album) was followed by Train's performance of Imagine by John Lennon.\", 'The Train song Mermaid, which belongs to the California 37 Train album and was produced by Espionage, is followed by the John Lennon song Imagine.', \"Train's song Imagine came after a song from their California 37 album, titled Mermaid, which was produced by the production team Espionage.\"], 'lang': ['', '', '', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'WrittenWork', 'size': 5, 'eid': 'Id25', 'original_triple_sets': {'otriple_set': [['The_Fellowship_of_the_Ring | publisher | George_Allen_&_Unwin', 'The_Fellowship_of_the_Ring | literaryGenre | Fantasy_(genre)', 'The_Fellowship_of_the_Ring | subsequentWork | The_Two_Towers', 'The_Fellowship_of_the_Ring | author | J._R._R._Tolkien', 'The_Fellowship_of_the_Ring | releaseDate | 1954-07-29']]}, 'modified_triple_sets': {'mtriple_set': [['The_Fellowship_of_the_Ring | publisher | George_Allen_&_Unwin', 'The_Fellowship_of_the_Ring | literaryGenre | Fantasy_(genre)', 'The_Fellowship_of_the_Ring | followedBy | The_Two_Towers', 'The_Fellowship_of_the_Ring | author | J._R._R._Tolkien', 'The_Fellowship_of_the_Ring | releaseDate | 1954-07-29']]}, 'shape': '(X (X) (X) (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['The Fellowship of the Ring was written by J.R.R. Tolkien and was released on July 29, 1954. The Fellowship of the Ring is considered fantasy and was published by George Allen & Unwin. The sequel to The Fellowship of the Ring was The Two Towers.', 'J.R.R. Tolkien is the author of The Fellowship of the Ring released on July 29, 1954. It is a fantasy book published by George Allen & Unwin. The novel was followed by The Two Towers.', 'The Fellowship of the Ring belongs to the fantasy genre. Its author is J.R.R. Tolkien. It was published on July 29, 1954 by George Allen & Unwin. It was followed by The Two Towers.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Company', 'size': 2, 'eid': 'Id26', 'original_triple_sets': {'otriple_set': [['GMA_New_Media | location | Philippines', 'GMA_New_Media | industry | Entertainment']]}, 'modified_triple_sets': {'mtriple_set': [['GMA_New_Media | location | Philippines', 'GMA_New_Media | industry | Entertainment']]}, 'shape': '(X (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['GMA New Media lies in the Philippines where applications are offered in the entertainment industry.', 'Located in the Philippines, GMA New Media is an entertainment industry.', 'GMA New Media is an entertainment company located in the Philippines.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Film', 'size': 3, 'eid': 'Id27', 'original_triple_sets': {'otriple_set': [['English_Without_Tears | cinematography | Bernard_Knowles', 'English_Without_Tears | writer | Terence_Rattigan', 'English_Without_Tears | runtime | 89.0']]}, 'modified_triple_sets': {'mtriple_set': [['English_Without_Tears | cinematography | Bernard_Knowles', 'English_Without_Tears | writer | Terence_Rattigan', 'English_Without_Tears | runtime | 89.0']]}, 'shape': '(X (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['English Without Tears, written by Terence Rattigan, runs 89 minutes. The cinematography for the film was done by Bernard Knowles.', 'English Without Tears, an 89 minute film written by Terence Rattigan, features the cinematography of Bernard Knowles.', 'Terence Rattigan is the writer of the 89 minute movie ´English Without Tears´ and Bernard Knowles is the cinematographer.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Scientist', 'size': 3, 'eid': 'Id28', 'original_triple_sets': {'otriple_set': [['Lady_Anne_Monson | spouse | George_Monson', 'Lady_Anne_Monson | deathDate | 1776-01-01', 'Lady_Anne_Monson | field | Botany']]}, 'modified_triple_sets': {'mtriple_set': [['Lady_Anne_Monson | spouse | George_Monson', 'Lady_Anne_Monson | deathDate | 1776-02-18', 'Lady_Anne_Monson | professionalField | Botany']]}, 'shape': '(X (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['George Monson was married to Lady Anne Monson, a botanist, who died on February 18, 1776.', 'Lady Anne Monson, a professional botanist who was married to George Monson, died on February 18th, 1776.', 'Lady Anne Monson is the spouse of George Monson. Her professional field of study was botany, and she died on 18 February 1776.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Politician', 'size': 2, 'eid': 'Id29', 'original_triple_sets': {'otriple_set': [['Abdul_Taib_Mahmud | residence | \"Demak Jaya, Jalan Bako, Kuching, Sarawak\"@en', 'Abdul_Taib_Mahmud | party | Parti_Pesaka_Bumiputera_Bersatu']]}, 'modified_triple_sets': {'mtriple_set': [['Abdul_Taib_Mahmud | residence | \"Demak Jaya, Jalan Bako, Kuching, Sarawak\"', 'Abdul_Taib_Mahmud | party | Parti_Pesaka_Bumiputera_Bersatu']]}, 'shape': '(X (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', ''], 'lid': ['Id1', 'Id2'], 'text': ['Abdul Taib Mahmud, member of the Parti Pesaka Bumiputera Bersatu party, resides in Demak Jaya, Jalan Bako, Kuching, Sarawak.', 'Abdul Taib Mahmud, a member of the Parti Pesaka Bumiputera Bersatu party, resides in Demak Jaya, Jalan Bako, Kuching, Sarawak.'], 'lang': ['', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Artist', 'size': 5, 'eid': 'Id30', 'original_triple_sets': {'otriple_set': [['Liselotte_Grschebina | birthPlace | Karlsruhe', 'Liselotte_Grschebina | nationality | Israel', 'Liselotte_Grschebina | training | School_of_Applied_Arts_in_Stuttgart', 'Karlsruhe | country | Germany', 'Israel | language | Modern_Hebrew']]}, 'modified_triple_sets': {'mtriple_set': [['Liselotte_Grschebina | birthPlace | Karlsruhe', 'Liselotte_Grschebina | nationality | Israel', 'Liselotte_Grschebina | training | School_of_Applied_Arts_in_Stuttgart', 'Karlsruhe | country | Germany', 'Israel | language | Modern_Hebrew']]}, 'shape': '(X (X) (X (X)) (X (X)))', 'shape_type': 'mixed', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': [\"Liselotte Grschebina was an Israeli who attended the school of Applied Arts in Stuttgart. She was born in Karlsruhe, Germany. Israel's national language is Modern Hebrew.\", 'Liselotte Grschebina is an Israeli national who did her studies at the School of Applied Arts in Stuttgart and was born in Karlsruhe, which is in Germany unlike Israel whose language is Modern Hebrew.', 'Liselotte Grschebina was born in Karlsruhe which is located in Germany, has Israeli nationality (the language in Israel is Modern Hebrew), and studied at the School of Applied Arts in Stuttgart.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'Company', 'size': 1, 'eid': 'Id31', 'original_triple_sets': {'otriple_set': [['Chinabank | location | Philippines']]}, 'modified_triple_sets': {'mtriple_set': [['Chinabank | location | Philippines']]}, 'shape': '(X (X))', 'shape_type': 'NA', 'lex': {'comment': ['', ''], 'lid': ['Id1', 'Id2'], 'text': [\"Chinabank's location is the Philippines.\", 'Chinabank is located in the Philippines.'], 'lang': ['', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n2\n{'category': 'MusicalWork', 'size': 6, 'eid': 'Id32', 'original_triple_sets': {'otriple_set': [['Mermaid_(Train_song) | recordLabel | Columbia_Records', 'Mermaid_(Train_song) | runtime | 3.2666666666666666', 'Mermaid_(Train_song) | recordLabel | Sony_Music_Entertainment', 'Mermaid_(Train_song) | writer | Espen_Lind', 'Mermaid_(Train_song) | genre | Reggae', 'Mermaid_(Train_song) | writer | Amund_Bjørklund']]}, 'modified_triple_sets': {'mtriple_set': [['Mermaid_(Train_song) | recordLabel | Columbia_Records', 'Mermaid_(Train_song) | runtime | 3.16', 'Mermaid_(Train_song) | recordLabel | Sony_Music_Entertainment', 'Mermaid_(Train_song) | writer | Espen_Lind', 'Mermaid_(Train_song) | genre | Reggae', 'Mermaid_(Train_song) | writer | Amund_Bjørklund']]}, 'shape': '(X (X) (X) (X) (X) (X) (X))', 'shape_type': 'sibling', 'lex': {'comment': ['', '', ''], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['The Train song Mermaid, which is an example of the reggae genre, was released under the record labels of Columbia Records and Sony Music Entertainment. It was written by Espen Lind and Amund Bjørklund and has a total runtime of 3 minutes and 16 seconds.', 'Amund Bjorklund and Espen Lind are writers of the 3.16 minute reggae song Mermaid by Train that was released under Sony Music Entertainment and Columbia Records.', 'The song Mermaid was written In the reggae music genre by Espen Lind and Amund Bjorklund The song was performed by Train and released by Columbia Records and Sony Music Entertainment records. It has a total runtime of three minutes and sixteen seconds.'], 'lang': ['', '', '']}, 'test_category': 'rdf-to-text-generation-test-data-with-refs-en', 'dbpedia_links': [], 'links': []}\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"}]},{"cell_type":"code","source":"# Writing predictions to a .txt file\nwith open(\"predictions\", \"w\") as f:\n    for prediction in predictions:\n        f.write(prediction + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T15:04:19.924952Z","iopub.execute_input":"2023-07-05T15:04:19.925784Z","iopub.status.idle":"2023-07-05T15:04:19.938436Z","shell.execute_reply.started":"2023-07-05T15:04:19.925750Z","shell.execute_reply":"2023-07-05T15:04:19.937478Z"},"id":"LEfhJSKRO0L2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate BLEU scores\n#bleu = corpus_bleu(predictions, [references])\n\nmultiple_references = []\nfor i in range(len(validation_dataset)):\n    multiple_references.append(validation_dataset[i]['lex']['text'])\n\nbleu = corpus_bleu(predictions, references)\nbleu_multiple = corpus_bleu(predictions, multiple_references)\n\nprint(f\"BLEU score: {bleu.score}\")\nprint(f\"BLEU score with multiple references: {bleu_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T17:50:22.171695Z","iopub.execute_input":"2023-07-05T17:50:22.172092Z","iopub.status.idle":"2023-07-05T17:50:23.702006Z","shell.execute_reply.started":"2023-07-05T17:50:22.172055Z","shell.execute_reply":"2023-07-05T17:50:23.700923Z"},"id":"JlP8Hs4vO0L2","outputId":"9846f4f5-0589-4ad5-db96-eadb935702f5","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"BLEU score: 0.18693009820085577\nBLEU score with multiple references: 88.12736030017146\n","output_type":"stream"}]},{"cell_type":"code","source":"# Getting the maximum length of the sublists in multiple_references\nmax_length = max(len(sublist) for sublist in multiple_references)\n\n# Writing multiple_references to separate .txt files\nfor i in range(max_length):\n    with open(f\"references{i}\", \"w\") as f:\n        for ref_list in multiple_references:\n            # Writing the ith element if it exists, otherwise an empty line\n            if i < len(ref_list):\n                f.write(ref_list[i] + \"\\n\")\n            else:\n                f.write(\"\\n\")","metadata":{"id":"q12EFQIzO0L3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate BLEU scores\n#bleu = corpus_bleu(predictions, [references])\n\nmultiple_references = []\nfor i in range(len(validation_dataset)):\n    multiple_references.append(validation_dataset[i]['lex']['text'])\n\n# First, determine the maximum length of sublists\nmax_len = max(len(refs) for refs in multiple_references)\n\n# Then pad all sublists to that length\npadded_references = [refs * (max_len // len(refs)) + refs[:max_len % len(refs)] for refs in multiple_references]\n\nbleu = corpus_bleu(predictions, references)\nbleu_multiple = corpus_bleu(predictions, padded_references)\n\nprint(f\"BLEU score: {bleu.score}\")\nprint(f\"BLEU score with padded references: {bleu_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:39:08.784027Z","iopub.execute_input":"2023-07-05T00:39:08.784420Z","iopub.status.idle":"2023-07-05T00:39:12.491724Z","shell.execute_reply.started":"2023-07-05T00:39:08.784371Z","shell.execute_reply":"2023-07-05T00:39:12.489939Z"},"id":"tZCRKZBUO0L3","outputId":"88047ac4-39ff-4d36-f8eb-7585780a8ab4","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"BLEU score: 0.16214501382472107\nBLEU score with padded references: 80.7204465338761\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric('sacrebleu')\n\n# First, determine the maximum length of sublists\nmax_len = max(len(refs) for refs in multiple_references)\n\n# Then pad all sublists to that length\npadded_references = [refs * (max_len // len(refs)) + refs[:max_len % len(refs)] for refs in multiple_references]\n\n# Now 'padded_references' is a list of lists, where each sublist has the same length.\n# We can now compute the SacreBLEU score.\n\n# Note the change in the compute line\nscore = metric.compute(predictions=predictions, references = padded_references)\n\nprint(f\"SacreBLEU score: {score['score']}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:39:29.889557Z","iopub.execute_input":"2023-07-05T00:39:29.889918Z","iopub.status.idle":"2023-07-05T00:39:34.151307Z","shell.execute_reply.started":"2023-07-05T00:39:29.889887Z","shell.execute_reply":"2023-07-05T00:39:34.149323Z"},"colab":{"referenced_widgets":["3977d215683d4a51941b587a2cad1d1b"]},"id":"nlbU_MX3O0L3","outputId":"5e176ca3-0c7d-4953-d785-60fbc7edaf90","trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3977d215683d4a51941b587a2cad1d1b"}},"metadata":{}},{"name":"stdout","text":"SacreBLEU score: 31.99615265661011\n","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_chrf\n# Calculate CHR F++ scores\nchrf = corpus_chrf(predictions, [references])\nchrf_multiple = corpus_chrf(predictions, multiple_references)\nprint(f\"CHR F++ score: {chrf.score}\")\nprint(f\"CHR F++ score with multiple references: {chrf_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:39:46.532954Z","iopub.execute_input":"2023-07-05T00:39:46.533322Z","iopub.status.idle":"2023-07-05T00:39:50.531546Z","shell.execute_reply.started":"2023-07-05T00:39:46.533289Z","shell.execute_reply":"2023-07-05T00:39:50.530539Z"},"id":"7muY_0s_O0L3","outputId":"a35fef43-009b-4367-ebdb-c70799a9e149","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"CHR F++ score: 54.00287217727219\nCHR F++ score with multiple references: 77.50627157244912\n","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_chrf\n# Calculate CHR F++ scores\nchrf = corpus_chrf(predictions, [references])\nchrf_multiple = corpus_chrf(predictions, padded_references)\nprint(f\"CHR F++ score: {chrf.score}\")\nprint(f\"CHR F++ score with multiple references: {chrf_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T00:40:05.832831Z","iopub.execute_input":"2023-07-05T00:40:05.833194Z","iopub.status.idle":"2023-07-05T00:40:16.362275Z","shell.execute_reply.started":"2023-07-05T00:40:05.833163Z","shell.execute_reply":"2023-07-05T00:40:16.361205Z"},"id":"XRS9FedkO0L4","outputId":"7c9c7428-486e-4c20-c105-b90adf27cc61","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"CHR F++ score: 54.00287217727219\nCHR F++ score with multiple references: 70.48380146771281\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bert_score","metadata":{"execution":{"iopub.status.busy":"2023-07-05T17:44:17.559215Z","iopub.execute_input":"2023-07-05T17:44:17.559823Z","iopub.status.idle":"2023-07-05T17:44:29.522407Z","shell.execute_reply.started":"2023-07-05T17:44:17.559789Z","shell.execute_reply":"2023-07-05T17:44:29.521219Z"},"id":"6LnOkrXCO0L5","outputId":"972f890d-26ef-4e3b-ceee-5022408ef408","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.0.0)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.5.3)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.30.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.28.2)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.64.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.15.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.5.5)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.3.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2023.5.7)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert_score) (2023.6.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert_score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\nimport numpy as np\n\n\nmetric = load_metric('bertscore')\n\nassert len(predictions) == len(references), \"The number of predictions and references should be the same.\"\n\n# Compute the score\nscore = metric.compute(predictions=predictions, references=references, lang='en')\n\nprint(f\"BERTScore: {np.mean(score['precision'])}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-05T17:44:29.524502Z","iopub.execute_input":"2023-07-05T17:44:29.524902Z","iopub.status.idle":"2023-07-05T17:45:39.851699Z","shell.execute_reply.started":"2023-07-05T17:44:29.524863Z","shell.execute_reply":"2023-07-05T17:45:39.850390Z"},"colab":{"referenced_widgets":["e0fed60107974bf68104b38215ea55ad","9099bc840fae40e4a9a431f3a917f06b","d19c43e2eef74951bc9127f73f6321ff","c545c55eab5b43d2a4855104e992249c","555aaa61fb2041438be3070d8ec954d4"]},"id":"0cxbPcgxO0L5","outputId":"b68b19a7-2e28-4b1f-aee5-17f5a448d8a2","trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0fed60107974bf68104b38215ea55ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9099bc840fae40e4a9a431f3a917f06b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d19c43e2eef74951bc9127f73f6321ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c545c55eab5b43d2a4855104e992249c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"555aaa61fb2041438be3070d8ec954d4"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"BERTScore: 0.9269932945579457\n","output_type":"stream"}]},{"cell_type":"code","source":"i=0\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hp5u7hyaO0L5","outputId":"d275c8fc-c231-4080-c321-8b03414a6e80","execution":{"iopub.status.busy":"2023-07-09T00:01:17.339041Z","iopub.execute_input":"2023-07-09T00:01:17.339753Z","iopub.status.idle":"2023-07-09T00:01:17.347935Z","shell.execute_reply.started":"2023-07-09T00:01:17.339711Z","shell.execute_reply":"2023-07-09T00:01:17.345149Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[['Estádio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca', 'Agremiação_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_Série_C', 'Campeonato_Brasileiro_Série_C | country | Brazil', 'Agremiação_Sportiva_Arapiraquense | nickname | \"\\'\\'Alvinegro\"@en', 'Agremiação_Sportiva_Arapiraquense | ground | Estádio_Municipal_Coaracy_da_Mata_Fonseca']]\n----\nThe Estádio Municipal Coaracy da Mata Fonseca is located in Arapiraca. Agremiaço Sportiva Arapiraquense play in the Campeonato Brasileiro Série C league. The country where Agremiaço Sportiva Arapiraquense play is Brazil. Agremiaço Sportiva Arapiraquense play in the Campeonato Brasileiro Série C league.  Agremiaço Sportiva Arapiraquense play\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"i=1\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZIivtFjO0L5","outputId":"d798faa6-900b-40bf-bd37-09a76b873578","execution":{"iopub.status.busy":"2023-07-09T00:01:33.789692Z","iopub.execute_input":"2023-07-09T00:01:33.790130Z","iopub.status.idle":"2023-07-09T00:01:33.797550Z","shell.execute_reply.started":"2023-07-09T00:01:33.790095Z","shell.execute_reply":"2023-07-09T00:01:33.796246Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[['Nie_Haisheng | birthDate | 1964-10-13', 'Nie_Haisheng | occupation | Fighter_pilot']]\n----\nNie Haisheng was born on October 13, 1964. He worked as a fighter pilot.\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"i=2\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"id":"4IDvDSAzO0L6","outputId":"caa49719-b70b-47a2-8fd4-e5fea7a2ff9f","execution":{"iopub.status.busy":"2023-07-09T00:01:40.479809Z","iopub.execute_input":"2023-07-09T00:01:40.480186Z","iopub.status.idle":"2023-07-09T00:01:40.486356Z","shell.execute_reply.started":"2023-07-09T00:01:40.480155Z","shell.execute_reply":"2023-07-09T00:01:40.485200Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[['MotorSport_Vision | locationCity | Fawkham']]\n----\nThe city where MotorSport Vision is located is Fawkham.\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"i=3\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"id":"3OYq5Bf-O0L6","outputId":"8c373d2c-e4ed-43ef-ab51-3677dbb4585d","execution":{"iopub.status.busy":"2023-07-09T00:01:43.768066Z","iopub.execute_input":"2023-07-09T00:01:43.768441Z","iopub.status.idle":"2023-07-09T00:01:43.774721Z","shell.execute_reply.started":"2023-07-09T00:01:43.768408Z","shell.execute_reply":"2023-07-09T00:01:43.773344Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[['Aleksandr_Prudnikov | Person/height | \"185.0\"^^<http://dbpedia.org/datatype/centimetre>', 'FC_Spartak_Moscow | ground | Otkrytiye_Arena', 'Aleksandr_Prudnikov | team | FC_Spartak_Moscow'], ['Aleksandr_Prudnikov | Person/height | \"185.0\"^^<http://dbpedia.org/datatype/centimetre>', 'FC_Spartak_Moscow | ground | Otkrytiye_Arena', 'Aleksandr_Prudnikov | clubs | FC_Spartak_Moscow']]\n----\nAleksandr Prudnikov's height is 185.0 cm. FC Spartak Moscow's home ground is the Otkrytiye Arena. Aleksandr Prudnikov also plays for FC Spartak Moscow.  Aleksandr Prudnikov's height is 185.0 cm and he plays for FC Spartak Moscow whose home ground is the Otkrytiye Arena.\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"i=4\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"id":"vw7OyYMNO0L6","outputId":"2475bfa3-beb0-48e7-ba6c-8864f5a8f5d3","execution":{"iopub.status.busy":"2023-07-09T00:02:22.786684Z","iopub.execute_input":"2023-07-09T00:02:22.787454Z","iopub.status.idle":"2023-07-09T00:02:22.793698Z","shell.execute_reply.started":"2023-07-09T00:02:22.787417Z","shell.execute_reply":"2023-07-09T00:02:22.792389Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[['Ciudad_Ayala | populationMetro | 1777539', 'Ciudad_Ayala | leaderTitle | City Manager', 'Ciudad_Ayala | type | City', 'Ciudad_Ayala | populationDensity | 1604.0', 'Ciudad_Ayala | governmentType | Council-manager_government']]\n----\nThe population of Ciudad Ayala is 1777539. The leader title of Ciudad Ayala is \"City Manager\". Ciudad Ayala is a city. Ciudad Ayala has a population density of 1604.0. The government type of Ciudad Ayala is Council-Manager Government.  The leader title of Ciudad Ayala is \"City Manager\". The population density of Ciudad Ayala is 1604.0. The government type of Ciudad Ayala is Council-Manager\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"i=5\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"id":"lEDFLeOpO0L6","outputId":"158a5c5d-955e-4555-daac-24daab4d399d","execution":{"iopub.status.busy":"2023-07-09T00:02:34.910250Z","iopub.execute_input":"2023-07-09T00:02:34.910618Z","iopub.status.idle":"2023-07-09T00:02:34.917996Z","shell.execute_reply.started":"2023-07-09T00:02:34.910589Z","shell.execute_reply":"2023-07-09T00:02:34.916612Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[['Bootleg_Series_Volume_1:_The_Quine_Tapes | previousWork | Squeeze_(The_Velvet_Underground_album)', 'Squeeze_(The_Velvet_Underground_album) | subsequentWork | 1969:_The_Velvet_Underground_Live']]\n----\nThe Bootleg Series Volume 1: The Queen Tapes was preceded by Squeeze (The Velvet Underground album). The Squeeze (The Velvet Underground album) was followed by 1969: The Velvet Underground Live. The Queen Tapes was also preceded by Squeeze (The Velvet Underground album).  The Queen Tapes was preceded by Squeeze (The Velvet Underground album) and 1969: The Velvet Underground Live.\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"i=6\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-09T00:03:10.584422Z","iopub.execute_input":"2023-07-09T00:03:10.584781Z","iopub.status.idle":"2023-07-09T00:03:10.591096Z","shell.execute_reply.started":"2023-07-09T00:03:10.584745Z","shell.execute_reply":"2023-07-09T00:03:10.589698Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[['Ciudad_Ayala | populationDensity | 1604.0', 'Ciudad_Ayala | leaderTitle | Governator', 'Ciudad_Ayala | country | Mexico', 'Ciudad_Ayala | elevation | 1147.0', 'Ciudad_Ayala | timeZone | Pacific_Daylight_Time']]\n----\nThe population density of Ciudad Ayala is 1604.0. The leader title of Ciudad Ayala is Governator. Ciudad Ayala is located in Mexico. Ciudad Ayala is 1147.0 above sea level. The time zone of Ciudad Ayala is Pacific Daylight Time. Ciudad Ayala is located in the Pacific Time Zone.  Ciudad Ayala is located in Mexico and has a population density of 1604.0. The leader title of Ciudad Ayala is a\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"i=8\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint('----')\nprint(predictions[i])\nprint('----')\nprint(references[i])","metadata":{"execution":{"iopub.status.busy":"2023-07-09T00:04:22.632773Z","iopub.execute_input":"2023-07-09T00:04:22.633898Z","iopub.status.idle":"2023-07-09T00:04:22.643797Z","shell.execute_reply.started":"2023-07-09T00:04:22.633843Z","shell.execute_reply":"2023-07-09T00:04:22.642529Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[['Saint_Petersburg | foundingDate | 1703-05-27', 'Olga_Bondareva | deathPlace | Saint_Petersburg', 'Saint_Petersburg | areaTotal | 1439.0']]\n----\nThe founding date of Saint Petersburg is 1703-05-27. Olga Bondareva died in Saint Petersburg. The total area of Saint Petersburg is 1439.0. Olga Bondareva was born in Saint Petersburg.  Olga Bondareva was born in Saint Petersburg on 27th May 1703 and died in Saint Petersburg. The total area of Saint Petersburg is 1439.0.\n----\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}