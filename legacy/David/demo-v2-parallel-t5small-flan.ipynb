{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"2a8badda5171f6c1da75e6dcec216359e8635e393e06f848b1b87b76c1bdea5e"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"27dac6771009442986c337835ac2fab0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81ab3401681e449faca4585337346d4a","IPY_MODEL_ac24b2b5a91b48e6a8746e3e0a6bdd56","IPY_MODEL_099b3ea61045469caa5684f5d4b5fa38"],"layout":"IPY_MODEL_d41d0e0245a142589c8f5767ce8e0d3b"}},"81ab3401681e449faca4585337346d4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e466a23c1954b84bd29cee2299101b5","placeholder":"​","style":"IPY_MODEL_094afeea467543ae879be701e4a73d63","value":"100%"}},"ac24b2b5a91b48e6a8746e3e0a6bdd56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa9427c68daf40d3af8410141bfe94b3","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6dfc55f38ffe49e59ccb600b0de75088","value":3}},"099b3ea61045469caa5684f5d4b5fa38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec91a1ad9e7b4bafbc79f9ddfaa0296e","placeholder":"​","style":"IPY_MODEL_4cec0b2d487b4c13ad153e6924cc8e4a","value":" 3/3 [00:00&lt;00:00, 65.75it/s]"}},"d41d0e0245a142589c8f5767ce8e0d3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e466a23c1954b84bd29cee2299101b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"094afeea467543ae879be701e4a73d63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa9427c68daf40d3af8410141bfe94b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dfc55f38ffe49e59ccb600b0de75088":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec91a1ad9e7b4bafbc79f9ddfaa0296e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cec0b2d487b4c13ad153e6924cc8e4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1af09f1f71524f44b3f79ed0427c8559":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4027186c2a1646c7a47db3e69d3ef93b","IPY_MODEL_c224ebc06fcf44dc80e8285b6578680e","IPY_MODEL_f3f96e77a1134c5c93ba218b8261ec0f"],"layout":"IPY_MODEL_45509cc5af034006bade5bff3fe9ea3b"}},"4027186c2a1646c7a47db3e69d3ef93b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7719bedd5d2544a38a46f058d0ef1a7e","placeholder":"​","style":"IPY_MODEL_305d7d10c879476ea87f924e2f802958","value":"100%"}},"c224ebc06fcf44dc80e8285b6578680e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4731ce03cfa84014bce0054c8611b4f9","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6af2a7876d954b93aca5a16930c9f079","value":3}},"f3f96e77a1134c5c93ba218b8261ec0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_528070b64e7d4bb0a891f1dbe89ae5bc","placeholder":"​","style":"IPY_MODEL_a99d41291bf84041a091180eb477e519","value":" 3/3 [00:00&lt;00:00, 106.45it/s]"}},"45509cc5af034006bade5bff3fe9ea3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7719bedd5d2544a38a46f058d0ef1a7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"305d7d10c879476ea87f924e2f802958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4731ce03cfa84014bce0054c8611b4f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af2a7876d954b93aca5a16930c9f079":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"528070b64e7d4bb0a891f1dbe89ae5bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99d41291bf84041a091180eb477e519":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d15948f114040928a325e1665e0b1bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9aa2a3f7d6ec414cb6bc735391cc7462","IPY_MODEL_a72bd5b05ddc4e20bd777a1e51bff87f","IPY_MODEL_45e968b74fdc440382f08bfe83797d7f"],"layout":"IPY_MODEL_27829187a83e45859d0adf6deb1a5f12"}},"9aa2a3f7d6ec414cb6bc735391cc7462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01cfd32ca9ea4e54a1bff6119613d64a","placeholder":"​","style":"IPY_MODEL_abcb191fcc264867b122d58caf9e3652","value":"Downloading (…)ve/main/spiece.model: 100%"}},"a72bd5b05ddc4e20bd777a1e51bff87f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1375be65005469a9c05fb385f1597db","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_194bc9079f024606b19ed153cd2d2226","value":791656}},"45e968b74fdc440382f08bfe83797d7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccf95078f5474a8a9917dc95c2d296df","placeholder":"​","style":"IPY_MODEL_8c955109118d4ffcb3b5b9db8520eb2a","value":" 792k/792k [00:00&lt;00:00, 3.16MB/s]"}},"27829187a83e45859d0adf6deb1a5f12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01cfd32ca9ea4e54a1bff6119613d64a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abcb191fcc264867b122d58caf9e3652":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1375be65005469a9c05fb385f1597db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"194bc9079f024606b19ed153cd2d2226":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccf95078f5474a8a9917dc95c2d296df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c955109118d4ffcb3b5b9db8520eb2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"836b768308904b9e98965838df6d56cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c26f17223f9049fabbeeef900dc0f084","IPY_MODEL_096b9fdf24f44aedaa16e9f31bff5e74","IPY_MODEL_3f2e2e165fcf4575bfd2127e0f392e0d"],"layout":"IPY_MODEL_511bf71170c94239b561c6ed9c7a2014"}},"c26f17223f9049fabbeeef900dc0f084":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e0a091ca3f743b599684ec709c0724d","placeholder":"​","style":"IPY_MODEL_7f042786107f41a5be4dffec5461e220","value":"Downloading (…)lve/main/config.json: 100%"}},"096b9fdf24f44aedaa16e9f31bff5e74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98782b2ca67b42eabe9128090a4f3eec","max":1206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b61db7dc7854a6da1f96c46dfbdf72c","value":1206}},"3f2e2e165fcf4575bfd2127e0f392e0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a85ddf4d0fdf44ba815ca3f03b476407","placeholder":"​","style":"IPY_MODEL_46f3784588fe467cbddcf6e15bfcaa82","value":" 1.21k/1.21k [00:00&lt;00:00, 21.9kB/s]"}},"511bf71170c94239b561c6ed9c7a2014":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e0a091ca3f743b599684ec709c0724d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f042786107f41a5be4dffec5461e220":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98782b2ca67b42eabe9128090a4f3eec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b61db7dc7854a6da1f96c46dfbdf72c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a85ddf4d0fdf44ba815ca3f03b476407":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46f3784588fe467cbddcf6e15bfcaa82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76ea121789c34ab0ae3db2a11ce092dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0755e20e9e894e0782a6dc013944a602","IPY_MODEL_16d5d7274b774723913d9a9df040db90","IPY_MODEL_ca6af7cc25b745999b2e819972a5794c"],"layout":"IPY_MODEL_46a8ce2527bb48088f5a414f6df0ee73"}},"0755e20e9e894e0782a6dc013944a602":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed369610f713419fae0a9c26abee2b91","placeholder":"​","style":"IPY_MODEL_fe46615805e146788d96ca94f066fd87","value":"Downloading pytorch_model.bin: 100%"}},"16d5d7274b774723913d9a9df040db90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15c2f29bfa54944989bf35497436615","max":242065649,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c7e7ef1e3a34c228e0972f094716cef","value":242065649}},"ca6af7cc25b745999b2e819972a5794c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2766052cd6cd43288677e89f524222aa","placeholder":"​","style":"IPY_MODEL_c1326237db9f4a39bb312b80678be410","value":" 242M/242M [00:01&lt;00:00, 240MB/s]"}},"46a8ce2527bb48088f5a414f6df0ee73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed369610f713419fae0a9c26abee2b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe46615805e146788d96ca94f066fd87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f15c2f29bfa54944989bf35497436615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c7e7ef1e3a34c228e0972f094716cef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2766052cd6cd43288677e89f524222aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1326237db9f4a39bb312b80678be410":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2bd17acda9f4a4cb40387e7a16a4aad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34b7d58e7c434652ab4a9f4cecef0791","IPY_MODEL_c406fb3d9ff8428da7b08d1dbf76e81a","IPY_MODEL_ceff9ff6affd4f168cff5c526d56fcd7"],"layout":"IPY_MODEL_13c9318a176f42ecac5d6162d510395f"}},"34b7d58e7c434652ab4a9f4cecef0791":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99ea585e29ff4e2a966d1c69be32cb97","placeholder":"​","style":"IPY_MODEL_1f85b576a95d4b6a8ee70e78ecaa34a7","value":"Downloading (…)neration_config.json: 100%"}},"c406fb3d9ff8428da7b08d1dbf76e81a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c80227b65297408db3c88583a2291f7b","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d55e7db195b44955b09e0f04598a3598","value":147}},"ceff9ff6affd4f168cff5c526d56fcd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85e687ff32694c0aa1bedacf5b4bbf21","placeholder":"​","style":"IPY_MODEL_0982aa5f0748431e86626537055d9978","value":" 147/147 [00:00&lt;00:00, 2.48kB/s]"}},"13c9318a176f42ecac5d6162d510395f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99ea585e29ff4e2a966d1c69be32cb97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f85b576a95d4b6a8ee70e78ecaa34a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c80227b65297408db3c88583a2291f7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d55e7db195b44955b09e0f04598a3598":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85e687ff32694c0aa1bedacf5b4bbf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0982aa5f0748431e86626537055d9978":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\n!pip install datasets\n\n!pip install transformers \n!pip install sentencepiece\n\n!pip install sacrebleu\n'''","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahHaXoNB9iBc","outputId":"7a29568e-467f-4334-b715-11bd6c8b649d","execution":{"iopub.status.busy":"2023-05-24T20:39:06.853402Z","iopub.execute_input":"2023-05-24T20:39:06.853745Z","iopub.status.idle":"2023-05-24T20:39:06.869756Z","shell.execute_reply.started":"2023-05-24T20:39:06.853716Z","shell.execute_reply":"2023-05-24T20:39:06.868644Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'\\n!pip install datasets\\n\\n!pip install transformers \\n!pip install sentencepiece\\n\\n!pip install sacrebleu\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom torch.nn.parallel import DataParallel\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\nmodel = DataParallel(model)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255,"referenced_widgets":["0d15948f114040928a325e1665e0b1bc","9aa2a3f7d6ec414cb6bc735391cc7462","a72bd5b05ddc4e20bd777a1e51bff87f","45e968b74fdc440382f08bfe83797d7f","27829187a83e45859d0adf6deb1a5f12","01cfd32ca9ea4e54a1bff6119613d64a","abcb191fcc264867b122d58caf9e3652","a1375be65005469a9c05fb385f1597db","194bc9079f024606b19ed153cd2d2226","ccf95078f5474a8a9917dc95c2d296df","8c955109118d4ffcb3b5b9db8520eb2a","836b768308904b9e98965838df6d56cc","c26f17223f9049fabbeeef900dc0f084","096b9fdf24f44aedaa16e9f31bff5e74","3f2e2e165fcf4575bfd2127e0f392e0d","511bf71170c94239b561c6ed9c7a2014","3e0a091ca3f743b599684ec709c0724d","7f042786107f41a5be4dffec5461e220","98782b2ca67b42eabe9128090a4f3eec","6b61db7dc7854a6da1f96c46dfbdf72c","a85ddf4d0fdf44ba815ca3f03b476407","46f3784588fe467cbddcf6e15bfcaa82","76ea121789c34ab0ae3db2a11ce092dc","0755e20e9e894e0782a6dc013944a602","16d5d7274b774723913d9a9df040db90","ca6af7cc25b745999b2e819972a5794c","46a8ce2527bb48088f5a414f6df0ee73","ed369610f713419fae0a9c26abee2b91","fe46615805e146788d96ca94f066fd87","f15c2f29bfa54944989bf35497436615","8c7e7ef1e3a34c228e0972f094716cef","2766052cd6cd43288677e89f524222aa","c1326237db9f4a39bb312b80678be410","c2bd17acda9f4a4cb40387e7a16a4aad","34b7d58e7c434652ab4a9f4cecef0791","c406fb3d9ff8428da7b08d1dbf76e81a","ceff9ff6affd4f168cff5c526d56fcd7","13c9318a176f42ecac5d6162d510395f","99ea585e29ff4e2a966d1c69be32cb97","1f85b576a95d4b6a8ee70e78ecaa34a7","c80227b65297408db3c88583a2291f7b","d55e7db195b44955b09e0f04598a3598","85e687ff32694c0aa1bedacf5b4bbf21","0982aa5f0748431e86626537055d9978"]},"id":"7Ms8N01X9MlZ","outputId":"331ae2b5-3110-47bb-e7a1-01240b6cab7c","execution":{"iopub.status.busy":"2023-05-24T23:15:16.962105Z","iopub.execute_input":"2023-05-24T23:15:16.963096Z","iopub.status.idle":"2023-05-24T23:15:37.560269Z","shell.execute_reply.started":"2023-05-24T23:15:16.963055Z","shell.execute_reply":"2023-05-24T23:15:37.559322Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9642d205a9e46f4a40d75817b1c7188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f370273ffad54f8d9aa427a6521887b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1a7fa1dd88649098097936929ad48c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793105350503452f9b6d18784807312a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9204604166d942839e7f34bafd47b2ff"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a8109daf684162ac15efde616ee296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26cbe10828184c298beacf309d9f8217"}},"metadata":{}}]},{"cell_type":"code","source":"new_tokens = ['<H>', '<R>', '<T>']\nnew_tokens_vocab = {}\nnew_tokens_vocab['additional_special_tokens'] = []\nfor idx, t in enumerate(new_tokens):\n    new_tokens_vocab['additional_special_tokens'].append(t)\nnum_added_toks = tokenizer.add_special_tokens(new_tokens_vocab)\n\ntokenizer.add_tokens(\"[MASK]\")\ntokenizer.mask_token = \"[MASK]\"\ntokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WebNLGDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        self.prefix = \"translate from Graph to Text: \"\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        # preprocess the input graph\n        try:\n            triples = item['original_triple_sets']['otriple_set']\n            input_text = self.prefix\n            for outer_list in triples: \n                for triple in outer_list:\n                    triple_txt = triple.split(\"|\")\n                    input_text += \" <H> \" + triple_txt[0] + \" <R> \" + triple_txt[1] + \" <T> \" + triple_txt[2]\n        except (KeyError, IndexError):\n            print(\"1\")\n            print(item['original_triple_sets']['otriple_set'])\n            print(item['original_triple_sets']['otriple_set'][0])\n            print(triples)\n            input_text = self.prefix\n        # preprocess the target text\n        try:\n            target_text = item['lex']['text'][0]\n        except (KeyError, IndexError):\n            print(\"2\")\n            print(item)\n            #print(item['original_triple_sets']['otriple_set'])\n            target_text = \"\"\n        #print(item)\n        #print(input_text)\n        # encode the inputs and targets using the tokenizer\n        input_ids = tokenizer.encode(input_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        target_ids = tokenizer.encode(target_text, return_tensors='pt', padding='max_length', max_length=128, truncation=True)\n        return input_ids.squeeze(0), target_ids.squeeze(0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_INPUT_LENGTH = 128\nMAX_TARGET_LENGTH = 128\ntokenizer.model_max_length = MAX_INPUT_LENGTH\nmodel.module.config.max_length = MAX_TARGET_LENGTH\n\n# set up the device (GPU or CPU)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1jjIPRO9Mla","outputId":"c138f2cb-2966-4872-ac87-616a2d4119d1","_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the WebNLG dataset\ndataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['train']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["1af09f1f71524f44b3f79ed0427c8559","4027186c2a1646c7a47db3e69d3ef93b","c224ebc06fcf44dc80e8285b6578680e","f3f96e77a1134c5c93ba218b8261ec0f","45509cc5af034006bade5bff3fe9ea3b","7719bedd5d2544a38a46f058d0ef1a7e","305d7d10c879476ea87f924e2f802958","4731ce03cfa84014bce0054c8611b4f9","6af2a7876d954b93aca5a16930c9f079","528070b64e7d4bb0a891f1dbe89ae5bc","a99d41291bf84041a091180eb477e519"]},"id":"qEf48SzQ9Mla","outputId":"4c918f52-9562-4b13-f519-0f20efe57b2d","execution":{"iopub.status.busy":"2023-05-24T23:15:37.562114Z","iopub.execute_input":"2023-05-24T23:15:37.562483Z","iopub.status.idle":"2023-05-24T23:15:53.334758Z","shell.execute_reply.started":"2023-05-24T23:15:37.562449Z","shell.execute_reply":"2023-05-24T23:15:53.333730Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8eb04aae62e44fb8418b48d63264d87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6605d9ced34c50af63dadbf714ad8d"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset web_nlg/webnlg_challenge_2017 (download: 24.32 MiB, generated: 8.99 MiB, post-processed: Unknown size, total: 33.31 MiB) to /root/.cache/huggingface/datasets/web_nlg/webnlg_challenge_2017/0.0.0/28ffb892f7f42450dd9558684aa43bcaf44b1b3bf0d77cb8d73534646af88dda...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"122a4f619f1846bd9a41a1d998c5e379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/6940 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4615 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset web_nlg downloaded and prepared to /root/.cache/huggingface/datasets/web_nlg/webnlg_challenge_2017/0.0.0/28ffb892f7f42450dd9558684aa43bcaf44b1b3bf0d77cb8d73534646af88dda. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f858df64c4a14a55ac71125f9b7121ea"}},"metadata":{}}]},{"cell_type":"code","source":"dataset[0]['lex']['text']","metadata":{"execution":{"iopub.status.busy":"2023-05-24T23:21:22.729574Z","iopub.execute_input":"2023-05-24T23:21:22.729939Z","iopub.status.idle":"2023-05-24T23:21:22.739932Z","shell.execute_reply.started":"2023-05-24T23:21:22.729907Z","shell.execute_reply":"2023-05-24T23:21:22.738903Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['The Aarhus is the airport of Aarhus, Denmark.',\n 'Aarhus Airport serves the city of Aarhus, Denmark.']"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(len(dataset)):\n    if dataset[i]['category'] == \"Politician\":\n        print(dataset[i]['lex']['text'])\n        print(' ')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T23:22:00.383893Z","iopub.execute_input":"2023-05-24T23:22:00.384264Z","iopub.status.idle":"2023-05-24T23:22:02.371704Z","shell.execute_reply.started":"2023-05-24T23:22:00.384227Z","shell.execute_reply":"2023-05-24T23:22:02.370776Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Adaptive pretraining","metadata":{}},{"cell_type":"markdown","source":"For STA, we fine-tuned the PLMs on a small amount of labeled data from the target task using a maximum likelihood estimation (MLE) objective. This involves training the model to maximize the likelihood of generating the correct output given the input graph and labeled data. This process helps to further adapt the PLM to the specific requirements of the target task and improve its performance on that task.","metadata":{}},{"cell_type":"code","source":"import random\n\npretrain_texts = []\nfor sample in dataset:\n    try:\n        text = sample['lex']['text'][0]\n        pretrain_texts.append(text)\n    except (KeyError, IndexError):\n        continue\n\ntokenized_inputs = tokenizer(pretrain_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\ninput_ids = tokenized_inputs['input_ids']\nattention_mask = tokenized_inputs['attention_mask']\n\npretrain_data = torch.utils.data.TensorDataset(input_ids, attention_mask)\n\npretrain_loader = torch.utils.data.DataLoader(pretrain_data, batch_size=int(60), shuffle=True)\n\npretrain_optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\npretrain_criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n\npretrain_epochs = 2  # Set the number of pre-training epochs\nmasking_prob = 0.15  # Probability of masking a token\n\nif tokenizer.mask_token is None:\n    # Manually set a mask token if not already defined\n    tokenizer.add_tokens(\"[MASK]\")\n    tokenizer.mask_token = \"[MASK]\"\n    tokenizer.mask_token_id = tokenizer.convert_tokens_to_ids(\"[MASK]\")\n\nfor epoch in range(pretrain_epochs):\n    running_loss = 0.0\n    for inputs, attention_mask in pretrain_loader:\n        inputs = inputs.to(device)\n        attention_mask = attention_mask.to(device)\n        batch_size, seq_length = inputs.shape\n        \n        # Create a mask for randomly selected tokens\n        mask = torch.rand(inputs.shape) < masking_prob\n        \n        # Randomly replace selected tokens with [MASK] token\n        masked_inputs = inputs.clone()\n        masked_inputs[mask] = tokenizer.mask_token_id\n        \n        pretrain_optimizer.zero_grad()\n        outputs = model(input_ids=masked_inputs, attention_mask=attention_mask, decoder_input_ids=inputs)\n        \n        # Compute the loss only for the masked tokens\n        masked_logits = outputs.logits[mask]\n        masked_labels = inputs[mask]\n        loss = pretrain_criterion(masked_logits.view(-1, masked_logits.size(-1)), masked_labels.view(-1))\n        \n        loss.backward()\n        pretrain_optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    \n    epoch_loss = running_loss / len(pretrain_data)\n    print(f\"Pretrain Epoch {epoch+1}/{pretrain_epochs} - loss: {epoch_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:39:49.425972Z","iopub.execute_input":"2023-05-22T23:39:49.426344Z","iopub.status.idle":"2023-05-22T23:42:28.778880Z","shell.execute_reply.started":"2023-05-22T23:39:49.426315Z","shell.execute_reply":"2023-05-22T23:42:28.777908Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Pretrain Epoch 1/2 - loss: 3.2586\nPretrain Epoch 2/2 - loss: 0.6002\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For LMA, we first fine-tuned the PLMs on a small amount of task-specific data using a masked language modeling objective. This involves randomly masking some tokens in the input sequence and training the model to predict the masked tokens based on the context provided by the unmasked tokens. This process helps to adapt the PLM to the specific characteristics of the target task and improve its performance on that task.","metadata":{}},{"cell_type":"markdown","source":"# Finetuning","metadata":{}},{"cell_type":"code","source":"# set up the data loader\ntrain_data = WebNLGDataset(dataset)\nbatch_size = 32 #16\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)","metadata":{"id":"pOfRTwjZ9Mla","execution":{"iopub.status.busy":"2023-05-22T23:42:52.447229Z","iopub.execute_input":"2023-05-22T23:42:52.447634Z","iopub.status.idle":"2023-05-22T23:42:52.453049Z","shell.execute_reply.started":"2023-05-22T23:42:52.447601Z","shell.execute_reply":"2023-05-22T23:42:52.451994Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# set up the optimizer and the loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4) #3e-5\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:42:54.413350Z","iopub.execute_input":"2023-05-22T23:42:54.413761Z","iopub.status.idle":"2023-05-22T23:42:54.423721Z","shell.execute_reply.started":"2023-05-22T23:42:54.413719Z","shell.execute_reply":"2023-05-22T23:42:54.422512Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# fine-tune the model\nnum_epochs = 2\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for inputs, targets in train_loader:\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs, labels=targets)\n        loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), targets.view(-1))\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n    epoch_loss = running_loss / len(train_data)\n    print(f\"Epoch {epoch+1}/{num_epochs} - loss: {epoch_loss:.4f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYG15tgj9Mla","outputId":"0e9adabd-0a23-4320-db12-8890b1a83361","execution":{"iopub.status.busy":"2023-05-22T23:42:57.529800Z","iopub.execute_input":"2023-05-22T23:42:57.530322Z","iopub.status.idle":"2023-05-22T23:46:26.510158Z","shell.execute_reply.started":"2023-05-22T23:42:57.530283Z","shell.execute_reply":"2023-05-22T23:46:26.509152Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2 - loss: 0.8788\nEpoch 2/2 - loss: 0.6847\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the entire model\ntorch.save(model, 'model_T5_flan_small_64')\nprint(\"Model saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:51:58.192082Z","iopub.execute_input":"2023-05-22T23:51:58.192696Z","iopub.status.idle":"2023-05-22T23:51:58.876455Z","shell.execute_reply.started":"2023-05-22T23:51:58.192662Z","shell.execute_reply":"2023-05-22T23:51:58.875426Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the model\n#model = torch.load('/kaggle/input/models/model_with_CCE_masked_pretraining_multipe_triples_71')\n\n# Print a confirmation message\nprint(\"Model loaded successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T23:53:35.297210Z","iopub.execute_input":"2023-05-21T23:53:35.297827Z","iopub.status.idle":"2023-05-21T23:53:35.303598Z","shell.execute_reply.started":"2023-05-21T23:53:35.297790Z","shell.execute_reply":"2023-05-21T23:53:35.302609Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Model loaded successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## are we accounting for the multiple texts targets in the bleu? it doesn't look like it","metadata":{}},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:46:35.952595Z","iopub.execute_input":"2023-05-22T23:46:35.952960Z","iopub.status.idle":"2023-05-22T23:46:47.580211Z","shell.execute_reply.started":"2023-05-22T23:46:35.952931Z","shell.execute_reply":"2023-05-22T23:46:47.579027Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.3.1)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2.7.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.3.23)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=32","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:47:57.239358Z","iopub.execute_input":"2023-05-22T23:47:57.239792Z","iopub.status.idle":"2023-05-22T23:47:57.244616Z","shell.execute_reply.started":"2023-05-22T23:47:57.239756Z","shell.execute_reply":"2023-05-22T23:47:57.243638Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sacrebleu import corpus_bleu\nfrom random import sample\nfrom tqdm import tqdm\n\n\n# load the WebNLG validation dataset\nvalidation_dataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['test']\nvalidation_dataset = [sample for sample in validation_dataset if sample['lex']['text']] # filter out samples with empty targets \n# Select a subset of the validation dataset\n#subset_size = 10  # Choose the desired subset size\n#validation_subset = sample(list(validation_dataset), subset_size)\nvalidation_data = WebNLGDataset(validation_dataset)\n\n# set up the validation data loader\nvalidation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)\n\n# switch model to evaluation mode\nmodel.eval()\n\n# generate predictions for the validation dataset\npredictions = []\nreferences = []\nwith torch.no_grad():\n    for inputs, targets in tqdm(validation_loader, desc='Validation Progress', leave=False):\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        outputs = model.module.generate(inputs, max_length=MAX_TARGET_LENGTH, num_beams=4)\n        # convert token IDs to strings\n        predicted_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        target_texts = tokenizer.batch_decode(targets, skip_special_tokens=True)\n        # append predicted and target texts for BLEU evaluation\n        predictions.extend(predicted_texts)\n        references.extend(target_texts)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:47:59.386223Z","iopub.execute_input":"2023-05-22T23:47:59.386645Z","iopub.status.idle":"2023-05-22T23:51:32.177129Z","shell.execute_reply.started":"2023-05-22T23:47:59.386613Z","shell.execute_reply":"2023-05-22T23:51:32.173669Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee4d47b0e3274433b65cde9a17e41b5b"}},"metadata":{}},{"name":"stderr","text":"Validation Progress:   0%|          | 0/87 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n  warnings.warn(\n                                                                    \r","output_type":"stream"}]},{"cell_type":"code","source":"# calculate BLEU scores\n#bleu = corpus_bleu(predictions, [references])\n\nmultiple_references = []\nfor i in range(len(validation_dataset)):\n    multiple_references.append(validation_dataset[i]['lex']['text'])\n    \nbleu = corpus_bleu(predictions, references)\nbleu_multiple = corpus_bleu(predictions, multiple_references)\n\nprint(f\"BLEU score: {bleu.score}\")\nprint(f\"BLEU score with multiple references: {bleu_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:51:37.531764Z","iopub.execute_input":"2023-05-22T23:51:37.532544Z","iopub.status.idle":"2023-05-22T23:51:38.408889Z","shell.execute_reply.started":"2023-05-22T23:51:37.532510Z","shell.execute_reply":"2023-05-22T23:51:38.407861Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"BLEU score: 0.4864375668364918\nBLEU score with multiple references: 63.894310424627285\n","output_type":"stream"}]},{"cell_type":"code","source":"from sacrebleu import corpus_chrf\n# Calculate CHR F++ scores\nchrf = corpus_chrf(predictions, [references])\nchrf_multiple = corpus_chrf(predictions, multiple_references)\nprint(f\"CHR F++ score: {chrf.score}\")\nprint(f\"CHR F++ score with multiple references: {chrf_multiple.score}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:58:56.304057Z","iopub.execute_input":"2023-05-22T23:58:56.304498Z","iopub.status.idle":"2023-05-22T23:58:58.908446Z","shell.execute_reply.started":"2023-05-22T23:58:56.304442Z","shell.execute_reply":"2023-05-22T23:58:58.907402Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"CHR F++ score: 61.33271855251572\nCHR F++ score with multiple references: 62.0921446150697\n","output_type":"stream"}]},{"cell_type":"code","source":"i=5\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:33.365256Z","iopub.execute_input":"2023-05-22T23:52:33.365645Z","iopub.status.idle":"2023-05-22T23:52:33.373686Z","shell.execute_reply.started":"2023-05-22T23:52:33.365613Z","shell.execute_reply":"2023-05-22T23:52:33.372704Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id6', 'original_triple_sets': {'otriple_set': [['Abdul_Taib_Mahmud | successor | Sulaiman_Abdul_Rahman_Taib']]}, 'modified_triple_sets': {'mtriple_set': [['Abdul_Taib_Mahmud | successor | Sulaiman_Abdul_Rahman_Taib']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': [\"Abdul Taib Mahmud's successor was Sulaiman Abdul Rahman Taib.\", 'Abdul Taib Mahmud was succeded by Sulaiman Abdul Rahman Taib.', 'The sucessor to Abdul Taib Mahmud was Sulaiman Abdul Rahman Taib.'], 'lang': ['', '', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Abdul_Taib_Mahmud | successor | Sulaiman_Abdul_Rahman_Taib']]\nAbdul Taib Mohammed was succeeded by Sulaiman Abdul Rasherman Taib.\n[\"Abdul Taib Mahmud's successor was Sulaiman Abdul Rahman Taib.\", 'Abdul Taib Mahmud was succeded by Sulaiman Abdul Rahman Taib.', 'The sucessor to Abdul Taib Mahmud was Sulaiman Abdul Rahman Taib.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=10\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:36.243017Z","iopub.execute_input":"2023-05-22T23:52:36.243387Z","iopub.status.idle":"2023-05-22T23:52:36.252461Z","shell.execute_reply.started":"2023-05-22T23:52:36.243357Z","shell.execute_reply":"2023-05-22T23:52:36.251442Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id11', 'original_triple_sets': {'otriple_set': [['Abner_W._Sibal | deathPlace | Alexandria,_Virginia']]}, 'modified_triple_sets': {'mtriple_set': [['Abner_W._Sibal | deathPlace | Alexandria,_Virginia']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Abner W Sibal died in Alexandria, Virginia.', 'Abner W. Sibal died in Alexandria, Virginia.', 'Abner W Sibal died in Alexandria, Virginia.'], 'lang': ['', '', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Abner_W._Sibal | deathPlace | Alexandria,_Virginia']]\nAbner W. Sibal died in Alexandria, Virginia.\n['Abner W Sibal died in Alexandria, Virginia.', 'Abner W. Sibal died in Alexandria, Virginia.', 'Abner W Sibal died in Alexandria, Virginia.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=50\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:38.537507Z","iopub.execute_input":"2023-05-22T23:52:38.537868Z","iopub.status.idle":"2023-05-22T23:52:38.545931Z","shell.execute_reply.started":"2023-05-22T23:52:38.537838Z","shell.execute_reply":"2023-05-22T23:52:38.544102Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id51', 'original_triple_sets': {'otriple_set': [['United_States_Army | battles | Spanish–American_War'], ['United_States_Army | battle | Spanish–American_War']]}, 'modified_triple_sets': {'mtriple_set': [['United_States_Army | battles | Spanish–American_War']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good'], 'lid': ['Id1'], 'text': ['The United States Army was involved in battles in the Spanish-American War.'], 'lang': ['']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['United_States_Army | battles | Spanish–American_War'], ['United_States_Army | battle | Spanish–American_War']]\nThe United States Army fought in the Spanish-American War.\n['The United States Army was involved in battles in the Spanish-American War.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=0\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:40.388689Z","iopub.execute_input":"2023-05-22T23:52:40.389045Z","iopub.status.idle":"2023-05-22T23:52:40.395503Z","shell.execute_reply.started":"2023-05-22T23:52:40.389016Z","shell.execute_reply":"2023-05-22T23:52:40.394445Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"{'category': 'Politician', 'size': 1, 'eid': 'Id1', 'original_triple_sets': {'otriple_set': [['Aaron_S._Daggett | award | Purple_Heart']]}, 'modified_triple_sets': {'mtriple_set': [['Aaron_S._Daggett | award | Purple_Heart']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Aaron S Daggett was awarded the Purple Heart.', 'Aaron S. Daggett was awarded the Purple Heart.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Aaron_S._Daggett | award | Purple_Heart']]\nAaron S. Daggett won the Purple Heart.\n['Aaron S Daggett was awarded the Purple Heart.', 'Aaron S. Daggett was awarded the Purple Heart.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### known error, sometimes the prompt leaks into the output ","metadata":{}},{"cell_type":"code","source":"i=70\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:42.873751Z","iopub.execute_input":"2023-05-22T23:52:42.874119Z","iopub.status.idle":"2023-05-22T23:52:42.881679Z","shell.execute_reply.started":"2023-05-22T23:52:42.874089Z","shell.execute_reply":"2023-05-22T23:52:42.880573Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"{'category': 'MeanOfTransportation', 'size': 1, 'eid': 'Id71', 'original_triple_sets': {'otriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema'], ['Alfa_Romeo_164 | related | Lancia_Thema']]}, 'modified_triple_sets': {'mtriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Alfa Romeo 164 and Lancia Thema are related types of transportation.', 'The related transport to the Alfa Romeo 164 is the Lancia Thema.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema'], ['Alfa_Romeo_164 | related | Lancia_Thema']]\nThe Alfa Romeo 164 is related to the Lancia Thema.\n['Alfa Romeo 164 and Lancia Thema are related types of transportation.', 'The related transport to the Alfa Romeo 164 is the Lancia Thema.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=130\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:45.311875Z","iopub.execute_input":"2023-05-22T23:52:45.312236Z","iopub.status.idle":"2023-05-22T23:52:45.319829Z","shell.execute_reply.started":"2023-05-22T23:52:45.312206Z","shell.execute_reply":"2023-05-22T23:52:45.318845Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{'category': 'Athlete', 'size': 1, 'eid': 'Id131', 'original_triple_sets': {'otriple_set': [['Aleksandr_Prudnikov | team | FC_Amkar_Perm'], ['Aleksandr_Prudnikov | clubs | FC_Amkar_Perm']]}, 'modified_triple_sets': {'mtriple_set': [['Aleksandr_Prudnikov | club | FC_Amkar_Perm']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Aleksandr Prudnikov plays for FC Amkar Perm.', 'Aleksandr Prudnikov plays for the FC Amkar Perm football club.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\n[['Aleksandr_Prudnikov | team | FC_Amkar_Perm'], ['Aleksandr_Prudnikov | clubs | FC_Amkar_Perm']]\nAleksandr Prudnikov plays for FC Amkar Perm.\n['Aleksandr Prudnikov plays for FC Amkar Perm.', 'Aleksandr Prudnikov plays for the FC Amkar Perm football club.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=1861\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:47.944098Z","iopub.execute_input":"2023-05-22T23:52:47.944532Z","iopub.status.idle":"2023-05-22T23:52:47.950272Z","shell.execute_reply.started":"2023-05-22T23:52:47.944497Z","shell.execute_reply":"2023-05-22T23:52:47.949251Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"{'category': 'Astronaut', 'size': 7, 'eid': 'Id971', 'original_triple_sets': {'otriple_set': [['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | selection | 1963', 'William_Anders | timeInSpace | \"8820.0\"^^<http://dbpedia.org/datatype/minute>', 'William_Anders | birthDate | \"1933-10-17\"^^xsd:date', 'William_Anders | occupation | Fighter_pilot', 'William_Anders | birthPlace | British_Hong_Kong', 'William_Anders | mission | Apollo_8']]}, 'modified_triple_sets': {'mtriple_set': [['William_Anders | dateOfRetirement | \"1969-09-01\"', 'William_Anders | was selected by NASA | 1963', 'William_Anders | timeInSpace | \"8820.0\"(minutes)', 'William_Anders | birthDate | \"1933-10-17\"', 'William_Anders | occupation | Fighter_pilot', 'William_Anders | birthPlace | British_Hong_Kong', 'William_Anders | was a crew member of | Apollo_8']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': ['Test pilot William Anders was born in British Hong Kong on October 17th, 1933. After joining NASA in 1963, he served as a crew member of Apollo 8. When he retired on September 1st, 1969 his total space time was 8820.0 minutes.', 'William Anders was born in British Hong Kong on October 17th, 1933. He served as a fighter pilot. He joined NASA in 1963 and was a crew member on Apollo 8. He retired on the 1st September 1969, having spent 8820 minutes in space.', 'Selected in 1963 by NASA as a test pilot, William Anders was born in Hong Kong on October 17 1933, retired in 1969, and served as a crew member of Apollo 8 spending 8820 minutes in space.'], 'lang': ['', '', '']}, 'test_category': 'testdata_with_lex', 'dbpedia_links': [], 'links': []}\n[['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | selection | 1963', 'William_Anders | timeInSpace | \"8820.0\"^^<http://dbpedia.org/datatype/minute>', 'William_Anders | birthDate | \"1933-10-17\"^^xsd:date', 'William_Anders | occupation | Fighter_pilot', 'William_Anders | birthPlace | British_Hong_Kong', 'William_Anders | mission | Apollo_8']]\nWilliam Anders was born on October 17th, 1933 and retired on September 1st, 1969. He was selected by NASA in 1963 and served as a Fighter pilot. He retired on September 1st, 1969.\n['Test pilot William Anders was born in British Hong Kong on October 17th, 1933. After joining NASA in 1963, he served as a crew member of Apollo 8. When he retired on September 1st, 1969 his total space time was 8820.0 minutes.', 'William Anders was born in British Hong Kong on October 17th, 1933. He served as a fighter pilot. He joined NASA in 1963 and was a crew member on Apollo 8. He retired on the 1st September 1969, having spent 8820 minutes in space.', 'Selected in 1963 by NASA as a test pilot, William Anders was born in Hong Kong on October 17 1933, retired in 1969, and served as a crew member of Apollo 8 spending 8820 minutes in space.']\n","output_type":"stream"}]},{"cell_type":"code","source":"i=1860\nprint(validation_dataset[i])\nprint(validation_dataset[i]['original_triple_sets']['otriple_set'])\nprint(predictions[i])\nprint(multiple_references[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:52:50.554031Z","iopub.execute_input":"2023-05-22T23:52:50.554408Z","iopub.status.idle":"2023-05-22T23:52:50.562221Z","shell.execute_reply.started":"2023-05-22T23:52:50.554377Z","shell.execute_reply":"2023-05-22T23:52:50.560053Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{'category': 'Astronaut', 'size': 7, 'eid': 'Id970', 'original_triple_sets': {'otriple_set': [['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | mission | Apollo_8', 'William_Anders | nationality | United_States', 'William_Anders | birthPlace | British_Hong_Kong', 'Apollo_8 | crew2Up | Buzz_Aldrin', 'Apollo_8 | crewMembers | Frank_Borman', 'Apollo_8 | operator | NASA']]}, 'modified_triple_sets': {'mtriple_set': [['William_Anders | dateOfRetirement | \"1969-09-01\"', 'William_Anders | was a crew member of | Apollo_8', 'William_Anders | nationality | United_States', 'William_Anders | birthPlace | British_Hong_Kong', 'Apollo_8 | backup pilot | Buzz_Aldrin', 'Apollo_8 | crewMembers | Frank_Borman', 'Apollo_8 | operator | NASA']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good', 'good'], 'lid': ['Id1', 'Id2', 'Id3'], 'text': [\"William Anders was born in British Hong Kong and is a U.S Citizen. William was a member of the Apollo 8 crew (along with Frank Borman) which was operated by NASA's backup pilot Buzz Aldrin. William retired on September 1st in 1969.\", 'William Anders was born in British Hong Kong but is an American. He was a member of Apollo 8 which is operated by NASA. His backup pilot was Buzz Aldrin. Anders retired in 1960-09-01.', \"William Anders was from the US and he was born in British Hong Kong. Alongside Frank Borman, he crewed the NASA operated Apollo 8 before he retired on1969-09-01. Apollo 8's backup pilot was Buzz Aldrin.\"], 'lang': ['', '', '']}, 'test_category': 'testdata_with_lex', 'dbpedia_links': [], 'links': []}\n[['William_Anders | dateOfRet | \"1969-09-01\"^^xsd:date', 'William_Anders | mission | Apollo_8', 'William_Anders | nationality | United_States', 'William_Anders | birthPlace | British_Hong_Kong', 'Apollo_8 | crew2Up | Buzz_Aldrin', 'Apollo_8 | crewMembers | Frank_Borman', 'Apollo_8 | operator | NASA']]\nWilliam Anders was born in British Hong Kong. He was a crew member of Apollo 8 operated by Buzz Aldrin and crewed by Frank Borman. He retired on September 1st, 1969.\n[\"William Anders was born in British Hong Kong and is a U.S Citizen. William was a member of the Apollo 8 crew (along with Frank Borman) which was operated by NASA's backup pilot Buzz Aldrin. William retired on September 1st in 1969.\", 'William Anders was born in British Hong Kong but is an American. He was a member of Apollo 8 which is operated by NASA. His backup pilot was Buzz Aldrin. Anders retired in 1960-09-01.', \"William Anders was from the US and he was born in British Hong Kong. Alongside Frank Borman, he crewed the NASA operated Apollo 8 before he retired on1969-09-01. Apollo 8's backup pilot was Buzz Aldrin.\"]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## there is a problem with empty target samples in the test set, we still need to check multiple triples!","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer\nfrom datasets import load_dataset\n\n# Define the tokenizer\n#tokenizer = T5Tokenizer.from_pretrained('t5-small')\n\n# Load the WebNLG dataset\ndataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['test']\ndataset = [sample for sample in dataset if sample['lex']['text']]\n\n# Create an instance of WebNLGDataset\nwebnlg_dataset = WebNLGDataset(dataset)\n\n# Define the index of the example you want to test\nexample_index = 70\n\n# Get the input and target texts for the example at the specified index\ninput_text, target_text = webnlg_dataset[example_index]\n\n# Decode the input and target texts using the tokenizer\ndecoded_input_text = tokenizer.decode(input_text, skip_special_tokens=True)\ndecoded_target_text = tokenizer.decode(target_text, skip_special_tokens=True)\n\n# Print the preprocessed input and target texts\nprint(\"Input Text:\", decoded_input_text)\nprint(\"Target Text:\", decoded_target_text)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T18:36:30.294773Z","iopub.execute_input":"2023-05-19T18:36:30.295189Z","iopub.status.idle":"2023-05-19T18:36:31.861708Z","shell.execute_reply.started":"2023-05-19T18:36:30.295152Z","shell.execute_reply":"2023-05-19T18:36:31.860533Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b598640a8aaf4538bace35a707a4555e"}},"metadata":{}},{"name":"stdout","text":"{'category': 'MeanOfTransportation', 'size': 1, 'eid': 'Id71', 'original_triple_sets': {'otriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema'], ['Alfa_Romeo_164 | related | Lancia_Thema']]}, 'modified_triple_sets': {'mtriple_set': [['Alfa_Romeo_164 | relatedMeanOfTransportation | Lancia_Thema']]}, 'shape': '', 'shape_type': '', 'lex': {'comment': ['good', 'good'], 'lid': ['Id1', 'Id2'], 'text': ['Alfa Romeo 164 and Lancia Thema are related types of transportation.', 'The related transport to the Alfa Romeo 164 is the Lancia Thema.'], 'lang': ['', '']}, 'test_category': 'testdata_unseen_with_lex', 'dbpedia_links': [], 'links': []}\ntranslate from Graph to Text:  <H> Alfa_Romeo_164  <R>  relatedMeanOfTransportation  <T>  Lancia_Thema <H> Alfa_Romeo_164  <R>  related  <T>  Lancia_Thema\nInput Text: translate from Graph to Text: Alfa_Romeo_164 relatedMeanOfTransportation Lancia_Thema Alfa_Romeo_164 related Lancia_Thema\nTarget Text: Alfa Romeo 164 and Lancia Thema are related types of transportation.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## seeing how many empty targets there are in the testing set","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('web_nlg', 'webnlg_challenge_2017')['test']\ncount_empty_text = 0\nfor sample in dataset:\n    if not sample['lex']['text']:\n        count_empty_text += 1\n\nprint(f\"Number of samples with empty 'lex' 'text' field: {count_empty_text}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:48:18.862931Z","iopub.execute_input":"2023-05-18T18:48:18.863745Z","iopub.status.idle":"2023-05-18T18:48:20.403634Z","shell.execute_reply.started":"2023-05-18T18:48:18.863701Z","shell.execute_reply":"2023-05-18T18:48:20.402308Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2dc9ec2d9f4cc5a3473a3a50d95272"}},"metadata":{}},{"name":"stdout","text":"Number of samples with empty 'lex' 'text' field: 1862\n","output_type":"stream"}]},{"cell_type":"code","source":"total_samples = len(dataset)\nprint(f\"Total number of samples in the test dataset: {total_samples}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:48:20.405561Z","iopub.execute_input":"2023-05-18T18:48:20.405994Z","iopub.status.idle":"2023-05-18T18:48:20.412699Z","shell.execute_reply.started":"2023-05-18T18:48:20.405940Z","shell.execute_reply":"2023-05-18T18:48:20.411048Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Total number of samples in the test dataset: 4615\n","output_type":"stream"}]}]}